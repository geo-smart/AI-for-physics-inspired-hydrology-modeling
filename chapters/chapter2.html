
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Chapter 12: AI for Physics-inspired Hydrology Modeling &#8212; Use Case Template</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Glossaries" href="../reference/glossary.html" />
    <link rel="prev" title="Chapter 7: AI for physics-inspired hydrology modeling" href="chapter1.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/GeoSMART_logo.svg" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Use Case Template</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  About
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference external" href="https://geo-smart.github.io/index.html">
   Geosmart Website
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference external" href="https://foundations.projectpythia.org/landing-page.html">
   Project Pythia Foundations
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Chapter One
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="chapter1.html">
   Chapter 7: AI for physics-inspired hydrology modeling
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Chapter Two
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Chapter 12: AI for Physics-inspired Hydrology Modeling
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Reference
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../reference/glossary.html">
   Glossaries
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../reference/bibliography.html">
   Bibliography
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<div class="menu-dropdown menu-dropdown-launch-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Launch interactive content">
      <i class="fas fa-rocket"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://mybinder.org/v2/gh/geo-smart/use_case_template/main?urlpath=lab/tree/book/chapters/chapter2.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Binder"
>
  

<span class="headerbtn__icon-container">
  
    <img src="../_static/images/logo_binder.svg">
  </span>
<span class="headerbtn__text-container">Binder</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/geo-smart/use_case_template"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/geo-smart/use_case_template/issues/new?title=Issue%20on%20page%20%2Fchapters/chapter2.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/geo-smart/use_case_template/edit/main/book/chapters/chapter2.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Edit this page"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="headerbtn__text-container">suggest edit</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../_sources/chapters/chapter2.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.ipynb</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#abstract">
   Abstract
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#keywords">
   Keywords
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#introduction-background">
   Introduction &amp; background
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-note-on-software-versions">
     A note on software versions
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#pytorch-and-autodifferentiation">
   Pytorch and autodifferentiation
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#getting-started-with-pytorch">
     Getting started with PyTorch
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#autodifferentiation-theory">
     Autodifferentiation theory
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#practical-use-of-autodifferentiation-in-pytorch">
     Practical use of autodifferentiation in PyTorch
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#a-note-on-calculating-derivatives-of-functions-in-pytorch">
       A note on calculating derivatives of functions in PyTorch
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#extremely-brief-background-on-numerical-optimization">
     Extremely brief background on numerical optimization
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#first-order-methods-gradient-descent-and-other-flavors-for-training-neural-networks">
       First order methods: Gradient descent and other flavors for training neural networks
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#second-order-methods-standards-for-numerical-solutions-to-differential-equations">
       Second order methods: Standards for numerical solutions to differential equations
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-view-of-other-autodiff-packages">
     A view of other autodiff packages
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#brief-detour-on-numerically-solving-odes">
     Brief detour on numerically solving ODEs
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#the-hydrologist-s-favorite-the-linear-reservoir-model">
       The hydrologist’s favorite: The linear reservoir model
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#bringing-things-together-solving-odes-inside-of-neural-networks">
     Bringing things together: Solving ODEs inside of neural networks
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#the-nonlinear-reservoir-model">
       The nonlinear reservoir model
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#learning-the-reservoir-conductivity-function-with-neural-networks">
       Learning the reservoir conductivity function with neural networks
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#split-out-the-input-output-data">
     Split out the input/output data
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#let-s-train">
     Let’s train!
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#what-did-the-network-actually-learn-though">
     What did the network actually learn though?
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#introducing-torchdiffeq">
     Introducing
     <code class="docutils literal notranslate">
      <span class="pre">
       torchdiffeq
      </span>
     </code>
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#scaling-up-to-a-conceptual-hydrologic-model">
   Scaling up to a conceptual hydrologic model
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#the-system-of-equations">
     The system of equations
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#data">
     Data
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#on-dunder-methods">
     On
     <code class="docutils literal notranslate">
      <span class="pre">
       __dunder__
      </span>
     </code>
     methods
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#the-model-training-functions">
     The model training functions
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#setting-up-our-training-testing-data">
     Setting up our training/testing data
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#defining-the-model-setup">
     Defining the model setup
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#training-the-model">
     Training the model
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#model-analysis">
     Model analysis
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#conclusions">
     6. Conclusions
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#assignments">
       6.1 Assignments
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#open-questions">
       6.2 Open questions
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#references">
     References
    </a>
   </li>
  </ul>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Chapter 12: AI for Physics-inspired Hydrology Modeling</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#abstract">
   Abstract
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#keywords">
   Keywords
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#introduction-background">
   Introduction &amp; background
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-note-on-software-versions">
     A note on software versions
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#pytorch-and-autodifferentiation">
   Pytorch and autodifferentiation
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#getting-started-with-pytorch">
     Getting started with PyTorch
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#autodifferentiation-theory">
     Autodifferentiation theory
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#practical-use-of-autodifferentiation-in-pytorch">
     Practical use of autodifferentiation in PyTorch
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#a-note-on-calculating-derivatives-of-functions-in-pytorch">
       A note on calculating derivatives of functions in PyTorch
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#extremely-brief-background-on-numerical-optimization">
     Extremely brief background on numerical optimization
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#first-order-methods-gradient-descent-and-other-flavors-for-training-neural-networks">
       First order methods: Gradient descent and other flavors for training neural networks
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#second-order-methods-standards-for-numerical-solutions-to-differential-equations">
       Second order methods: Standards for numerical solutions to differential equations
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-view-of-other-autodiff-packages">
     A view of other autodiff packages
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#brief-detour-on-numerically-solving-odes">
     Brief detour on numerically solving ODEs
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#the-hydrologist-s-favorite-the-linear-reservoir-model">
       The hydrologist’s favorite: The linear reservoir model
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#bringing-things-together-solving-odes-inside-of-neural-networks">
     Bringing things together: Solving ODEs inside of neural networks
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#the-nonlinear-reservoir-model">
       The nonlinear reservoir model
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#learning-the-reservoir-conductivity-function-with-neural-networks">
       Learning the reservoir conductivity function with neural networks
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#split-out-the-input-output-data">
     Split out the input/output data
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#let-s-train">
     Let’s train!
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#what-did-the-network-actually-learn-though">
     What did the network actually learn though?
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#introducing-torchdiffeq">
     Introducing
     <code class="docutils literal notranslate">
      <span class="pre">
       torchdiffeq
      </span>
     </code>
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#scaling-up-to-a-conceptual-hydrologic-model">
   Scaling up to a conceptual hydrologic model
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#the-system-of-equations">
     The system of equations
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#data">
     Data
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#on-dunder-methods">
     On
     <code class="docutils literal notranslate">
      <span class="pre">
       __dunder__
      </span>
     </code>
     methods
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#the-model-training-functions">
     The model training functions
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#setting-up-our-training-testing-data">
     Setting up our training/testing data
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#defining-the-model-setup">
     Defining the model setup
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#training-the-model">
     Training the model
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#model-analysis">
     Model analysis
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#conclusions">
     6. Conclusions
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#assignments">
       6.1 Assignments
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#open-questions">
       6.2 Open questions
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#references">
     References
    </a>
   </li>
  </ul>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="chapter-12-ai-for-physics-inspired-hydrology-modeling">
<h1>Chapter 12: AI for Physics-inspired Hydrology Modeling<a class="headerlink" href="#chapter-12-ai-for-physics-inspired-hydrology-modeling" title="Permalink to this headline">#</a></h1>
<p>Andrew Bennett (<a class="reference external" href="mailto:andrbenn&#37;&#52;&#48;email&#46;arizona&#46;edu">andrbenn<span>&#64;</span>email<span>&#46;</span>arizona<span>&#46;</span>edu</a>)</p>
<p>University of Arizona</p>
<section id="abstract">
<h2>Abstract<a class="headerlink" href="#abstract" title="Permalink to this headline">#</a></h2>
<p>In this chapter we walk from beginning to end of how to implement so called “hybrid”
models which blend machine learning with traditional modeling techniques for simulating the
hydrologic cycle. Specifically, this chapter outlines the basics of automatic differentiation, it’s
use in optimization and machine learning. Then we cover some basic background on numerical
optimization. These pieces all come together in a proof-of-concept example for parameterizing
very simple differential equations with neural networks to represent unknown relationships. We
present a synthetic example describing reservoir behavior to illustrate the techniques. Following
this we show how these techniques can be scaled from synthetic data to a real hydrologic
model. The model that we implement has multiple soil storage components, vegetation, and is
represented by a well understood set of differential equations. We use the techniques built up
through the course of the chapter to practically show how to fuse machine learning techniques
with more traditional techniques in a way that is physically consistent and interpretable.</p>
</section>
<section id="keywords">
<h2>Keywords<a class="headerlink" href="#keywords" title="Permalink to this headline">#</a></h2>
<p>Hydrology, Machine Learning</p>
</section>
<section id="introduction-background">
<h2>Introduction &amp; background<a class="headerlink" href="#introduction-background" title="Permalink to this headline">#</a></h2>
<p>There is little doubt that machine-learning based methods are a valuable framework for hydrologic modeling (<strong>Nearing et al., 2021; Shen, 2018</strong>). Before diving into recent applications and their implications we would like to summarize at a very high level some of the aims and applications of modeling the hydrologic cycle. To do so, it is first worthwhile to discuss the hydrologic cycle as a whole, not only for the general reader but also to put the work we will undertake in this chapter into a proper frame of view. The goal of hydrologic science, broadly stated, is to better understand both the fate and role of water on land surface processes. These processes comprise a diverse set including streamflow in rivers, soil moisture stored in soil, snowpack stored on the land, groundwater storage in the deep subsurface, transport of both nutrients and contaminants in the subsurface mediated by subsurface water availability, biogeochemical cycling of plants and bacteria which are dependent on water availabilty, landscape morphology including erosion and weathering, and more. While there are clearly a large number of scientifically interesting open problems from a pure-research point of view in hydrology it is also clear that there is an absolutely critical role that water plays in human life and our societies broadly. As such, it is necessary that we have adequate ways to model and forecast the aforementioned quantities to ensure both quality and quantity of water supplies for human consumption and infrastructure, not to mention to maintain ecosystem health (or rather, to avoid damaging them via human activities).</p>
<p>In this chapter we want to demystify and provide a basic set of tools for developing “physics inspired” hydrologic models.  Indeed the terminology “physics inspired” is overloaded, especially in the context of AI and machine learning. While there are enormous opportunities for future research projects to meld traditional hydrology knowledge into data-driven approaches via machine learning it can be difficult to get up to speed in understanding how these approaches relate to each other. In this chapter we will build up from basic principles how to encode hydrologic theory into machine learning frameworks, with the PyTorch ecosystem as an example. To this end, we want to be clear in our goals: this chapter is mainly focused on explaining theoretic constructs and methods as well as providing a set of working code developed from the ground up rather than focusing on obtaining state-of-the-art performance metrics in our finally constructed model.</p>
<p>Concretely, our goal in this chapter is to lay out some ways in which technologies from machine learning can be merged with traditional hydrologic modeling. As this chapter is mainly aimed at Earth scientists looking to find concrete workflows of machine-learning technologies we must constrain the hydrologic point-of-view. In doing so we have chosen to focus on catchment hydrology and the prediction of streamflow. This is a popular, and highly-successful, application of machine-learning in hydrology due to a number of well-curated datasets, a clear problem statement, and the clear ability for data-driven models to outperform simple conceptual formulations of the physical systems. The recent rise in such applications can be seen in a large number of studies (<strong>Kratzert et al., 2017; Gauch et al., 2021; Thapa et al., 2020; Mai et al., 2022</strong>)</p>
<p>One of the main criticisms of these purely data driven approaches is that they may not adhere to physical principles such as mass or energy balance (although this relaxation may be one of the reasons for their high performance), and do not offer any guarantees that the resulting trained model will have any obvious interpretability. While there have been a number of explorations in using “explainable artificial intelligence” methods (XAI) in hydrology to validate trained machine learning models (<strong>Jiang et al., 2021; Schäfer et al., 2022</strong>), these models still are almost always designed for a particular purpose such as simulating streamflow timeseries for a single catchment. At the time of writing this, it is very rare for machine learning models in hydrology to be trained to output multiple variables, and even when they do they are often not explicitly linked in how they are calculated as is done in both conceptual and physics based hydrologic models. The explicit nature of non-ML hydrologic models is also appealing because they can 1) be used for multiple purposes and 2) allow us to see how resulting changes in one quantity affects changes in another. For instance you can directly explore how a decrease in simulated snowpack affects the simulated streamflow in most commonly used hydrologic models.</p>
<p>However, these criticisms must be kept in check with the overwhelming reality that in only a short number of years the ML-based modeling approaches have easily and significantly improved our ability to model quantities of hydrologic interest including streamflow, soil moisture, evapotranspiration, snowpack, and groundwater levels. Because of the consistent and significant advantages in the predictive capabilities of ML-based models as criticisms around their physical interpretability or ability to directly model intermediate processes there is a growing interest in finding hybrid approaches which blend ideas from traditional hydrologic modeling and machine learning. The interest in hybrid approaches is often appealing due to numerous innovations of such approaches in other fields such as atmospheric science, chemistry, and physics. Because the field of hybrid-machine learning methods is both new and rapidly evolving there are numerous terms being used for similar things. For the sake of clarity we will provide a set of definitions for these different approaches. While we hope that laying out these definitions up front clarifies the landscape, we also must admit our view has a certain amount of bias, and may not be agreed upon by everybody but at least provides a consistent viewpoint.</p>
<p>The terms which we wish to disentangle are Knowledge Guided Machine Learning (KGML), Neural Ordinary Differential Equation (NeuralODE),  Physics Inspired Neural Networks (PINN), and Hybrid Models. Knowledge Guided Machine learning largely is an informal set of approaches which seems to span many areas of the other terms as well as being more general. KGML based methods can incorporate methods of PINNS, NeuralODEs, and use Hybrid Models, as well as refer to activities such as feature selection and engineering based on domain-specific knowledge. The Neural Ordinary Differential Equation method was popularized by <strong>Chen, et al. (2017)</strong> and refers to a specific neural network architecture where rather than specifying discrete hidden layers the hidden state of the network is specified via an ordinary differential equation (ODE) where the form is not explicitly specified or designed for each particular application as in hydrologic or other more traditional modeling efforts. Neural ODE based methods have been successful in generic machine-learning settings, particularly for Continuous Normalizing Flows (CNFs, which are used in generative modeling to sample from very complex probability distributions) and timeseries modeling with irregular observations/inputs. On the other hand in Physics Inspired Neural Networks (PINNs), the architecture of the network is open to definition, but the loss function is set up to satisfy a particular equation form. Most successfully this method has been used to learn to simulate complex partial differential equations (PDEs, <strong>Raissi et al., 2017</strong>). However, application of PINNs in the broader Earth sciences has not seen large practical uptakes due to their difficulty in training them (<strong>Krishnapriyan et al., 2021)</strong>. Finally hybrid models are those which contain both a data driven component as well as a traditional ODE or PDE based component.</p>
<p>Largely these approaches to hybrid models can be summed up into three camps. First is putting a neural network into a larger computational model. This is popular in the atmospheric science community to try to resolve processes which happen at scales smaller than the computational element (or grid cell) to improve predictions without need for higher resolutions which is very computationally costly. Examples of this type of approach include <strong>Brenowitz and Bretherton (2020); Rasp et al. (2018); Beucler et al. (2020); and Bennett &amp; Nijssen (2021)</strong>. On the other hand, you also might switch the ordering and put a particular parametric form of an ODE or partial differential equation (PDE) into a broader neural network framework. This has become more popular in the hydrology community, particularly because it is easier to make models of particular locations rather than needing to resolve the entire planet with each prediction step. Examples of this include <strong>Jiang et al. (2020) and Kraft et al. (2021)</strong>. This is the approach that we take in this chapter. Finally, there is a third general approach to hybrid modeling which chains together model types, such as using a data-driven approach to either pre/post process data to/from a more traditionally based model. Examples of this include <strong>Frame et al. (2021), Feigl et al. (2020), and Tian et al. (2018)</strong> Of course, these are broad categorizations, and there are many overlaps and fuzzy boundaries which make exact definitions elusive.</p>
<p>With a broad overview of the different approaches to physics inspired machine learning we now turn to the outline of what we will describe in this chapter. The end goal of this chapter is to demonstrate how to build a conceptual hydrologic model parameterized by PyTorch constructs that interoperate with the broader machine learning infrastructure of optimizers and automatic differentiation. This chapter will begin with a brief introduction on the PyTorch ecosystem and is followed by a primer of automatic differentiation, which is one of the modern foundations of machine learning. It then conducts another brief overview on numerical optimization. The combination of automatic differentiation and optimization provides the basic underlying tools to start building models which blends solving domain-specific ODEs with simple neural networks. We first demonstrate the principle with a simple non-linear reservoir model and synthetic data to help understand how all of the parts operate together. Finally, we construct a variant of a conceptual hydrologic model which is parameterized by PyTorch parameters and then train the model in the same fashion as a neural network. We examine this model’s performance and show how this approach is easily interpretible and explore the intermediate processes such as evapotranspiration and soil storages to better understand what our trained model is doing. Finally, we end with concluding remarks and offer some modifications and exercises you might complete to solidify your understanding and build on these principles.</p>
<section id="a-note-on-software-versions">
<h3>A note on software versions<a class="headerlink" href="#a-note-on-software-versions" title="Permalink to this headline">#</a></h3>
<p>This tutorial was designed to be able to run as an interactive Jupyter notebook. We provide a conda environment and all of the necessary data that you need to run this end to end. Along the way we recommend that you play with specific numbers and try modifications of each section to see their effects. In a standard fashion, our first code cell is handling some imports and code setup cells.</p>
<p>However, if you are simply reading the text of this chapter without the full computational environment the library versions for the code that we use are as follows:</p>
<ul class="simple">
<li><p>matplotlib: 3.2.2</p></li>
<li><p>numpy: 1.21.5</p></li>
<li><p>xarray: 2022.3.0</p></li>
<li><p>tqdm: 4.62.3</p></li>
<li><p>torch: 1.10.1</p></li>
<li><p>torchdiffeq: 0.2.2</p></li>
</ul>
</section>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>      <span class="c1"># Plotting interface</span>
<span class="kn">import</span> <span class="nn">matplotlib</span> <span class="k">as</span> <span class="nn">mpl</span>             <span class="c1"># Plotting configuration</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>                   <span class="c1"># Standard numerical computing</span>
<span class="kn">import</span> <span class="nn">xarray</span> <span class="k">as</span> <span class="nn">xr</span>                  <span class="c1"># Package for multidimensional arrays</span>
<span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">partial</span>        <span class="c1"># Allows injecting arguments into functions</span>
<span class="kn">from</span> <span class="nn">tqdm.auto</span> <span class="kn">import</span> <span class="n">tqdm</span>           <span class="c1"># Show progress longer running processes</span>
<span class="n">mpl</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;figure.dpi&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">300</span>     <span class="c1"># Make figures suitable for printing</span>
<span class="n">seed</span> <span class="o">=</span> <span class="mi">999</span>                           <span class="c1"># Set so that our runs are reproducible</span>
<span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>    <span class="c1"># Use that random seed for numpy</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="pytorch-and-autodifferentiation">
<h2>Pytorch and autodifferentiation<a class="headerlink" href="#pytorch-and-autodifferentiation" title="Permalink to this headline">#</a></h2>
<section id="getting-started-with-pytorch">
<h3>Getting started with PyTorch<a class="headerlink" href="#getting-started-with-pytorch" title="Permalink to this headline">#</a></h3>
<p>We will use the PyTorch (<a class="reference external" href="https://pytorch.org/">https://pytorch.org/</a>) as our machine learning framework. PyTorch is one of the most popular machine learning frameworks and has been used in numerous applications (<strong>Paskze et al., 2019</strong>). It is most commonly used to build neural networks from existing building blocks, but also provides a great deal of support for developing novel architectures and components. We will use both aspects of PyTorch in this chapter, so it is good to start with some of the basics. Like many other python packages PyTorch has a number of useful modules. Here we’ll quickly go over the ones that we need to build, train, and evaluate our models.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">torch</span></code>: This is the base PyTorch module, and provides access to fundamental components like the array interface <code class="docutils literal notranslate"><span class="pre">torch.tensor</span></code> and functions which operate on the tensors (such as <code class="docutils literal notranslate"><span class="pre">torch.sum</span></code> and <code class="docutils literal notranslate"><span class="pre">torch.abs</span></code>). Among other things it also has functionality to build arrays with many similarities to the <code class="docutils literal notranslate"><span class="pre">numpy</span></code> library (for example <code class="docutils literal notranslate"><span class="pre">torch.arange</span></code> and <code class="docutils literal notranslate"><span class="pre">torch.ones</span></code>). The need for a separate implementation of array operations will become clear when we discuss automatic differentiation in the next sections.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">torch.nn</span></code>: This module provides base implementations of many standard neural network architecture components, or layers.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">torch.nn.functional</span></code> (imported as <code class="docutils literal notranslate"><span class="pre">F</span></code>): This implements a number of functions which are “functional”, meaning they do not retain any state. These functions are often used outside of the neural network definitions.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">torch.autograd</span></code>: Implements automatic differentiation routines. The base module provides two main functions <code class="docutils literal notranslate"><span class="pre">torch.autograd.grad</span></code>, which returns the sum of gradients of the output of a function with respect to the inputs, and <code class="docutils literal notranslate"><span class="pre">torch.autograd.backward</span></code> which computes the sum of of the gradients of the input with respect to the outputs of a function. We will see the uses of both of these functions in the next section, but won’t be using this module explicitly.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">torch.autograd.functional</span></code>: Implements some building blocks for writing numerical optimization routines (among other uses). We will make heavy use of the <code class="docutils literal notranslate"><span class="pre">jacobian</span></code> function here, but the other functions can be used to implement more advanced algorithms.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">torch.utils.data</span></code>: Implements the <code class="docutils literal notranslate"><span class="pre">Dataset</span></code> and <code class="docutils literal notranslate"><span class="pre">DataLoader</span></code> classes, which will be used later in this chapter to load real-life hydrologic data to train our models.</p></li>
</ul>
<p>To complete the setup of our environment we will import these packages as well. Then, we will set some basic configuration options. First the <code class="docutils literal notranslate"><span class="pre">device</span></code> will be set, which specifies the location where computation will happen on the computer. For the sake of accessibility in this chapter it will be run as a <code class="docutils literal notranslate"><span class="pre">cpu</span></code> computation, but for more advanced uses of ML in the real world using a GPU will be much more performant. If you are running this chapter interactively and have an environment which can use a GPU you may see it used here. Next, we set the <code class="docutils literal notranslate"><span class="pre">dtype</span></code> which is the data type that we will use throughout. Here, we set <code class="docutils literal notranslate"><span class="pre">torch.float32</span></code> which is a single precision floating point number. Most standard numerical implementations default to double precision (or <code class="docutils literal notranslate"><span class="pre">float64</span></code>), which require twice as much memory per value and are also slower to compute. Because machine learning is often computationally expensive we default to using <code class="docutils literal notranslate"><span class="pre">float32</span></code>, which is fairly common. Recent advances in processing capabilities on certain devices like GPUs and TPUs have also driven adoption of the <code class="docutils literal notranslate"><span class="pre">float16</span></code> or short to further improve throughput of models. To get started, we create an example tensor vector with the <code class="docutils literal notranslate"><span class="pre">torch.arange</span></code> function. This will be used as our example domain in the remainder of this section. As you can se this looks very similar to a <code class="docutils literal notranslate"><span class="pre">numpy</span></code> array, but it has some special properties like recording it’s derivative with respect to mathematical operations.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>
<span class="kn">import</span> <span class="nn">torch.autograd</span> <span class="k">as</span> <span class="nn">autograd</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">Dataset</span><span class="p">,</span> <span class="n">DataLoader</span>
<span class="kn">from</span> <span class="nn">torch.autograd.functional</span> <span class="kn">import</span> <span class="n">jacobian</span>

<span class="c1"># Set the device that we&#39;ll run on </span>
<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda:0&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Computations in this chapter will be run on a </span><span class="si">{</span><span class="n">device</span><span class="si">}</span><span class="s1">.&#39;</span><span class="p">)</span>

<span class="c1"># Some configuration, set datatype and propagate the random seed to pytorch</span>
<span class="n">dtype</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">float32</span>
<span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>

<span class="c1"># A simple helper function to take a torch tensor</span>
<span class="c1"># and make it a numpy array </span>
<span class="k">def</span> <span class="nf">to_np</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>    <span class="c1"># Stop recording gradients</span>
             <span class="o">.</span><span class="n">cpu</span><span class="p">()</span>       <span class="c1"># Make sure it&#39;s stored on CPU</span>
             <span class="o">.</span><span class="n">numpy</span><span class="p">()</span>     <span class="c1"># Convert to a numpy array</span>
             <span class="o">.</span><span class="n">squeeze</span><span class="p">())</span>  <span class="c1"># Remove any extra dimensions</span>

<span class="c1"># V will be our domain for testing functions</span>
<span class="n">v</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="mf">2.0</span><span class="p">,</span> <span class="mf">2.1</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Our example vector, v, has a shape of </span><span class="si">{</span><span class="n">v</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s1">.&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;The example vector is: </span><span class="se">\n</span><span class="si">{</span><span class="n">v</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Computations in this chapter will be run on a cpu.
Our example vector, v, has a shape of torch.Size([82]).
The example vector is: 
tensor([-2.0000e+00, -1.9500e+00, -1.9000e+00, -1.8500e+00, -1.8000e+00,
        -1.7500e+00, -1.7000e+00, -1.6500e+00, -1.6000e+00, -1.5500e+00,
        -1.5000e+00, -1.4500e+00, -1.4000e+00, -1.3500e+00, -1.3000e+00,
        -1.2500e+00, -1.2000e+00, -1.1500e+00, -1.1000e+00, -1.0500e+00,
        -1.0000e+00, -9.5000e-01, -9.0000e-01, -8.5000e-01, -8.0000e-01,
        -7.5000e-01, -7.0000e-01, -6.5000e-01, -6.0000e-01, -5.5000e-01,
        -5.0000e-01, -4.5000e-01, -4.0000e-01, -3.5000e-01, -3.0000e-01,
        -2.5000e-01, -2.0000e-01, -1.5000e-01, -1.0000e-01, -5.0000e-02,
        -5.9605e-09,  5.0000e-02,  1.0000e-01,  1.5000e-01,  2.0000e-01,
         2.5000e-01,  3.0000e-01,  3.5000e-01,  4.0000e-01,  4.5000e-01,
         5.0000e-01,  5.5000e-01,  6.0000e-01,  6.5000e-01,  7.0000e-01,
         7.5000e-01,  8.0000e-01,  8.5000e-01,  9.0000e-01,  9.5000e-01,
         1.0000e+00,  1.0500e+00,  1.1000e+00,  1.1500e+00,  1.2000e+00,
         1.2500e+00,  1.3000e+00,  1.3500e+00,  1.4000e+00,  1.4500e+00,
         1.5000e+00,  1.5500e+00,  1.6000e+00,  1.6500e+00,  1.7000e+00,
         1.7500e+00,  1.8000e+00,  1.8500e+00,  1.9000e+00,  1.9500e+00,
         2.0000e+00,  2.0500e+00])
</pre></div>
</div>
</div>
</div>
</section>
<section id="autodifferentiation-theory">
<h3>Autodifferentiation theory<a class="headerlink" href="#autodifferentiation-theory" title="Permalink to this headline">#</a></h3>
<p>As alluded to in the previous section, one of the foundations of machine learning frameworks is automatic differentiation (which we will refer to simply as autdifferentiation or autodiff). This is the underlying numerical technique that makes the backpropagation algorithm work, which allows for neural networks to be trained. This technique can also be used in other numerical optimization problems such as solving differential equations. We’ll see how this works out in subsequent sections, but first we will provide a very brief overview of how autodiff works for simple scalar valued functions. For a more complete treatment see <strong>Nocedal and Wright, (2006)</strong>.</p>
<p>As an example, consider the simple function:</p>
<div class="math notranslate nohighlight">
\[
f(x) = sin(x^2) + cos(x^2)
\]</div>
<p>We can easily compute the derivative of this function using our toolbox of derivative tricks from calculus 1 to find:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
\frac{df}{dx}(x) 
                 &amp; = \frac{d}{dx}\left(sin(x^2) + cos(x^2)\right) \\
                 &amp; = \frac{d}{dx}sin(x^2) + \frac{d}{dx}cos(x^2) \\
                 &amp; = \frac{d sin(x^2)}{d(x^2)}\frac{d(x^2)}{dx} + \frac{d cos(x^2)}{d(x^2)}\frac{d(x^2)}{dx} \\
                 &amp; = 2x (cos(x^2)) + 2x (-sin(x^2)) \\
                 &amp; = 2x (cos(x^2) - sin(x^2))
\end{aligned}               
\end{split}\]</div>
<p>Notice here what we did intuitively was break the equation down until each “elementary” part had a single derivative to calculate with respect to it’s input. Then, we simply use the rules for differentiation of these elementary parts to complete the equation, and finally simplify the algebra. Autodiff works by doing something similar, breaking apart the equation to be differentiated into the elementary parts in what’s known as a “computational graph.” This graph can then be operated on atomistically, solving each part by the known rules. The actual way to compute this can be done in one of two ways, namely “forward mode autodiff” and “reverse mode autodiff”</p>
<p>The graph of our example function looks like the following:</p>
<p><img alt="The computational graph for sin(x^2)+cos(x^2)" src="chapters/assets/computational_graph.png" /></p>
<p>For the forward mode autodifferentiation the program starts at the beginning (left) of the graph and makes use of a construct called “dual numbers” to accumulate derivatives in the forward pass. The implementation of “dual numbers” is beyond the scope of this chapter, for a reference implementation see <strong>Kochenderfer and Wheeler (2019)</strong>. For practical purposes you can think of them as a data type that records its value and its derivative with respect to the previously applied operation. To calculate the derivative we take the value of the function and it’s derivative is recorded. So, for example at <span class="math notranslate nohighlight">\(x=\pi\)</span> the input node we have <span class="math notranslate nohighlight">\(\frac{dx}{dx}=1\)</span>. Then at the output of the next layer of computational nodes we have <span class="math notranslate nohighlight">\(a=x^2=\pi^2\)</span> we have <span class="math notranslate nohighlight">\(\frac{da}{dx} = 2x = 2\pi\)</span> and likewise <span class="math notranslate nohighlight">\(b=x^2=\pi^2\)</span> so <span class="math notranslate nohighlight">\(\frac{db}{dx}=2x = 2\pi\)</span>. Similarly, after the trigonometric function nodes we have <span class="math notranslate nohighlight">\(c=cos(a)=cos(\pi^2)\)</span> and <span class="math notranslate nohighlight">\(\frac{dc}{da} = \frac{}{} \cdot sin(a) = 2\pi \cdot cos(\pi^2)\)</span> and <span class="math notranslate nohighlight">\(d=sin(b)=sin(\pi^2)\)</span> so <span class="math notranslate nohighlight">\(\frac{dd}{db}=-\frac{db}{dx}cos(b)=-2\pi \cdot sin(\pi^2)\)</span>. Finally, the sum gives us the output of the derivative, so:</p>
<div class="math notranslate nohighlight">
\[
\frac{df}{dx}(x=\pi) = -2\pi \cdot cos(\pi^2) + 2\pi \cdot sin(\pi^2) = 2\pi (sin(\pi^2) - cos(\pi^2)) \approx -2.97
\]</div>
<p>For the reverse mode autodifferentiation we begin at the end of the computational graph, tallying up each of the derivatives needed along the way. Mathematically, this comes out to:</p>
<div class="math notranslate nohighlight">
\[\begin{split}  
\begin{aligned}
\frac{df}{dx} &amp;= \frac{df}{dc_5} \frac{dc_5}{dx} \\
              &amp;= \frac{df}{dc_5}\left( \frac{dc_5}{dc_4}\frac{dc_4}{dx} + \frac{dc_5}{dc_3}\frac{dc_3}{dx} \right) \\
              &amp;= \frac{df}{dc_5}\left(\frac{dc_5}{dc_4}
                      \left(\frac{dc_4}{dc_2}\cdot \frac{dc_2}{dx} \right)
               + \frac{dc_5}{dc_3}
                       \left(\frac{dc_3}{dc_1} \cdot \frac{dc_3}{dx} \right)
               \right)
\end{aligned} 
\end{split}\]</div>
<p>Chances are this individual example will not be entirely clear if you haven’t seen these concepts before, and if you want to dive in deeper we recommend both <strong>Kochenderfer and Wheeler (2019)</strong> as well as <strong>Nocedal and Wright (2006)</strong> as previously referenced. In the mean time, it’s entirely possible to sidestep the theory of automatic differentiation as we’ll build up confidence for the method in the following sections.</p>
</section>
<section id="practical-use-of-autodifferentiation-in-pytorch">
<h3>Practical use of autodifferentiation in PyTorch<a class="headerlink" href="#practical-use-of-autodifferentiation-in-pytorch" title="Permalink to this headline">#</a></h3>
<p>Without diving too much deeper into the theory that drives autodiff or the details of its implementation we can hand-wave some of this away by using the built-in implementation in PyTorch. For the sake of this chapter, we will be focusing on scalar valued functions, which means that the Jacobian of a function is simply its derivative. So, making use of the <code class="docutils literal notranslate"><span class="pre">jacobian</span></code> function that we imported earlier is simply a means of getting the derivative of a scalar valued function at some point which we want to evaluate.</p>
<p>Just to get a feel for how the <code class="docutils literal notranslate"><span class="pre">jacobian</span></code> function works, let’s look at some examples where we have analytic solutions. Here I show that the autodiff calculation of the derivatives of both ReLU and hyperbolic tangent are equivalent to their analytic counterparts.</p>
<p>First, let’s look at the ReLU (or Rectified Linear Unit) function, a common nonlinearity introduced into neural networks. It’s functional form and derivative are quite easy to write down:</p>
<div class="math notranslate nohighlight">
\[
ReLU(x) = max(0, x)
\]</div>
<p>and</p>
<div class="math notranslate nohighlight">
\[
\frac{d}{dx} ReLU(x) = \text{1 if x&gt;0, else 0}
\]</div>
<p>The ReLU function is available in the <code class="docutils literal notranslate"><span class="pre">pytorch.functional</span></code> (or <code class="docutils literal notranslate"><span class="pre">F</span></code>) module. We can implement the derivative by hand quite easily as <code class="docutils literal notranslate"><span class="pre">drelu</span></code> and finally compare our hand-done derivative to one computed by the <code class="docutils literal notranslate"><span class="pre">jacobian</span></code> function on our set of test inputs, <code class="docutils literal notranslate"><span class="pre">v</span></code>. Note that you have to iterate over individual values of <code class="docutils literal notranslate"><span class="pre">v</span></code> in a loop to make the computation on the scalar valued function. Providing the full vector, <code class="docutils literal notranslate"><span class="pre">v</span></code>, as the second argument to <code class="docutils literal notranslate"><span class="pre">jacobian</span></code> will result in the full Jacobian matrix because PyTorch is treating the ReLU function as a vector function rather than a scalar function. If you were to simply run the <code class="docutils literal notranslate"><span class="pre">jacobian</span></code> function over <code class="docutils literal notranslate"><span class="pre">v</span></code> then what you would find is that the diagonal of the computed matrix would contain the derivative values that we are after. The call to <code class="docutils literal notranslate"><span class="pre">np.allclose</span></code> simply makes sure that both sets of derivatives are numerically equal.</p>
<section id="a-note-on-calculating-derivatives-of-functions-in-pytorch">
<h4>A note on calculating derivatives of functions in PyTorch<a class="headerlink" href="#a-note-on-calculating-derivatives-of-functions-in-pytorch" title="Permalink to this headline">#</a></h4>
<p>It is also worth noting here that the autograd functionality in PyTorch is still being developed and there are several other ways to automatically compute the derivative of a function with PyTorch. The syntax that we use here is not the most performant way to do this computation, but should be easy to understand compared to some of the other, faster methods.</p>
</section>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">drelu</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="c1"># Derivative of the relu function</span>
    <span class="k">return</span> <span class="n">x</span><span class="o">&gt;</span><span class="mi">0</span>

<span class="n">torch_drelu_v</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">jacobian</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">,</span> <span class="n">vv</span><span class="p">)</span> <span class="k">for</span> <span class="n">vv</span> <span class="ow">in</span> <span class="n">v</span><span class="p">])</span>
<span class="n">truth_drelu_v</span> <span class="o">=</span> <span class="n">drelu</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>

<span class="k">assert</span> <span class="n">np</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">torch_drelu_v</span><span class="p">,</span> <span class="n">truth_drelu_v</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Next up we’ll try another common activation function, the hyperbolic tangent. The code is almost exactly the same as before, but now we’re going to evaluate against the analytic derivative:</p>
<div class="math notranslate nohighlight">
\[
\frac{d}{dx}tanh = \frac{1}{cosh^2(x)}
\]</div>
<p>Again, we evaluate to make sure that the autodiff version is numerically equivalent to the hand-calculated derivative.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">dtanh</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="mi">1</span><span class="o">/</span><span class="n">torch</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cosh</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">2.0</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">))</span>

<span class="n">truth_dtanh_v</span> <span class="o">=</span> <span class="n">dtanh</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
<span class="n">torch_dtanh_v</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">jacobian</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tanh</span><span class="p">,</span> <span class="n">vv</span><span class="p">)</span> <span class="k">for</span> <span class="n">vv</span> <span class="ow">in</span> <span class="n">v</span><span class="p">])</span>
<span class="k">assert</span> <span class="n">np</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">truth_dtanh_v</span><span class="p">,</span> <span class="n">torch_dtanh_v</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Great, those both work out of the box. Now can we take derivatives of simple neural networks? Let’s find out. Here we will define a basic feedforward type network. Rather than initializing weights randomly from a distribution we will specify the values so that we know what the derivative should be. Also note that our activation functions will be the ReLU and hyperbolic tangents that we know the <code class="docutils literal notranslate"><span class="pre">jacobian</span></code> function works on, but you could expand this as hinted at in the exercises for this section.</p>
<p>For the first test we’ll just do the derivative of neural-network that consists of a single neuron with the hyperbolic tangent activation. This is equivalent to the previous test we did just to make sure that we could use the <code class="docutils literal notranslate"><span class="pre">jacobian</span></code> function as intended. Now you’ll note there are some subtle things happening in this code. First, we now use the <code class="docutils literal notranslate"><span class="pre">nn.Tanh</span></code> class, rather than the <code class="docutils literal notranslate"><span class="pre">F.tanh</span></code> function. This is generally considered a better practice when putting activation functions into a neural network, rather than using the functional form. This is because it is a subclass of the <code class="docutils literal notranslate"><span class="pre">nn.Module</span></code> class, which is a basic building block of PyTorch  neural-networks. Second, we have to initialize parameters for the <code class="docutils literal notranslate"><span class="pre">nn.Linear</span></code> layer, which has a <code class="docutils literal notranslate"><span class="pre">weight</span></code> and <code class="docutils literal notranslate"><span class="pre">bias</span></code>. For our network where <code class="docutils literal notranslate"><span class="pre">width</span></code> is set to 1, this corresponds to a linear equation where <code class="docutils literal notranslate"><span class="pre">weight</span></code> is the slope and <code class="docutils literal notranslate"><span class="pre">bias</span></code> is the intercept. We default the <code class="docutils literal notranslate"><span class="pre">weight</span></code> to be 1 and the <code class="docutils literal notranslate"><span class="pre">bias</span></code> to be 0, which encodes the function <span class="math notranslate nohighlight">\(f(x) = x\)</span>. When the <code class="docutils literal notranslate"><span class="pre">forward</span></code> method is used on the <span class="math notranslate nohighlight">\(Neuron\)</span>, this invokes the forward computation, which in our first example boils down to <span class="math notranslate nohighlight">\(Neuron(x) = tanh(f(x)) = tanh(x)\)</span>. And thus <span class="math notranslate nohighlight">\(\frac{d}{dx}Neuron(x) = \frac{1}{cosh^2(x)}\)</span> as before.</p>
<p>We verify this via outpu plot. Note here that while we could derive what we wanted to happen with the derivative, it is important to make sure that the introduction of the <code class="docutils literal notranslate"><span class="pre">nn.Module</span></code> machinery and creating a new instance class could still preserve the numerical relations that we wanted to encode. This quick test of something we previously knew to be true still holds, and this makes us much more confident that our code is correct.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Neuron</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">activation</span> <span class="o">=</span> <span class="n">activation</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">init_parameters</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
        
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">layer</span><span class="p">(</span><span class="n">X</span><span class="p">))</span>
    
    <span class="k">def</span> <span class="nf">init_parameters</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">weight_value</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">bias_value</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">layer</span><span class="o">.</span><span class="n">weight</span><span class="p">[:,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">weight_value</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">layer</span><span class="o">.</span><span class="n">bias</span><span class="p">[:]</span> <span class="o">=</span> <span class="n">bias_value</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">m</span> <span class="o">=</span> <span class="n">Neuron</span><span class="p">(</span><span class="n">activation</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">Tanh</span><span class="p">)</span>
<span class="n">torch_dmodel_v</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">([</span>
    <span class="n">jacobian</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">vv</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span> <span class="k">for</span> <span class="n">vv</span> <span class="ow">in</span> <span class="n">v</span>
<span class="p">])</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>

<span class="n">truth_dtanh_v</span> <span class="o">=</span> <span class="n">dtanh</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">truth_dtanh_v</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Analytic&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">torch_dmodel_v</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Autograd&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Input (x)&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;Derivative ($ \frac{\partial M}{\partial x}$)&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Single neuron with tanh activation&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Text(0.5, 1.0, &#39;Single neuron with tanh activation&#39;)
</pre></div>
</div>
<img alt="../_images/chapter2_13_1.png" src="../_images/chapter2_13_1.png" />
</div>
</div>
<p>Now that we are getting more confident, let’s do a two layer (each with single neurons) network of a ReLU activation followed by a hyperbolic tangent activation. Each of the linear layers still have the <code class="docutils literal notranslate"><span class="pre">weight</span></code> and <code class="docutils literal notranslate"><span class="pre">bias</span></code> set to 1 and 0, respectively. Thus, we can write the mathematical function that the network performs to be:</p>
<div class="math notranslate nohighlight">
\[
f(x) = tanh(ReLU(x))
\]</div>
<p>So, calculating the derivative via the chain rule we have:</p>
<div class="math notranslate nohighlight">
\[
\frac{df}{dx}(x) = \frac{d}{dx}\left( ReLU \circ tanh \right)(x) = \frac{dReLU}{dtanh} \frac{dtanh}{dx}(x) = \frac{dReLU}{dx}(x) \cdot \frac{dtanh}{dx}(x)
\]</div>
<p>As we see from the code below, this is reproduced by running the <code class="docutils literal notranslate"><span class="pre">jacobian</span></code> function on our neural network. This shows that the autodiff implementation can work through deeper networks besides a single layer, as it should.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">m2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">Neuron</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">),</span>
                   <span class="n">Neuron</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Tanh</span><span class="p">))</span>
<span class="n">torch_dmodel2_v</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">([</span>
    <span class="n">to_np</span><span class="p">(</span><span class="n">jacobian</span><span class="p">(</span><span class="n">m2</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="n">vv</span><span class="p">]])))</span> <span class="k">for</span> <span class="n">vv</span> <span class="ow">in</span> <span class="n">v</span><span class="p">])</span>

<span class="n">truth_dmodel2_v</span> <span class="o">=</span> <span class="n">drelu</span><span class="p">(</span><span class="n">v</span><span class="p">)</span> <span class="o">*</span> <span class="n">dtanh</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">truth_dmodel2_v</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Analytic&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">torch_dmodel2_v</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Autograd&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Input (x)&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;Derivative ($ \frac{\partial M}{\partial x}$)&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;2 layer (relu, tanh)&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Text(0.5, 1.0, &#39;2 layer (relu, tanh)&#39;)
</pre></div>
</div>
<img alt="../_images/chapter2_15_1.png" src="../_images/chapter2_15_1.png" />
</div>
</div>
<p>This is not a surprising result, as deep neural-networks are able to be trained via the backpropogation algorithm - but again, it instills confidence that we can use the <code class="docutils literal notranslate"><span class="pre">jacobian</span></code> function for autodifferenentiating complex mathematical constructs that can be assembled with PyTorch.</p>
<p>If you are still feeling unsure how these principles work you should try writing out the derivatives for networks where the <code class="docutils literal notranslate"><span class="pre">weight</span></code> and <code class="docutils literal notranslate"><span class="pre">bias</span></code> are set to values other than 1 and 0. If you want to get further in the weeds you could try writing a perceptron class which implements multiple neurons in a single layer, and see if you can work out the derivative of such a network with 3 neurons with hyperbolic tangent activations, weights of 2, and biases of 1, whose output dimension is 1. For reference, this network implements the mathematical function:</p>
<div class="math notranslate nohighlight">
\[
f(x) = 3 \cdot tanh(2x+1)
\]</div>
<p>and the neural network implementing this is:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">SmallPerceptron</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">Tanh</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">width</span> <span class="o">=</span> <span class="n">width</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weight</span> <span class="o">=</span> <span class="n">weight</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bias</span> <span class="o">=</span> <span class="n">bias</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">linear</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">width</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">activation</span> <span class="o">=</span> <span class="n">activation</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">init_parameters</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">init_parameters</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">linear</span><span class="o">.</span><span class="n">weight</span><span class="p">[:,</span> <span class="p">:]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">linear</span><span class="o">.</span><span class="n">bias</span><span class="p">[:]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias</span>
            
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">activation</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="n">X</span><span class="p">)))</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="extremely-brief-background-on-numerical-optimization">
<h3>Extremely brief background on numerical optimization<a class="headerlink" href="#extremely-brief-background-on-numerical-optimization" title="Permalink to this headline">#</a></h3>
<p>To progress beyond just implementing existing machine-learning based models that can regress on quantities of interest for hydrology we need to take yet another brief detour. This detour is a bit longer than the previous, but consider it essential to understanding the methods. We want to emphasize that the field of numerical optimization is evolving nearly as quickly as the rest of machine-learning. This section will begin with a quick overview of first-order gradient based optimization, which provides the basis for the most commonly used optimization strategies for training neural-networks (examples include stochastic gradient descent (SGD), Adam, etc). By including them we hope to emphasize that optimization is not unique to machine-learning and data-driven methods, but a core and essential component to performing numerical computation of complex systems.</p>
<p>From here, we progress to second-order methods, which are the bread-and-butter of introductory numerical analysis and computational modeling courses. These optimization strategies form the backbone of many common numerical ODE and PDE solvers which in turn are almost exclusively what we refer to as “physics-based” models. At this point you might be asking, why are first-order methods implied for neural networks while second-order methods implied for differential equations? This is a good question to ask indeed, but once again beyond the scope of this chapter. We refer interested readers to <strong>Nocedal and Wright (2006), Kochenderfer and Wheeler (2019), Goodfellow et al. (2016), and Isaacson &amp; Keller (1994)</strong></p>
<section id="first-order-methods-gradient-descent-and-other-flavors-for-training-neural-networks">
<h4>First order methods: Gradient descent and other flavors for training neural networks<a class="headerlink" href="#first-order-methods-gradient-descent-and-other-flavors-for-training-neural-networks" title="Permalink to this headline">#</a></h4>
<p>The language of optimization is often rooted in topography - if you want to get to the bottom of a valley you must head downhill after all. Simply put, gradient-descent methods are often called first-order methods because they make use of the first derivative (aka the slope of the valley) to find the direction to head towards the optimal point (the bottom of the valley).</p>
<p>Considering such an approach from an intuitive standpoint brings up several questions - should I always go in the direction of the steepest slope? How far should I continue before considering changing to another direction? When is it okay to go up instead of down? These are predominantly the questions that the different popular optimization strategies for training neural networks are concerned with, albeit in a more formalized mathematical sense than we’ve let on here. To get away from the intuitive and into the formalism, if we are trying to minimize a function <span class="math notranslate nohighlight">\(f\)</span> we ought to head in the opposite direction of the gradient <span class="math notranslate nohighlight">\(\nabla f\)</span>. To do so we might choose a direction, <span class="math notranslate nohighlight">\(d\)</span>, that maximizes the gradient via:</p>
<div class="math notranslate nohighlight">
\[
d(x) = - \frac{\nabla f(x)}{||\nabla f(x)||}
\]</div>
<p>where <span class="math notranslate nohighlight">\(|| \cdot ||\)</span> implies the Euclidean norm (also known as the squared error). Using the previous implementation of the autodiff derivative/gradient you might see how we can implement this in code. However, our implementations have been for scalar (or one-dimensional) functions, and this becomes a very difficult problem when going to higher dimensions.</p>
<p>In practical machine-learning optimization strategies a number of things have become standard to make optimizing large neural-networks possible. First, the actual gradient calculation is often approximated to reduce the computational burden of computing high-dimensional gradients (computational cost is also a main reason for reaching for first, rather than second-order methods for training neural-networks). Additionally the learning rate, or roughly amount of time that you walk in the downhill direction before changing course is often not fixed. This is implemented in different ways for different methods, but popular choices include Adam and RMSProp (<strong>Kingma and Ba, 2014; Ruder, 2017</strong>). Another view on augmenting the speed at which the optimizer heads downhill is the concept of momentum, which operates in line with the physics-basis of the terminology. Optimization steps with high-momentum tend to be difficult to change direction rapidly, which is favored when the topography of the optimization landscape is relatively smooth. On the other hand, low-momentum steps should be adopted when the optimization landscape is very jagged, meaning each step is important to consider to make sure the optimization doesn’t get trapped in a local minimum or overshoot out of the valley and into the mountains.</p>
</section>
<section id="second-order-methods-standards-for-numerical-solutions-to-differential-equations">
<h4>Second order methods: Standards for numerical solutions to differential equations<a class="headerlink" href="#second-order-methods-standards-for-numerical-solutions-to-differential-equations" title="Permalink to this headline">#</a></h4>
<p>Many questions of first-order optimization can be answered by second-order optimization, but with a very large number of caveats. As first order optimization uses the first-derivative to find the direction of search, second order methods use the second derivative to determine the search strategy.  Recall how the first-order optimization strategies implied questions of how far and which direction to actually step - second-order strategies alleviate some of these concerns by providing information about not only the slope of the optimization landscape but also the curvature.  The basis for second-order methods is called <em>Newton’s method</em> and can be implemented for a scalar value function <span class="math notranslate nohighlight">\(f\)</span> first by taking the second-order expansion about a test-point <span class="math notranslate nohighlight">\(x^i\)</span></p>
<div class="math notranslate nohighlight">
\[
\hat{f}(x)\approx f(x^i) + (x-x^i)f'(x^i)+ \frac{(x-x^i)^2}{2}\cdot f''(x^i)
\]</div>
<p>Using this equation we can iterate an update equation until some tolerance has converged or a maximum number of iterations has occurred. For the <span class="math notranslate nohighlight">\((i+1)th\)</span> step of the iteration process the iteration becomes:</p>
<div class="math notranslate nohighlight">
\[
x^{(i+1)} = x^{(i)} - \frac{f'(x^{(i)})}{f''(x^{(i)})}
\]</div>
<p>Newton’s method will converge quadratically, much faster than the linear convergence of first-order methods, provided some very specific criteria are met. These criteria often revolve around choosing the initial test point <span class="math notranslate nohighlight">\(x^{(0)}\)</span> as well as the curvature of the function being optimized. Newton’s method is notoriously simple to derive but difficult to make work in practice, meaning it is only used in its simplest form in simple applications. Many extensions of Newton’s method exist but are beyond the scope of this chapter. Generally, we urge scientists not to roll their own numerical solvers, and to rely on the numerous and well tested packages for solving such problems. However, in our case we must be able to implement numerical solvers in a way that interoperates with autodiff and backpropogation via the PyTorch package. We also want to provide reference implementations that make it clear how the principles operate in code. That said, the <code class="docutils literal notranslate"><span class="pre">torch.optim</span></code> default package implements a host of standard (generally first-order) solvers, <code class="docutils literal notranslate"><span class="pre">pytorch-optimizers</span></code> (<code class="docutils literal notranslate"><span class="pre">pip</span></code> installable as <code class="docutils literal notranslate"><span class="pre">torch_optimizer</span></code>) implements a wide range of other optimizers, and <code class="docutils literal notranslate"><span class="pre">torchdiffeq</span></code> offers some other optimizers for numerically solving differential equations with autodiff capabilities within python, which we will rely on in later portions of this chapter.</p>
<p>Below we provide a bare-bones implementation of a Newtwon’s method iterative solver for second-order optimization. You will note it takes a function (<code class="docutils literal notranslate"><span class="pre">f</span></code>), it’s derivative (<code class="docutils literal notranslate"><span class="pre">fprime</span></code>), a test point (<code class="docutils literal notranslate"><span class="pre">x</span></code>), and some tolerance/iteration criteria. As mentioned before, choice of the test point, <code class="docutils literal notranslate"><span class="pre">x</span></code>, is critical for convergence in complex landscapes. For this reason, as well as computational complexity we will continue to focus on scalar valued functions.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">newton_solve</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">fprime</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">100</span><span class="p">):</span>
    <span class="n">f_test</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x_list</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">]</span>
    <span class="n">it</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">while</span> <span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">f_test</span><span class="o">.</span><span class="n">clone</span><span class="p">())</span> <span class="o">&gt;</span> <span class="n">tol</span> <span class="ow">and</span> <span class="n">it</span> <span class="o">&lt;</span> <span class="n">max_iter</span><span class="p">:</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">-</span> <span class="p">(</span><span class="n">f_test</span> <span class="o">/</span> <span class="n">fprime</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">f_test</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">it</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="k">return</span> <span class="n">x</span>
</pre></div>
</div>
</div>
</div>
<p>For confidence, let’s do an easy one, solving for the minimum of a parabola. We don’t have a need for the <code class="docutils literal notranslate"><span class="pre">jacobian</span></code> function, neural networks, or anything fancy, we’ll write it out from scratch. To do so we will define the function <code class="docutils literal notranslate"><span class="pre">f</span></code> as well as the hand-done derivative <code class="docutils literal notranslate"><span class="pre">fprime</span></code> explicitly. We will then apply it to a random points on the domain <span class="math notranslate nohighlight">\(x \in [-1, 1]\)</span>. As you can see from the resulting plot, our initial guess (poorly-chosen by design) is very far off of the minimum while the minimum is, to our eye, very close to the actual minimum of the parabolic function.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">f</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">**</span><span class="mi">2</span>
<span class="n">fprime</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="mi">2</span><span class="o">*</span><span class="n">x</span>

<span class="n">x_init</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">0.95</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>
<span class="n">x_min</span> <span class="o">=</span> <span class="n">newton_solve</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">fprime</span><span class="p">,</span> <span class="n">x_init</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">plot_newton_solve</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">x_init</span><span class="p">,</span> <span class="n">x_min</span><span class="p">,</span> <span class="n">xrange</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)):</span>

    <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">xrange</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">xrange</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">100</span><span class="p">)</span>
    <span class="n">fx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">to_np</span><span class="p">(</span><span class="n">f</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">xx</span><span class="p">])))</span> <span class="k">for</span> <span class="n">xx</span> <span class="ow">in</span> <span class="n">x</span><span class="p">])</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">fx</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span>
        <span class="n">x_init</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">f</span><span class="p">(</span><span class="n">x_init</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> 
        <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;X&#39;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;crimson&#39;</span><span class="p">,</span> 
        <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Initial guess&#39;</span>
    <span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span>
        <span class="n">x_min</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">f</span><span class="p">(</span><span class="n">x_min</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> 
        <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;X&#39;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;green&#39;</span><span class="p">,</span> 
        <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Minimum found by Newton solver&#39;</span>
    <span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plot_newton_solve</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">x_init</span><span class="p">,</span> <span class="n">x_min</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/chapter2_22_0.png" src="../_images/chapter2_22_0.png" />
</div>
</div>
<p>Now let’s test the solvers on a simple “neural net” defined by a new <code class="docutils literal notranslate"><span class="pre">nn.Module</span></code>. Keep in mind here the question is - can we use traditional numerical optimization techniques on top of the broader autodiff frameworks that are used to train neural networks. To make this work, we’ll need to define a neural network which is likely not useful in any real setting. Let’s call it <code class="docutils literal notranslate"><span class="pre">TroughLayer</span></code> because it essentially represents a “trough” where there is a low point in the middle of the domain surrounded by high walls. This is a carefully designed network with two sigmoid neurons whose weights and biases were chosen so that the output is what we want. The definition of the <code class="docutils literal notranslate"><span class="pre">TroughLayer</span></code> follows below.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">TroughLayer</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">activation</span> <span class="o">=</span> <span class="n">activation</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">init_parameters</span><span class="p">()</span>
        
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>
    
    <span class="k">def</span> <span class="nf">init_parameters</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layer</span><span class="o">.</span><span class="n">weight</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span>  <span class="mf">1.5</span><span class="p">],</span> <span class="p">[</span> <span class="o">-</span><span class="mf">1.5</span><span class="p">]])</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layer</span><span class="o">.</span><span class="n">bias</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="o">-</span><span class="mf">12.0</span><span class="p">,</span> <span class="o">-</span><span class="mf">12.0</span><span class="p">])</span>
        <span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Despite being a contrived setup, we can take the <code class="docutils literal notranslate"><span class="pre">jacobian</span></code> function and apply it to the network to get <code class="docutils literal notranslate"><span class="pre">fprime</span></code> so that we can put it into the Newton solver. As you will see, we find a generally good minimum. There was some tuning of the tolerance here, if you set it too low you will diverge. This “network” encodes a function that is quite hard for the standard Newton iteration to converge on a the global minimum. As an exercise, you should try different values of <code class="docutils literal notranslate"><span class="pre">x_init</span></code> as well as determining when it converges with respect to the actual derivative (and second derivative if you’re ambitious). This function should give you a good overview of some of the difficulties of numerical optimization in a 1-d setting. In the meantime we can simply bypass these concerns because <em>most of the time it works</em>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Define the surface to look for the minimum of</span>
<span class="n">m</span> <span class="o">=</span> <span class="n">TroughLayer</span><span class="p">()</span>
<span class="c1"># Take the derivative of the model</span>
<span class="n">dm_dx</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">jacobian</span><span class="p">,</span> <span class="n">m</span><span class="p">)</span>
<span class="c1"># Initial guess</span>
<span class="n">x_init</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">9.5</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>
<span class="c1"># Use newton solver to find the minimum</span>
<span class="n">x_min</span> <span class="o">=</span> <span class="n">newton_solve</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">dm_dx</span><span class="p">,</span> <span class="n">x_init</span><span class="p">)</span>
<span class="c1"># Plot the results</span>
<span class="n">plot_newton_solve</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">x_init</span><span class="p">,</span> <span class="n">x_min</span><span class="p">,</span> <span class="p">(</span><span class="o">-</span><span class="mf">12.0</span><span class="p">,</span> <span class="mf">12.0</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/chapter2_26_0.png" src="../_images/chapter2_26_0.png" />
</div>
</div>
</section>
</section>
<section id="a-view-of-other-autodiff-packages">
<h3>A view of other autodiff packages<a class="headerlink" href="#a-view-of-other-autodiff-packages" title="Permalink to this headline">#</a></h3>
<p>We also would be remiss without mentioning the rapidly developing capabilities of the JAX python framework that provides high performance low-level primitives for autodiff of arbitrary python code and associated frameworks such as haiku, equinox, and diffrax. Similarly we must acknowledge the broader Julia programming language ecosystem which has the excellent Flux.jl and DifferentialEquations.jl packages. Both sets of ecosystems/packages implement performant and state-of-the-art packages for machine learning, numerical analysis, and solving differential equations and arbitrary differential optimization at large.</p>
</section>
<section id="brief-detour-on-numerically-solving-odes">
<h3>Brief detour on numerically solving ODEs<a class="headerlink" href="#brief-detour-on-numerically-solving-odes" title="Permalink to this headline">#</a></h3>
<p>At this point you might be wondering what all of this curve traversing is about. Finally time to bring it back - we’re trying to merge some machine learning methods with hydrologic modeling methods. As always, we should begin by starting with the simplest approach. To do so we’ll describe the linear reservoir model, implement it with the tools we’ve built up, and show how we can easily solve it. However, it’s worth pointing out that the model we will develop here still does not quite get us to a useful hydrologic model at a catchment scale. This is because a single linear reservoir cannot capture the richness of topography and vegetation that we see in the real world. But, it does provide a useful stepping stone towards more complex models. Once we have seen we can numerically solve the linear reservoir model with the tools we’ve built up we’ll relax the constraint of linearity. We will show that we can learn a nonlinear conductivity curve for a reservoir operation release in this idealized model using a hybrid physics/data-driven approach. Let’s get started!</p>
<section id="the-hydrologist-s-favorite-the-linear-reservoir-model">
<h4>The hydrologist’s favorite: The linear reservoir model<a class="headerlink" href="#the-hydrologist-s-favorite-the-linear-reservoir-model" title="Permalink to this headline">#</a></h4>
<p>It’s the hydrologist’s favorite model! We can pretty easily solve this one analytically, so let’s use it to make sure that our solvers are capable of producing good solutions. The linear reservoir model is given by the equation:</p>
<div class="math notranslate nohighlight">
\[
\frac{dS}{dt} = k \cdot S(t)
\]</div>
<p>where <span class="math notranslate nohighlight">\(S(t)\)</span> is the storage of the reservoir at time <span class="math notranslate nohighlight">\(t\)</span> and <span class="math notranslate nohighlight">\(k\)</span> is the reservoir conductivity constant with units <span class="math notranslate nohighlight">\(1/t\)</span>. For fixed values of <span class="math notranslate nohighlight">\(k\)</span> we can solve this equation analytically, as it’s simply an exponential:</p>
<div class="math notranslate nohighlight">
\[
S(t) = S(0) \cdot e^{k\cdot t}
\]</div>
<p>where <span class="math notranslate nohighlight">\(S(0)\)</span> is the initial storage. You should verify that this equation satisfies the original differential equation. You might note that if <span class="math notranslate nohighlight">\(k\)</span> is positive, we get exponential growth and if <span class="math notranslate nohighlight">\(k\)</span> is negative we get exponential decay. In line with some physical intuition, the <span class="math notranslate nohighlight">\(k\)</span> value in a “hydrologically-flavored” reservoir should be negative, as the water will drain out. To see an example of this, along with comparison of our implementation of a numerical solution using Newton’s method we will select <span class="math notranslate nohighlight">\(k=-0.1\)</span> and <span class="math notranslate nohighlight">\(S(0)=1.0\)</span>. To solve the equation we will use the implicit, or backward, Euler method, which is one of the simplest methods for numerically solving differential equations. We can estimate the storage at some time <span class="math notranslate nohighlight">\(t_{i+1}\)</span> given the current storage at time <span class="math notranslate nohighlight">\(t_i\)</span> as:</p>
<div class="math notranslate nohighlight">
\[
S(t_{i+1}) = S(t_{i}) + \Delta t \cdot \left( k \cdot S(t_{i+1}) \right)
\]</div>
<p>Given this equation, you might see the problem, <span class="math notranslate nohighlight">\(S(t_{i+1})\)</span> is on both sides of the equation, meaning we must make an optimization step to iteratively solve for <span class="math notranslate nohighlight">\(S_{i+1}\)</span>. This is where Newton’s method comes in. We can frame this problem as a Newton iteration by rearranging the equation to:</p>
<div class="math notranslate nohighlight">
\[
\begin{aligned}
0 &amp;= S(t_{i+1}) - S(t_{i}) - \Delta t \cdot \left(k \cdot S(t_{i+1}) \right)
\end{aligned}
\]</div>
<p>This equation will be supplied to the Newton iteration (defined as <code class="docutils literal notranslate"><span class="pre">f</span></code> below). This function is also easy enough to take the derivative of with respect to <span class="math notranslate nohighlight">\(S(t_{i+1})\)</span>, which we define as <code class="docutils literal notranslate"><span class="pre">fprime</span></code> for the sake of example. We also compute an autodiff variant of this derivative to show how we don’t need to always hand-calculate the derivatives for every problem we want to solve.</p>
<p>As you can see we can solve this equation pretty well numerically. Sure, there is some discrepancy, but this is mainly showing how to get an end-to-end solution, rather than fine tuning each piece. Let’s call this good enough and move on because there’s no need to do any machine learning here.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Reservoir constant</span>
<span class="n">k</span> <span class="o">=</span> <span class="o">-</span><span class="mf">0.1</span>

<span class="c1"># Initial value</span>
<span class="n">S0</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>
<span class="n">N_time</span> <span class="o">=</span> <span class="mi">50</span>

<span class="c1"># Analytic solution</span>
<span class="n">t_range</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">N_time</span><span class="p">)</span>
<span class="n">S_analytic</span> <span class="o">=</span> <span class="n">S0</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">k</span> <span class="o">*</span> <span class="n">t_range</span><span class="p">)</span>

<span class="c1"># Format the ODE for the Newton solver</span>
<span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">S</span><span class="p">,</span> <span class="n">k</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">x</span> <span class="o">-</span> <span class="n">S</span> <span class="o">-</span> <span class="n">k</span> <span class="o">*</span> <span class="n">x</span>

<span class="c1"># Derivative of the equation above</span>
<span class="k">def</span> <span class="nf">fprime</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">S</span><span class="p">,</span> <span class="n">k</span><span class="p">):</span>
    <span class="k">return</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">k</span>

<span class="c1"># Start with the initial value</span>
<span class="n">S_newt</span> <span class="o">=</span> <span class="p">[</span><span class="n">S0</span><span class="p">]</span>
<span class="n">S_newt_ad</span> <span class="o">=</span> <span class="p">[</span><span class="n">S0</span><span class="p">]</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N_time</span><span class="p">):</span>
    <span class="c1"># Partials are getting rid of the initial condition and parameter args</span>
    <span class="n">fprime_Sk</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">fprime</span><span class="p">,</span> <span class="n">S</span><span class="o">=</span><span class="n">S_newt</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">k</span><span class="o">=</span><span class="n">k</span><span class="p">)</span>
    <span class="n">f_Sk</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">S</span><span class="o">=</span><span class="n">S_newt</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">k</span><span class="o">=</span><span class="n">k</span><span class="p">)</span>
    <span class="c1"># Calculate the update</span>
    <span class="n">S_newt</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">newton_solve</span><span class="p">(</span>
        <span class="n">f_Sk</span><span class="p">,</span>             <span class="c1"># Function with conditions at current time</span>
        <span class="n">fprime_Sk</span><span class="p">,</span>        <span class="c1"># Derivative with conditions at current time</span>
        <span class="p">(</span><span class="mi">1</span><span class="o">+</span><span class="n">k</span><span class="p">)</span><span class="o">*</span><span class="n">S_newt</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span> <span class="c1"># Initial guess - I just made this one up</span>
    <span class="p">)</span>
   
    <span class="c1"># Now do the same, but with an autodiff calculated derivative</span>
    <span class="n">fprime_Sk_ad</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">jacobian</span><span class="p">,</span> <span class="n">f_Sk</span><span class="p">)</span>
    <span class="n">S_newt_ad</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">newton_solve</span><span class="p">(</span>
        <span class="n">f_Sk</span><span class="p">,</span> 
        <span class="n">fprime_Sk_ad</span><span class="p">,</span> 
        <span class="p">(</span><span class="mi">1</span><span class="o">+</span><span class="n">k</span><span class="p">)</span><span class="o">*</span><span class="n">S_newt</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
    <span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">S_analytic</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Analytic&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">S_newt</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;crimson&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> 
         <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Implicit Euler (Hand calculated derivative)&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">S_newt_ad</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;orange&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;:&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> 
         <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Implicit Euler (Autodiff calculated derivative)&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;time&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;storage&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Text(0, 0.5, &#39;storage&#39;)
</pre></div>
</div>
<img alt="../_images/chapter2_28_1.png" src="../_images/chapter2_28_1.png" />
</div>
</div>
</section>
</section>
<section id="bringing-things-together-solving-odes-inside-of-neural-networks">
<h3>Bringing things together: Solving ODEs inside of neural networks<a class="headerlink" href="#bringing-things-together-solving-odes-inside-of-neural-networks" title="Permalink to this headline">#</a></h3>
<section id="the-nonlinear-reservoir-model">
<h4>The nonlinear reservoir model<a class="headerlink" href="#the-nonlinear-reservoir-model" title="Permalink to this headline">#</a></h4>
<p>As we said, the linear reservoir is too easy and doesn’t involve much uncertainty that would require any extra fancy machinery. So, to get there, let’s change the ODE so that the conductivity term, K, is now dependent on the current storage. We will use the conductivity term as:</p>
<div class="math notranslate nohighlight">
\[
K(x) = -0.1 \cdot \text{tanh}\left( 10\cdot(x-0.5) \right)
\]</div>
<p>This represents a conductivity term where, basically, if you have low storage you start filling up and if you have high storage you start draining. Steady state is at a nice even value of 0.5. We encode this into our function <code class="docutils literal notranslate"><span class="pre">kx</span></code> below, and then run it for a bunch of values ranging from 0 to 1 to see the actual curve. The plot is output from the next code cell. Again, values above 0 correspond to the reservoir draining and values below 0 correspond to the reservoir filling.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">v</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mf">0.001</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">kx</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">b</span><span class="o">=</span><span class="mf">0.50</span><span class="p">,</span> <span class="n">s</span><span class="o">=-</span><span class="mf">0.1</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">s</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="mi">10</span> <span class="o">*</span> <span class="p">(</span><span class="n">x</span><span class="o">-</span><span class="n">b</span><span class="p">))</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">kx</span><span class="p">(</span><span class="n">v</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;grey&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Storage (S)&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Reservoir conductivity (K)&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Text(0, 0.5, &#39;Reservoir conductivity (K)&#39;)
</pre></div>
</div>
<img alt="../_images/chapter2_30_1.png" src="../_images/chapter2_30_1.png" />
</div>
</div>
<p>Given all of our machinery developed so far, we can now solve the nonlinear version for all sorts of initial conditions. Note that I am using autodiff’s <code class="docutils literal notranslate"><span class="pre">jacobian</span></code> to determine the derivative of the conductivity function <span class="math notranslate nohighlight">\(K(S)\)</span>, but there’s also a commented out version of the solver.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">S</span><span class="p">,</span> <span class="n">k</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">x</span> <span class="o">-</span> <span class="n">S</span> <span class="o">-</span> <span class="n">k</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">*</span><span class="n">x</span>

<span class="k">def</span> <span class="nf">fprime</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">S</span><span class="p">,</span> <span class="n">k</span><span class="p">):</span>
    <span class="k">return</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">jacobian</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span> <span class="o">*</span> <span class="n">x</span> <span class="o">-</span> <span class="n">k</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">my_odeint</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">fprime</span><span class="p">,</span> <span class="n">S_newt</span><span class="p">,</span> <span class="n">kx</span><span class="p">,</span> <span class="n">N_time</span><span class="o">=</span><span class="mi">30</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N_time</span><span class="p">):</span>
        <span class="n">f_Sk</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">S</span><span class="o">=</span><span class="n">S_newt</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">k</span><span class="o">=</span><span class="n">kx</span><span class="p">)</span>
        <span class="c1"># &quot;hand done&quot; derivative function</span>
        <span class="c1">#fprime_Sk = partial(fprime, S=S_newt[-1], k=kx)</span>
        <span class="c1"># autodiff derivative function</span>
        <span class="n">fprime_Sk</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">jacobian</span><span class="p">,</span> <span class="n">f_Sk</span><span class="p">)</span>                  
        <span class="n">S_newt</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">newton_solve</span><span class="p">(</span><span class="n">f_Sk</span><span class="p">,</span> <span class="n">fprime_Sk</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="o">+</span><span class="n">k</span><span class="p">)</span><span class="o">*</span><span class="n">S_newt</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>
    <span class="k">return</span> <span class="n">S_newt</span>

<span class="n">all_S_newt</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">S0</span> <span class="ow">in</span> <span class="p">[</span><span class="mf">0.9</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">]:</span>
    <span class="n">all_S_newt</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">my_odeint</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">fprime</span><span class="p">,</span> <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">S0</span><span class="p">)],</span> <span class="n">kx</span><span class="p">))</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">all_S_newt</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span>    <span class="n">label</span><span class="o">=</span><span class="s1">&#39;$S_</span><span class="si">{0}</span><span class="s1">$=0.9&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">all_S_newt</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;orange&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;$S_</span><span class="si">{0}</span><span class="s1">$=0.7&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">all_S_newt</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;gold&#39;</span><span class="p">,</span>   <span class="n">label</span><span class="o">=</span><span class="s1">&#39;$S_</span><span class="si">{0}</span><span class="s1">$=0.5&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">all_S_newt</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;green&#39;</span><span class="p">,</span>  <span class="n">label</span><span class="o">=</span><span class="s1">&#39;$S_</span><span class="si">{0}</span><span class="s1">$=0.3&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">all_S_newt</span><span class="p">[</span><span class="mi">4</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;blue&#39;</span><span class="p">,</span>   <span class="n">label</span><span class="o">=</span><span class="s1">&#39;$S_</span><span class="si">{0}</span><span class="s1">$=0.1&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;time&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;storage&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Text(0, 0.5, &#39;storage&#39;)
</pre></div>
</div>
<img alt="../_images/chapter2_32_1.png" src="../_images/chapter2_32_1.png" />
</div>
</div>
</section>
<section id="learning-the-reservoir-conductivity-function-with-neural-networks">
<h4>Learning the reservoir conductivity function with neural networks<a class="headerlink" href="#learning-the-reservoir-conductivity-function-with-neural-networks" title="Permalink to this headline">#</a></h4>
<p>Now imagine you’re actually a hydrologist - you can’t directly measure the conductivity of the “reservoir” but you can measure storage levels. If you’re interested in determining <span class="math notranslate nohighlight">\(K(S)\)</span> from data you have all sorts of avenues, but the one we’re interested in is a neural network. In this case, imagine we “know” what the dynamics look like (aka the general structure of the ODE defining the system), but we do not know the functional form for <span class="math notranslate nohighlight">\(K(S)\)</span>. Our neural network then, will solve the dynamics, and update the weights of a network that represents the conductivity during training. Once trained, we can pull out the network and look at what <span class="math notranslate nohighlight">\(K(S)\)</span> was determined to be from the data.
Below is the network in question. Note it’s just a simple densely connected network with <code class="docutils literal notranslate"><span class="pre">width</span></code> and <code class="docutils literal notranslate"><span class="pre">depth</span></code> hyperparameters. You might modify this to be a more complex structure, but for simplicity let’s give this a go.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">MLP</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;A basic Multi Layer Perceptron model&quot;&quot;&quot;</span>
    
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> 
        <span class="n">width</span><span class="p">,</span> 
        <span class="n">depth</span><span class="p">,</span> 
        <span class="n">activation</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">Tanh</span><span class="p">,</span>
        <span class="n">in_dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">out_dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">linear</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layers</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">linear</span><span class="p">(</span><span class="n">in_dim</span><span class="p">,</span> <span class="n">width</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="n">bias</span><span class="p">))</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">depth</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">linear</span><span class="p">(</span><span class="n">width</span><span class="p">,</span> <span class="n">width</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="n">bias</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">linear</span><span class="p">(</span><span class="n">width</span><span class="p">,</span> <span class="n">out_dim</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="n">bias</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layers</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">activation</span> <span class="o">=</span> <span class="n">activation</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Identity</span><span class="p">()</span>
        
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation</span><span class="p">(</span><span class="n">l</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">out</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">](</span><span class="n">x</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">x</span>


<span class="k">class</span> <span class="nc">NeuralReservoir</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A module representing the Nonlinear reservoir with a </span>
<span class="sd">    conductivity term represented by an MLP</span>
<span class="sd">    &quot;&quot;&quot;</span>
    
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">width</span><span class="p">,</span> <span class="n">depth</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="c1"># Parameterize K(S) as an MLP model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">K</span> <span class="o">=</span> <span class="n">MLP</span><span class="p">(</span><span class="n">width</span><span class="p">,</span> <span class="n">depth</span><span class="p">)</span>
        
    <span class="k">def</span> <span class="nf">newton_solve</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">fprime</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">100</span><span class="p">):</span>
        <span class="n">f_test</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">it</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">tol</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">tol</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>
        <span class="n">err</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">tol</span><span class="p">)</span> <span class="c1">#ensure at least one pass occurs</span>
        <span class="k">while</span> <span class="n">err</span> <span class="o">&gt;</span> <span class="n">tol</span> <span class="ow">and</span> <span class="n">it</span> <span class="o">&lt;</span> <span class="n">max_iter</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">-</span> <span class="p">(</span><span class="n">f_test</span> <span class="o">/</span> <span class="n">fprime</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
            <span class="n">f_test</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
            <span class="n">err</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">f_test</span><span class="p">)</span>
            <span class="n">it</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">return</span> <span class="n">x</span>
    
    <span class="k">def</span> <span class="nf">res_equation</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">S</span><span class="p">):</span>
        <span class="c1"># Reservoir equation (aka the &quot;dynamics&quot;)</span>
        <span class="k">return</span> <span class="n">x</span> <span class="o">-</span> <span class="n">S</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">K</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">*</span> <span class="n">x</span>
   
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">S0</span><span class="p">):</span>
        <span class="n">f_Sk</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">res_equation</span><span class="p">,</span> <span class="n">S</span><span class="o">=</span><span class="n">S0</span><span class="p">)</span>
        <span class="n">fprime_Sk</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">jacobian</span><span class="p">,</span> <span class="n">f_Sk</span><span class="p">)</span> 
        <span class="n">S1_guess</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">0.95</span><span class="p">)</span> <span class="o">*</span> <span class="n">S0</span>
        <span class="n">S_all</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">newton_solve</span><span class="p">(</span><span class="n">f_Sk</span><span class="p">,</span> <span class="n">fprime_Sk</span><span class="p">,</span> <span class="n">S1_guess</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">S_all</span>
    
</pre></div>
</div>
</div>
</div>
<p>Before we can train the network we need some data - this is where we use our previous solution to generate some synthetic data and we will see how well the network can reconstruct the known conductivity function. I’ll just run a few timesteps for a bunch of different initial conditions.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">n_samples</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">all_S_newt</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">all_initial_conds</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>
<span class="k">for</span> <span class="n">S0</span> <span class="ow">in</span> <span class="n">all_initial_conds</span><span class="p">:</span>
    <span class="n">all_S_newt</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">my_odeint</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">fprime</span><span class="p">,</span> <span class="p">[</span><span class="n">S0</span><span class="p">],</span> <span class="n">kx</span><span class="p">,</span> <span class="n">N_time</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<p>We will also define a standard <code class="docutils literal notranslate"><span class="pre">epoch</span></code> function whcih simply iterates over the training data and runs the optimization routine (Here, a variant of gradient descent). If you are not familiar with this sort of construct we recommend you go back and work through some basic PyTorch tutorials because designing the training loop is one of the most crucial and common workflows in deep learning.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">epoch</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">loss_fun</span><span class="p">,</span> <span class="n">opt</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">):</span>
    <span class="n">total_loss</span><span class="p">,</span> <span class="n">total_err</span> <span class="o">=</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span>
    <span class="n">n_iter</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_iter</span><span class="p">):</span>
        <span class="n">Xd</span><span class="p">,</span> <span class="n">yd</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">opt</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">yp</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">Xd</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fun</span><span class="p">(</span><span class="n">yp</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(),</span> <span class="n">yd</span><span class="o">.</span><span class="n">squeeze</span><span class="p">())</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">opt</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
        <span class="n">total_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">*</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">total_loss</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="split-out-the-input-output-data">
<h3>Split out the input/output data<a class="headerlink" href="#split-out-the-input-output-data" title="Permalink to this headline">#</a></h3>
<p>Our networks training task is to figure out the storage one timestep later, given it’s initial storage. We have 10 samples for training, but you could add more by adding more <code class="docutils literal notranslate"><span class="pre">S0</span></code>’s under the <code class="docutils literal notranslate"><span class="pre">Training</span> <span class="pre">Data</span></code> heading or by increasing the number of timesteps in the <code class="docutils literal notranslate"><span class="pre">my_odeint</span></code> function. You might be thinking 10 samples is way too small to do any machine learning on, but keep in mind we have a <em>very</em> strong inductive bias for how our model operates because we’ve directly encoded the differential equaiton and are only attempting to figure out a parameterization of it. If you bump this number up to 100  or 1000 you will see we can pretty much perfectly match the conductivity curve. But, using only 10 samples is conceptually more interesting as it shows how viable this type of approach can be.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_X</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">train_Y</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">ss</span> <span class="ow">in</span> <span class="n">all_S_newt</span><span class="p">:</span>
    <span class="n">train_X</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ss</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">train_Y</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ss</span><span class="p">[</span><span class="mi">1</span><span class="p">:])</span>

<span class="n">train_X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">(</span><span class="n">train_X</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">train_Y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">(</span><span class="n">train_Y</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="n">train_X</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>torch.Size([10, 1])
</pre></div>
</div>
</div>
</div>
</section>
<section id="let-s-train">
<h3>Let’s train!<a class="headerlink" href="#let-s-train" title="Permalink to this headline">#</a></h3>
<p>The NeuralReservoir is set up with some user-defined width and depth settings. We additionally set a learning rate for our optimizer (chosen to be Adam) and finally train a user-defined number of epochs. Following training we can look at the loss curve to see if the model was able to converge.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">max_epochs</span> <span class="o">=</span> <span class="mi">300</span>
<span class="n">width</span> <span class="o">=</span> <span class="mi">12</span>
<span class="n">depth</span> <span class="o">=</span> <span class="mi">4</span>
<span class="c1"># We go big here: https://twitter.com/karpathy/status/801621764144971776?lang=en</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">3e-3</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">NeuralReservoir</span><span class="p">(</span><span class="n">width</span><span class="p">,</span> <span class="n">depth</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">loss_fun</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">()</span>
<span class="n">opt</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">loss_history</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">max_epochs</span><span class="p">)):</span>
    <span class="n">train_loss</span> <span class="o">=</span> <span class="n">epoch</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span> <span class="n">train_Y</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">loss_fun</span><span class="p">,</span> <span class="n">opt</span><span class="p">)</span>
    <span class="n">loss_history</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">train_loss</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "2edd1abe7a4242b58e6d39eed18dd154", "version_major": 2, "version_minor": 0}
</script></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">plot_loss</span><span class="p">(</span><span class="n">loss_history</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">loss_history</span><span class="p">[</span><span class="mi">1</span><span class="p">:])</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Epoch&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;MSE Loss&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">semilogy</span><span class="p">()</span>
    
<span class="n">plot_loss</span><span class="p">(</span><span class="n">loss_history</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/chapter2_44_0.png" src="../_images/chapter2_44_0.png" />
</div>
</div>
</section>
<section id="what-did-the-network-actually-learn-though">
<h3>What did the network actually learn though?<a class="headerlink" href="#what-did-the-network-actually-learn-though" title="Permalink to this headline">#</a></h3>
<p>Looking at the loss curve, we can see that the model was able to reduce the loss over a number of epochs, and then started to oscillate in it’s performance. It’s most certainly possible that the model could be trained to a better overall loss value, but in the interest of conciseness we leave these as possible exercises. Getting back to the question at hand, our network was evaluated on how it was able to predict the next timestep’s storage, but we were interested in getting the reservoir conductivity function, <span class="math notranslate nohighlight">\(K(S)\)</span>, out. Lucky for us, we can just pull it out with <code class="docutils literal notranslate"><span class="pre">model.K</span></code> and start inputting storage values. Let’s see how we did!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">plot_conductivity</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">v</span><span class="p">):</span>
    <span class="n">dtype</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">float32</span>
    <span class="n">model_k</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">K</span>
    <span class="n">yhat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">([</span><span class="n">to_np</span><span class="p">(</span><span class="n">model_k</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">vv</span><span class="p">])))</span> <span class="k">for</span> <span class="n">vv</span> <span class="ow">in</span> <span class="n">v</span><span class="p">])</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
        <span class="n">all_initial_conds</span><span class="p">,</span> 
        <span class="n">kx</span><span class="p">(</span><span class="n">all_initial_conds</span><span class="p">),</span> 
        <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">,</span> 
        <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;D&#39;</span><span class="p">,</span> 
        <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Training points&#39;</span><span class="p">,</span> 
        <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span>
    <span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">kx</span><span class="p">(</span><span class="n">v</span><span class="p">),</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;target&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">yhat</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;crimson&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;neural net&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Storage (S)&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Reservoir conductivity (K)&#39;</span><span class="p">)</span>
    
<span class="n">v</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mf">0.001</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>
<span class="n">plot_conductivity</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/chapter2_46_0.png" src="../_images/chapter2_46_0.png" />
</div>
</div>
</section>
<section id="introducing-torchdiffeq">
<h3>Introducing <code class="docutils literal notranslate"><span class="pre">torchdiffeq</span></code><a class="headerlink" href="#introducing-torchdiffeq" title="Permalink to this headline">#</a></h3>
<p>Now that you see how we can solve differential equations <em>inside</em> of neural networks and still train them it’s time to move beyond home-grown solutions. As solving differential equations is quite difficult to get right and the basic methods tend to break down on harder problems mathematicians, scientists, and software engineers have spent a great deal of time developing packages and methods that can be taken “off the shelf”. The <code class="docutils literal notranslate"><span class="pre">torchdiffeq</span></code> package (<a class="reference external" href="https://github.com/rtqichen/torchdiffeq">https://github.com/rtqichen/torchdiffeq</a>) developed in recent years allows for many of these numerical solvers to be integrated seamlessly with PyTorch (<strong>Chen et al., 2017</strong>). We can reframe the previous problem of estimating the reservoir constant using this new package quite easily.</p>
<p>To do so, we first package up the ODE in a new <code class="docutils literal notranslate"><span class="pre">nn.Module</span></code> subclass, whose <code class="docutils literal notranslate"><span class="pre">forward</span></code> method simply implements the right hand side of the reservoir equation:</p>
<div class="math notranslate nohighlight">
\[
\frac{dS}{dt} = K(S)\cdot S
\]</div>
<p>The constructor on the <code class="docutils literal notranslate"><span class="pre">ReservoirEquation</span></code> class takes in a <code class="docutils literal notranslate"><span class="pre">K</span></code> parameter which we will represent with a multilayer perceptron as before.  Then, we create a new class, <code class="docutils literal notranslate"><span class="pre">TorchDiffEqNeuralReservoir</span></code>, which solves the <code class="docutils literal notranslate"><span class="pre">ReservoirEquation</span></code> via the new <code class="docutils literal notranslate"><span class="pre">odeint</span></code> function which we just imported. There are some extra details here, such as the <code class="docutils literal notranslate"><span class="pre">solver_method</span></code> and <code class="docutils literal notranslate"><span class="pre">integration_time</span></code> which we will not cover directly here, but are explained in the <code class="docutils literal notranslate"><span class="pre">torchdiffeq</span></code> documentation at the link given above.</p>
<p>Anyhow, as you can see the training procedure is nearly identical to before, as is the training time. Similarly, the extracted conductivity curve still looks reasonably close to the target, though it differs qualitatively from the out previous model simply due to the randomness in the training process.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">torchdiffeq</span> <span class="kn">import</span> <span class="n">odeint</span>

<span class="k">class</span> <span class="nc">ReservoirEquation</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">K</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">K</span> <span class="o">=</span> <span class="n">K</span>
            
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span>  <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">K</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">*</span> <span class="n">x</span>


<span class="k">class</span> <span class="nc">TorchDiffEqNeuralReservoir</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">width</span><span class="p">,</span> <span class="n">depth</span><span class="p">,</span> <span class="n">solver_method</span><span class="o">=</span><span class="s1">&#39;implicit_adams&#39;</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">K</span> <span class="o">=</span> <span class="n">MLP</span><span class="p">(</span><span class="n">width</span><span class="p">,</span> <span class="n">depth</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">res</span> <span class="o">=</span> <span class="n">ReservoirEquation</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">K</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">time</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">method</span> <span class="o">=</span> <span class="n">solver_method</span>
        
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">S_all</span> <span class="o">=</span> <span class="n">odeint</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">res</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">time</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">method</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">S_all</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
 
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">TorchDiffEqNeuralReservoir</span><span class="p">(</span><span class="n">width</span><span class="p">,</span> <span class="n">depth</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">loss_fun</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">()</span>
<span class="n">opt</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>

<span class="n">loss_history</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">max_epochs</span><span class="p">)):</span>
    <span class="n">train_loss</span> <span class="o">=</span> <span class="n">epoch</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span> <span class="n">train_Y</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">loss_fun</span><span class="p">,</span> <span class="n">opt</span><span class="p">)</span>
    <span class="n">loss_history</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">train_loss</span><span class="p">)</span>

<span class="n">v</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mf">0.001</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>
<span class="n">plot_conductivity</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "a4dcae7c9baf421c814b71434e39f97a", "version_major": 2, "version_minor": 0}
</script><img alt="../_images/chapter2_49_1.png" src="../_images/chapter2_49_1.png" />
</div>
</div>
</section>
</section>
<section id="scaling-up-to-a-conceptual-hydrologic-model">
<h2>Scaling up to a conceptual hydrologic model<a class="headerlink" href="#scaling-up-to-a-conceptual-hydrologic-model" title="Permalink to this headline">#</a></h2>
<section id="the-system-of-equations">
<h3>The system of equations<a class="headerlink" href="#the-system-of-equations" title="Permalink to this headline">#</a></h3>
<p>Now we have a working way to train differential equations parameterized by neural networks. It’s time to move to something a bit more useful than the nonlinear reservoir example. We will develop a relatively simple conceptual hydrologic model with two storage buckets. We will allow drainage from the “surface” bucket to the “subsurface” bucket as well as “evapotranspiration” to come from the “surface” bucket. Streamflow will be considered the sum of the outflow of the two buckets. In mathematical terms we can write this as a system of equations:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\frac{d}{dt} \begin{pmatrix}
S_{0}\\
S_{1}
\end{pmatrix} = 
\begin{pmatrix}
 P - ET - D - Q_{0} \\
 D - Q_{1}
\end{pmatrix}
\end{split}\]</div>
<p>Where <span class="math notranslate nohighlight">\(S_{0}\)</span> is the “surface” bucket, <span class="math notranslate nohighlight">\(S_{1}\)</span> is the “subsurface” bucket, <span class="math notranslate nohighlight">\(P\)</span> is precipitation, <span class="math notranslate nohighlight">\(ET\)</span> is evapotranspiration, <span class="math notranslate nohighlight">\(D\)</span> is drainage from the surface to the subsurface, and <span class="math notranslate nohighlight">\(Q_{0}\)</span>/<span class="math notranslate nohighlight">\(Q_{1}\)</span> are the surface/subsurface discharge. Before defining how each of these calculations is done explicitly we will also define the following terminology for how certain parameters are handled:</p>
<div class="math notranslate nohighlight">
\[
\left.\sigma\right|_{b}^{a}(x) = (a - b) \cdot \sigma(x) + b
\]</div>
<p>where <span class="math notranslate nohighlight">\(x\)</span> is the name of the parameter, <span class="math notranslate nohighlight">\(\sigma\)</span> is the sigmoid function, and <span class="math notranslate nohighlight">\(a\)</span> and <span class="math notranslate nohighlight">\(b\)</span> are the bounds of the parameter with <span class="math notranslate nohighlight">\(a&gt;b\)</span>. This operation allows us to train the parameters, but not have to strictly constrain them to be roughly on the <span class="math notranslate nohighlight">\(\pm 1\)</span> range. Essentially this is the sigmoid function scaled between <span class="math notranslate nohighlight">\(a\)</span> and <span class="math notranslate nohighlight">\(b\)</span> and is employed so that all underlying trainable parameters fall on the same range but can be translated to hydrologically relevant values. We implement this as the <code class="docutils literal notranslate"><span class="pre">HydroParam</span></code> module:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">HydroParam</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">low</span><span class="p">,</span> <span class="n">high</span><span class="p">,</span> <span class="n">net</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="c1"># `register_buffer` assigns variables which can be</span>
        <span class="c1"># used in training, but are not meant to be trainable values</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s1">&#39;low&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">low</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s1">&#39;high&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">high</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s1">&#39;range&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">high</span><span class="o">-</span><span class="n">low</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">net</span> <span class="o">=</span> <span class="n">net</span>
        
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">range</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">low</span>
    
</pre></div>
</div>
</div>
</div>
<p>To parameterize each of these terms we will follow some conventional approaches, namely a set of relations described in the Framework for Understanding Structural Errors (FUSE) model (<strong>Clark et al., 2008</strong>). Namely we will calculate ET as:</p>
<div class="math notranslate nohighlight">
\[
ET = \left.\sigma\right|_0^1(p) \cdot PET \cdot \left( 
         \frac{S_{0}}
         {\left.\sigma\right|_{1}^{100}(S_{0, max})} 
     \right)
\]</div>
<p>where <span class="math notranslate nohighlight">\(p\)</span> is the tunable parameter, and <span class="math notranslate nohighlight">\(PET\)</span> is the reference potential evapotranspiration. We implement this equation via the <code class="docutils literal notranslate"><span class="pre">ETTerm</span></code>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">ETTerm</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">S0max</span><span class="p">,</span> <span class="n">p</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">S0max</span> <span class="o">=</span> <span class="n">S0max</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">p</span> <span class="o">=</span> <span class="n">p</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s1">&#39;z&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">0.0</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">))</span>
        
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">S0</span><span class="p">,</span> <span class="n">pet</span><span class="p">):</span>
        <span class="n">S0max_val</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">S0max</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">p_val</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">p</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">et</span> <span class="o">=</span> <span class="n">p_val</span> <span class="o">*</span> <span class="n">pet</span> <span class="o">*</span> <span class="p">(</span><span class="n">S0</span> <span class="o">/</span> <span class="n">S0max_val</span><span class="p">)</span>
        <span class="n">et</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="n">et</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">z</span><span class="p">,</span> <span class="n">S0</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">et</span>
    
</pre></div>
</div>
</div>
</div>
<p>Drainage is calculated as:</p>
<div class="math notranslate nohighlight">
\[
D = \left.\sigma\right|_{0.01}^{100}(k_{u}) 
    \cdot \left( \frac{S_{0}}{\left.\sigma\right|_{1}^{100}(S_{0, max})} \right) 
    ^ {\left.\sigma\right|_{0.01}^{10}(c)}
\]</div>
<p>where <span class="math notranslate nohighlight">\(k_u\)</span> and <span class="math notranslate nohighlight">\(c\)</span> are tunable parameters. We implement this as the <code class="docutils literal notranslate"><span class="pre">DrainageTerm</span></code>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">DrainageTerm</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">S0max</span><span class="p">,</span> <span class="n">ku</span><span class="p">,</span> <span class="n">c</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">S0max</span> <span class="o">=</span> <span class="n">S0max</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ku</span> <span class="o">=</span> <span class="n">ku</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">c</span> <span class="o">=</span> <span class="n">c</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s1">&#39;z&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">0.0</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">))</span>
        
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">S0</span><span class="p">):</span>
        <span class="n">S0max_val</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">S0max</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">ku_val</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ku</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">c_val</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">c</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">drainage</span> <span class="o">=</span> <span class="n">ku_val</span> <span class="o">*</span> <span class="p">(</span><span class="n">S0</span> <span class="o">/</span> <span class="n">S0max_val</span><span class="p">)</span> <span class="o">**</span> <span class="n">c_val</span>
        <span class="n">drainage</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="n">drainage</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">z</span><span class="p">,</span> <span class="n">S0</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">drainage</span>
    
</pre></div>
</div>
</div>
</div>
<p>Surface flow <span class="math notranslate nohighlight">\(Q_{0}\)</span> is calculated by estimating the saturated fraction (<span class="math notranslate nohighlight">\(A_{sat}\)</span>) as:</p>
<div class="math notranslate nohighlight">
\[
A_{sat} = 1 - \left(1 -  \frac{S_{0}}{
         \left.\sigma\right|_{1}^{100}(S_{0, max})
} \right) ^{\left.\sigma\right|_{0.001}^{3.0}(b)}
\]</div>
<p>And the implementation via the <code class="docutils literal notranslate"><span class="pre">SaturatedAreaTerm</span></code> class:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">SaturatedAreaTerm</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">S0max</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">S0max</span> <span class="o">=</span> <span class="n">S0max</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">b</span> <span class="o">=</span> <span class="n">b</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s1">&#39;z&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">0.0</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">))</span>
        
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">S0</span><span class="p">):</span>
        <span class="n">S0max_val</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">S0max</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">b_val</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">b</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">ratio</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span>
            <span class="n">S0</span> <span class="o">/</span> <span class="n">S0max_val</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">z</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">z</span> <span class="o">+</span> <span class="mi">1</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="mi">1</span> <span class="o">-</span> <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">ratio</span><span class="p">)</span> <span class="o">**</span> <span class="n">b_val</span>
    
</pre></div>
</div>
</div>
</div>
<p>The surface flow is simply calculated by multiplying the surface saturation by the incoming precipitation:</p>
<div class="math notranslate nohighlight">
\[
Q_{0} = A_{sat} \cdot P
\]</div>
<p>And the implementation via the <code class="docutils literal notranslate"><span class="pre">SurfaceFlowTerm</span></code> class:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">SurfaceFlowTerm</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">a_sat</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">a_sat</span> <span class="o">=</span> <span class="n">a_sat</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s1">&#39;z&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">0.0</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">))</span>
        
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">S0</span><span class="p">,</span> <span class="n">prcp</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">a_sat</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">S0</span><span class="p">)</span> <span class="o">*</span> <span class="n">prcp</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">z</span><span class="p">)</span>
    
</pre></div>
</div>
</div>
</div>
<p>Finally, we define the subsurface flow as:</p>
<div class="math notranslate nohighlight">
\[
Q_{1} = \left. \sigma \right|_{0.001}^{10}(k_s) \cdot \left( \frac{S_1}
         {\left.\sigma\right|_{1}^{100}(S_{1, max})} 
         \right) ^ {\left. \sigma\right|_{0.01}^{10}(n)}
\]</div>
<p>And the implementation viat the <code class="docutils literal notranslate"><span class="pre">SubsurfaceFlowTerm</span></code> class:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">SubsurfaceFlowTerm</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">S1max</span><span class="p">,</span> <span class="n">ks</span><span class="p">,</span> <span class="n">n</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">S1max</span> <span class="o">=</span> <span class="n">S1max</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ks</span> <span class="o">=</span> <span class="n">ks</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n</span> <span class="o">=</span> <span class="n">n</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">z</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>
        
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">S1</span><span class="p">):</span>
        <span class="n">ks_val</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ks</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">S1max_val</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">S1max</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">n_val</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">subsurf_flow</span> <span class="o">=</span> <span class="n">ks_val</span> <span class="o">*</span> <span class="p">(</span><span class="n">S1</span> <span class="o">/</span> <span class="n">S1max_val</span><span class="p">)</span> <span class="o">**</span> <span class="n">n_val</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="n">subsurf_flow</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">z</span><span class="p">,</span> <span class="n">S1max_val</span><span class="p">)</span>
    
</pre></div>
</div>
</div>
</div>
<p>This defines all of the necessary fluxes for our conceptual hydrologic model! The model structure as defined here was taken from <strong>Clark et al. (2008)</strong> and was designed to be somewhat analogous to a simplified Variable Infiltration Capacity (VIC, <strong>Liang et al., 1994</strong>) type model, though lacking clear energy and water balance interaction terms as well as the obvious omission of snow and vegetation processes beyond a simple “lumped” ET quantity. The implementation of this is all wrapped into our <code class="docutils literal notranslate"><span class="pre">HydroEquation</span></code> class, as follows below. You’ll note here that there are not any user-definable parameters, everything is learned! You might consider the ranges allowed on the parameter values as hyperparameter, but we will not consider trying to tune them specifically here.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">HydroEquation</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">S0max</span><span class="p">,</span> <span class="n">S1max</span><span class="p">,</span>
        <span class="n">p</span><span class="p">,</span> <span class="n">ku</span><span class="p">,</span> <span class="n">ks</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">n</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">S0max</span> <span class="o">=</span> <span class="n">S0max</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">S1max</span> <span class="o">=</span> <span class="n">S1max</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">p</span> <span class="o">=</span> <span class="n">p</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ku</span> <span class="o">=</span> <span class="n">ku</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ks</span> <span class="o">=</span> <span class="n">ks</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">c</span> <span class="o">=</span> <span class="n">c</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">b</span> <span class="o">=</span> <span class="n">b</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n</span> <span class="o">=</span> <span class="n">n</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">et_term</span> <span class="o">=</span> <span class="n">ETTerm</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">S0max</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">p</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">drainage_term</span> <span class="o">=</span> <span class="n">DrainageTerm</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">S0max</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">ku</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">c</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">saturated_area_term</span> <span class="o">=</span> <span class="n">SaturatedAreaTerm</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">S0max</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">b</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">surface_flow_term</span> <span class="o">=</span> <span class="n">SurfaceFlowTerm</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">saturated_area_term</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">subsurf_flow_term</span> <span class="o">=</span> <span class="n">SubsurfaceFlowTerm</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">S1max</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">ks</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">storage</span><span class="p">):</span>
        <span class="n">S0</span><span class="p">,</span> <span class="n">S1</span> <span class="o">=</span> <span class="n">storage</span>
        <span class="n">pet</span><span class="p">,</span> <span class="n">prcp</span><span class="p">,</span> <span class="o">*</span><span class="n">attrs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">forcing</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">attrs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">et</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">et_term</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">S1</span><span class="p">,</span> <span class="n">pet</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">drainage</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">drainage_term</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">S0</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">surface_flow</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">surface_flow_term</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">S0</span><span class="p">,</span> <span class="n">prcp</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">subsurf_flow</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">subsurf_flow_term</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">S1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">qtotal</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">surface_flow</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">subsurf_flow</span><span class="p">)</span>
            
        <span class="c1"># Clamping enforces mass balance</span>
        <span class="n">dS0_dt</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span>
            <span class="n">prcp</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">et</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">drainage</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">surface_flow</span><span class="p">,</span>
            <span class="nb">min</span><span class="o">=-</span><span class="n">S0</span><span class="p">,</span>
            <span class="nb">max</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">S0max</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">-</span> <span class="n">S0</span>
        <span class="p">)</span>
        <span class="n">dS1_dt</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">drainage</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">subsurf_flow</span><span class="p">,</span>
            <span class="nb">min</span><span class="o">=-</span><span class="n">S1</span><span class="p">,</span>
            <span class="nb">max</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">S1max</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">-</span> <span class="n">S1</span>
        <span class="p">)</span>
        <span class="n">dS_dt</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">hstack</span><span class="p">([</span><span class="n">dS0_dt</span><span class="p">,</span> <span class="n">dS1_dt</span><span class="p">])</span>
        <span class="k">return</span> <span class="n">dS_dt</span>       
</pre></div>
</div>
</div>
</div>
<p>As in the nonlinear reservoir network here we will also wrap up the <code class="docutils literal notranslate"><span class="pre">HydroEquation</span></code> class so that it’s easier to extract what we want out of the solution to the ODE system. We’ll call this the <code class="docutils literal notranslate"><span class="pre">HydroSimulator</span></code> since it solves the <code class="docutils literal notranslate"><span class="pre">HydroEquation</span></code> but allows us to see the time-evolution of the system by recording all of the necessary fluxes and states along the way.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">HydroSimulator</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">S0max</span><span class="p">,</span> <span class="n">S1max</span><span class="p">,</span>
        <span class="n">p</span><span class="p">,</span> <span class="n">ku</span><span class="p">,</span> <span class="n">ks</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span>
        <span class="n">method</span><span class="o">=</span><span class="s1">&#39;euler&#39;</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">method</span> <span class="o">=</span> <span class="n">method</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s1">&#39;t&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ode</span> <span class="o">=</span> <span class="n">HydroEquation</span><span class="p">(</span>
            <span class="n">S0max</span><span class="p">,</span> <span class="n">S1max</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">ku</span><span class="p">,</span>
            <span class="n">ks</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">n</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">forcing</span><span class="p">,</span> <span class="n">storage</span><span class="p">):</span>
        <span class="n">qtotal</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">storage_ts</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">surf_flow</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">subsurf_flow</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">drainage</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">et</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">forcing</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">ode</span><span class="o">.</span><span class="n">forcing</span> <span class="o">=</span> <span class="n">f</span>
            <span class="n">storage</span> <span class="o">=</span> <span class="n">odeint</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ode</span><span class="p">,</span> <span class="n">storage</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">t</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">method</span><span class="p">)</span>
            <span class="n">storage</span> <span class="o">=</span> <span class="n">storage</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
            <span class="n">storage_ts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">storage</span><span class="p">)</span>
            <span class="n">qtotal</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ode</span><span class="o">.</span><span class="n">qtotal</span><span class="p">)</span>
            <span class="n">surf_flow</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ode</span><span class="o">.</span><span class="n">surface_flow</span><span class="p">)</span>
            <span class="n">subsurf_flow</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ode</span><span class="o">.</span><span class="n">subsurf_flow</span><span class="p">)</span>
            <span class="n">drainage</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ode</span><span class="o">.</span><span class="n">drainage</span><span class="p">)</span>
            <span class="n">et</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ode</span><span class="o">.</span><span class="n">et</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">end_storage</span> <span class="o">=</span> <span class="n">storage</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">storage_ts</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">storage_ts</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">surface_flow</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">surf_flow</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">subsurface_flow</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">subsurf_flow</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">drainage</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">drainage</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">et</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">et</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">qtotal</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="data">
<h3>Data<a class="headerlink" href="#data" title="Permalink to this headline">#</a></h3>
<p>With the overall model structure out of the way we come to the real fork in the road - data! So far we’ve been working with synthetic data, or just idealized situations. But as hydrologists &amp; Earth systems modelers we cannot live in fantasy land, so eventually must be confronted by the real world. This means we need some basic infrastructure for training (aka calibrating) the model structure we’ve designed against something closer to reality. This requires two basic components. First, the actual raw data - for this, we’ll use a subset of the CAMELS dataset (<strong>Newman et al., 2015; Addor et al., 2017</strong>). For this chapter we will only train for a single basin, but we include data for multiple basins for you to explore. The CAMELS dataset contains a wide range of hydroclimatic conditions in basins which are minimally impacted by human infrastructure and have long records of streamflow observations.</p>
<p>As our model contains no explicit store for snow we will take some time to filter out basins where snowpack is a dominant factor. However, since we don’t have actual observed snow data for these basins to filter with we will use daily minimum temperature as a proxy. To do so, we simply filter out any basins where the 10th percentile of daily minimum temperature during the winter months is below 0 degrees C. The code below opens up the provided NetCDF dataset via xarray and converts all of the data to <code class="docutils literal notranslate"><span class="pre">float32</span></code>, which is done to improve memory usage and computational speed. We then calculate the winter low temperatures using a <code class="docutils literal notranslate"><span class="pre">groupby</span></code> approach, which allows us to concisely find which basins whic hmeet the criteria specified earlier. We then do so using the <code class="docutils literal notranslate"><span class="pre">.where</span></code> method, and finally select the basins we want using the <code class="docutils literal notranslate"><span class="pre">.sel</span></code> method. As you can see the final dataset printed out still has 131 basins, each with 10 water years of data.</p>
<p>This dataset contains a number of pre-run results from other hydrologic models, forcing variables such as daylength (<code class="docutils literal notranslate"><span class="pre">dayl</span></code>), precipitation (<code class="docutils literal notranslate"><span class="pre">prcp</span></code>), daily minimum and maximum temperatures (<code class="docutils literal notranslate"><span class="pre">Tmin</span></code> and <code class="docutils literal notranslate"><span class="pre">Tmax</span></code>), and potential evapotranspiration (<code class="docutils literal notranslate"><span class="pre">pet</span></code>) among others. Additionally there are a number of basin specific attributes such as basin area (<code class="docutils literal notranslate"><span class="pre">area</span></code>), basin average elevation (<code class="docutils literal notranslate"><span class="pre">elevation</span></code>), and aridity (<code class="docutils literal notranslate"><span class="pre">aridity</span></code>).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ds</span> <span class="o">=</span> <span class="n">xr</span><span class="o">.</span><span class="n">open_dataset</span><span class="p">(</span><span class="s1">&#39;./data/camels_data.nc&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">load</span><span class="p">()</span>
<span class="n">low_temp</span> <span class="o">=</span> <span class="p">(</span><span class="n">ds</span><span class="p">[</span><span class="s1">&#39;Tmin&#39;</span><span class="p">]</span>                        <span class="c1"># Select daily min temp</span>
              <span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="n">ds</span><span class="p">[</span><span class="s1">&#39;time&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">dt</span><span class="o">.</span><span class="n">season</span><span class="p">)</span>  <span class="c1"># Group it into seasons</span>
              <span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="n">q</span><span class="o">=</span><span class="mf">0.10</span><span class="p">)</span>               <span class="c1"># Get the 10th %-ile value</span>
              <span class="o">.</span><span class="n">sel</span><span class="p">(</span><span class="n">season</span><span class="o">=</span><span class="s1">&#39;DJF&#39;</span><span class="p">))</span>             <span class="c1"># Grab winter month vals</span>

<span class="c1"># Select only the basins where the winter lows are above 0C.</span>
<span class="n">warm_basins</span> <span class="o">=</span> <span class="n">ds</span><span class="p">[</span><span class="s1">&#39;hru&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">low_temp</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">ds</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">sel</span><span class="p">(</span><span class="n">hru</span><span class="o">=</span><span class="n">warm_basins</span><span class="p">)</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="s1">&#39;quantile&#39;</span><span class="p">,</span> <span class="s1">&#39;season&#39;</span><span class="p">])</span>
<span class="n">ds</span><span class="p">[</span><span class="s1">&#39;elevation&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">ds</span><span class="p">[</span><span class="s1">&#39;elevation&#39;</span><span class="p">]</span> <span class="o">/</span> <span class="mi">1000</span>
<span class="n">ds</span><span class="p">[</span><span class="s1">&#39;area&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">ds</span><span class="p">[</span><span class="s1">&#39;area&#39;</span><span class="p">]</span> <span class="o">/</span> <span class="mi">1000</span>
<span class="n">ds</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div><svg style="position: absolute; width: 0; height: 0; overflow: hidden">
<defs>
<symbol id="icon-database" viewBox="0 0 32 32">
<path d="M16 0c-8.837 0-16 2.239-16 5v4c0 2.761 7.163 5 16 5s16-2.239 16-5v-4c0-2.761-7.163-5-16-5z"></path>
<path d="M16 17c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z"></path>
<path d="M16 26c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z"></path>
</symbol>
<symbol id="icon-file-text2" viewBox="0 0 32 32">
<path d="M28.681 7.159c-0.694-0.947-1.662-2.053-2.724-3.116s-2.169-2.030-3.116-2.724c-1.612-1.182-2.393-1.319-2.841-1.319h-15.5c-1.378 0-2.5 1.121-2.5 2.5v27c0 1.378 1.122 2.5 2.5 2.5h23c1.378 0 2.5-1.122 2.5-2.5v-19.5c0-0.448-0.137-1.23-1.319-2.841zM24.543 5.457c0.959 0.959 1.712 1.825 2.268 2.543h-4.811v-4.811c0.718 0.556 1.584 1.309 2.543 2.268zM28 29.5c0 0.271-0.229 0.5-0.5 0.5h-23c-0.271 0-0.5-0.229-0.5-0.5v-27c0-0.271 0.229-0.5 0.5-0.5 0 0 15.499-0 15.5 0v7c0 0.552 0.448 1 1 1h7v19.5z"></path>
<path d="M23 26h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z"></path>
<path d="M23 22h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z"></path>
<path d="M23 18h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z"></path>
</symbol>
</defs>
</svg>
<style>/* CSS stylesheet for displaying xarray objects in jupyterlab.
 *
 */

:root {
  --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1));
  --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54));
  --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38));
  --xr-border-color: var(--jp-border-color2, #e0e0e0);
  --xr-disabled-color: var(--jp-layout-color3, #bdbdbd);
  --xr-background-color: var(--jp-layout-color0, white);
  --xr-background-color-row-even: var(--jp-layout-color1, white);
  --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee);
}

html[theme=dark],
body.vscode-dark {
  --xr-font-color0: rgba(255, 255, 255, 1);
  --xr-font-color2: rgba(255, 255, 255, 0.54);
  --xr-font-color3: rgba(255, 255, 255, 0.38);
  --xr-border-color: #1F1F1F;
  --xr-disabled-color: #515151;
  --xr-background-color: #111111;
  --xr-background-color-row-even: #111111;
  --xr-background-color-row-odd: #313131;
}

.xr-wrap {
  display: block !important;
  min-width: 300px;
  max-width: 700px;
}

.xr-text-repr-fallback {
  /* fallback to plain text repr when CSS is not injected (untrusted notebook) */
  display: none;
}

.xr-header {
  padding-top: 6px;
  padding-bottom: 6px;
  margin-bottom: 4px;
  border-bottom: solid 1px var(--xr-border-color);
}

.xr-header > div,
.xr-header > ul {
  display: inline;
  margin-top: 0;
  margin-bottom: 0;
}

.xr-obj-type,
.xr-array-name {
  margin-left: 2px;
  margin-right: 10px;
}

.xr-obj-type {
  color: var(--xr-font-color2);
}

.xr-sections {
  padding-left: 0 !important;
  display: grid;
  grid-template-columns: 150px auto auto 1fr 20px 20px;
}

.xr-section-item {
  display: contents;
}

.xr-section-item input {
  display: none;
}

.xr-section-item input + label {
  color: var(--xr-disabled-color);
}

.xr-section-item input:enabled + label {
  cursor: pointer;
  color: var(--xr-font-color2);
}

.xr-section-item input:enabled + label:hover {
  color: var(--xr-font-color0);
}

.xr-section-summary {
  grid-column: 1;
  color: var(--xr-font-color2);
  font-weight: 500;
}

.xr-section-summary > span {
  display: inline-block;
  padding-left: 0.5em;
}

.xr-section-summary-in:disabled + label {
  color: var(--xr-font-color2);
}

.xr-section-summary-in + label:before {
  display: inline-block;
  content: '►';
  font-size: 11px;
  width: 15px;
  text-align: center;
}

.xr-section-summary-in:disabled + label:before {
  color: var(--xr-disabled-color);
}

.xr-section-summary-in:checked + label:before {
  content: '▼';
}

.xr-section-summary-in:checked + label > span {
  display: none;
}

.xr-section-summary,
.xr-section-inline-details {
  padding-top: 4px;
  padding-bottom: 4px;
}

.xr-section-inline-details {
  grid-column: 2 / -1;
}

.xr-section-details {
  display: none;
  grid-column: 1 / -1;
  margin-bottom: 5px;
}

.xr-section-summary-in:checked ~ .xr-section-details {
  display: contents;
}

.xr-array-wrap {
  grid-column: 1 / -1;
  display: grid;
  grid-template-columns: 20px auto;
}

.xr-array-wrap > label {
  grid-column: 1;
  vertical-align: top;
}

.xr-preview {
  color: var(--xr-font-color3);
}

.xr-array-preview,
.xr-array-data {
  padding: 0 5px !important;
  grid-column: 2;
}

.xr-array-data,
.xr-array-in:checked ~ .xr-array-preview {
  display: none;
}

.xr-array-in:checked ~ .xr-array-data,
.xr-array-preview {
  display: inline-block;
}

.xr-dim-list {
  display: inline-block !important;
  list-style: none;
  padding: 0 !important;
  margin: 0;
}

.xr-dim-list li {
  display: inline-block;
  padding: 0;
  margin: 0;
}

.xr-dim-list:before {
  content: '(';
}

.xr-dim-list:after {
  content: ')';
}

.xr-dim-list li:not(:last-child):after {
  content: ',';
  padding-right: 5px;
}

.xr-has-index {
  font-weight: bold;
}

.xr-var-list,
.xr-var-item {
  display: contents;
}

.xr-var-item > div,
.xr-var-item label,
.xr-var-item > .xr-var-name span {
  background-color: var(--xr-background-color-row-even);
  margin-bottom: 0;
}

.xr-var-item > .xr-var-name:hover span {
  padding-right: 5px;
}

.xr-var-list > li:nth-child(odd) > div,
.xr-var-list > li:nth-child(odd) > label,
.xr-var-list > li:nth-child(odd) > .xr-var-name span {
  background-color: var(--xr-background-color-row-odd);
}

.xr-var-name {
  grid-column: 1;
}

.xr-var-dims {
  grid-column: 2;
}

.xr-var-dtype {
  grid-column: 3;
  text-align: right;
  color: var(--xr-font-color2);
}

.xr-var-preview {
  grid-column: 4;
}

.xr-var-name,
.xr-var-dims,
.xr-var-dtype,
.xr-preview,
.xr-attrs dt {
  white-space: nowrap;
  overflow: hidden;
  text-overflow: ellipsis;
  padding-right: 10px;
}

.xr-var-name:hover,
.xr-var-dims:hover,
.xr-var-dtype:hover,
.xr-attrs dt:hover {
  overflow: visible;
  width: auto;
  z-index: 1;
}

.xr-var-attrs,
.xr-var-data {
  display: none;
  background-color: var(--xr-background-color) !important;
  padding-bottom: 5px !important;
}

.xr-var-attrs-in:checked ~ .xr-var-attrs,
.xr-var-data-in:checked ~ .xr-var-data {
  display: block;
}

.xr-var-data > table {
  float: right;
}

.xr-var-name span,
.xr-var-data,
.xr-attrs {
  padding-left: 25px !important;
}

.xr-attrs,
.xr-var-attrs,
.xr-var-data {
  grid-column: 1 / -1;
}

dl.xr-attrs {
  padding: 0;
  margin: 0;
  display: grid;
  grid-template-columns: 125px auto;
}

.xr-attrs dt,
.xr-attrs dd {
  padding: 0;
  margin: 0;
  float: left;
  padding-right: 10px;
  width: auto;
}

.xr-attrs dt {
  font-weight: normal;
  grid-column: 1;
}

.xr-attrs dt:hover span {
  display: inline-block;
  background: var(--xr-background-color);
  padding-right: 10px;
}

.xr-attrs dd {
  grid-column: 2;
  white-space: pre-wrap;
  word-break: break-all;
}

.xr-icon-database,
.xr-icon-file-text2 {
  display: inline-block;
  vertical-align: middle;
  width: 1em;
  height: 1.5em !important;
  stroke-width: 0;
  stroke: currentColor;
  fill: currentColor;
}
</style><pre class='xr-text-repr-fallback'>&lt;xarray.Dataset&gt;
Dimensions:         (hru: 131, time: 3652)
Coordinates:
  * hru             (hru) int64 7292500 2342933 8158810 ... 2245500 2430085
  * time            (time) datetime64[ns] 1989-10-01 1989-10-02 ... 1999-09-30
Data variables: (12/25)
    QObs            (hru, time) float32 1.525 0.7277 0.4899 ... 0.1324 0.1384
    HBV_lb          (hru, time) float32 1.173 1.067 0.9227 ... 0.1385 0.1369
    HBV_ub          (hru, time) float32 1.183 0.9443 0.8918 ... 0.05157 0.05042
    SAC_SMA         (hru, time) float32 0.4151 0.4034 0.4005 ... 0.2743 0.2674
    VIC_basin       (hru, time) float32 2.532 1.31 0.7074 ... 0.1104 0.09831
    q_sim_fuse_900  (hru, time) float32 1.912 1.048 0.7786 ... 0.17 0.1467
    ...              ...
    frac_forest     (hru) float32 0.9468 0.9083 0.0548 ... 0.963 0.8235 0.8644
    p_mean          (hru) float32 4.256 3.815 2.509 2.232 ... 5.819 3.756 4.233
    pet_mean        (hru) float32 3.475 3.275 3.377 3.811 ... 2.838 3.81 2.947
    aridity         (hru) float32 0.8166 0.8586 1.346 ... 0.4877 1.014 0.6963
    Tavg            (hru, time) float32 21.31 22.92 24.86 ... 25.7 22.33 14.51
    pet             (hru, time) float32 3.207 5.699 5.843 ... 3.261 2.623 4.953</pre><div class='xr-wrap' style='display:none'><div class='xr-header'><div class='xr-obj-type'>xarray.Dataset</div></div><ul class='xr-sections'><li class='xr-section-item'><input id='section-225ebe34-7c28-412a-9023-de6236adaa26' class='xr-section-summary-in' type='checkbox' disabled ><label for='section-225ebe34-7c28-412a-9023-de6236adaa26' class='xr-section-summary'  title='Expand/collapse section'>Dimensions:</label><div class='xr-section-inline-details'><ul class='xr-dim-list'><li><span class='xr-has-index'>hru</span>: 131</li><li><span class='xr-has-index'>time</span>: 3652</li></ul></div><div class='xr-section-details'></div></li><li class='xr-section-item'><input id='section-209202b8-3f07-45f3-ba1d-82b4747c796d' class='xr-section-summary-in' type='checkbox'  checked><label for='section-209202b8-3f07-45f3-ba1d-82b4747c796d' class='xr-section-summary' >Coordinates: <span>(2)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>hru</span></div><div class='xr-var-dims'>(hru)</div><div class='xr-var-dtype'>int64</div><div class='xr-var-preview xr-preview'>7292500 2342933 ... 2245500 2430085</div><input id='attrs-b61f5c4d-7ab8-4ab4-b68c-e16753e8e0f9' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-b61f5c4d-7ab8-4ab4-b68c-e16753e8e0f9' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-310fa71a-931e-4743-8163-c86159f7bccd' class='xr-var-data-in' type='checkbox'><label for='data-310fa71a-931e-4743-8163-c86159f7bccd' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([ 7292500,  2342933,  8158810,  7315200,  7295000,  8202700,  2481510,
        8178880,  2395120, 14306500,  8164000,  8070200, 11532500, 11451100,
        2408540,  8155200,  8066200, 11141280,  8171300,  8165300,  8164300,
        2361000,  8014500,  2193340,  8190000,  8066300,  2298608,  7291000,
        2216180, 10259000,  2374500,  8189500, 14166500,  8103900, 12013500,
       11151300, 11284400, 14303200,  8050800,  8023080,  2469800,  7315700,
        8176900,  7362100, 11481200,  2363000,  2472000, 12043000,  2092500,
        8190500,  2472500,  2315500,  2296500,  2464360,  2198100,  2297310,
        2235200,  8086290, 11468500,  2371500,  8175000,  2479155,  2372250,
       11476600, 11478500, 14400000,  2212600,  2299950, 14305500,  8196000,
        2415000,  9508300, 11143000, 14306340, 12025000,  2297155,  2481000,
        8013000, 12040500,  8164600,  7290650,  2464000,  2221525, 12073500,
       12035000,  9512280,  9513780,  9484000, 11176400, 11124500,  2350900,
        8079600,  8198500, 11482500,  2464146,  2479560, 11473900,  2479300,
        7376000,  2298123,  2202600, 14325000,  2215100,  2102908,  8194200,
        8104900,  8150800,  8070000, 11475560, 11148900, 11162500,  9510200,
        2427250,  7373000,  9447800, 14309500,  7375000,  8109700,  2465493,
        2196000, 14362250,  7346045,  2246000,  8086212,  9484600,  2349900,
       12010000,  8101000, 14301000,  2245500,  2430085])</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>time</span></div><div class='xr-var-dims'>(time)</div><div class='xr-var-dtype'>datetime64[ns]</div><div class='xr-var-preview xr-preview'>1989-10-01 ... 1999-09-30</div><input id='attrs-a762f835-c139-49df-b15f-4bde97da8627' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-a762f835-c139-49df-b15f-4bde97da8627' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-23f29010-b5be-40a0-8df8-c0462df4a93a' class='xr-var-data-in' type='checkbox'><label for='data-23f29010-b5be-40a0-8df8-c0462df4a93a' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([&#x27;1989-10-01T00:00:00.000000000&#x27;, &#x27;1989-10-02T00:00:00.000000000&#x27;,
       &#x27;1989-10-03T00:00:00.000000000&#x27;, ..., &#x27;1999-09-28T00:00:00.000000000&#x27;,
       &#x27;1999-09-29T00:00:00.000000000&#x27;, &#x27;1999-09-30T00:00:00.000000000&#x27;],
      dtype=&#x27;datetime64[ns]&#x27;)</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-d6376ad9-4e11-4871-af96-5061590d154a' class='xr-section-summary-in' type='checkbox'  ><label for='section-d6376ad9-4e11-4871-af96-5061590d154a' class='xr-section-summary' >Data variables: <span>(25)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span>QObs</span></div><div class='xr-var-dims'>(hru, time)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>1.525 0.7277 ... 0.1324 0.1384</div><input id='attrs-a0da0bec-88ee-487d-ae23-a71d936a4eb9' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-a0da0bec-88ee-487d-ae23-a71d936a4eb9' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-c9665f49-31e1-40e6-aa76-fd8ca0bfd942' class='xr-var-data-in' type='checkbox'><label for='data-c9665f49-31e1-40e6-aa76-fd8ca0bfd942' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([[ 1.525 ,  0.7277,  0.4899, ...,  0.2486,  0.5416,  1.0243],
       [ 4.7336,  1.6285,  0.6581, ...,  0.0278,  0.0219,  0.0177],
       [ 0.    ,  0.    ,  0.    , ...,  0.    ,  0.    ,  0.    ],
       ...,
       [ 0.1318,  0.1403,  0.1261, ...,  0.1374,  0.1374,  0.1346],
       [ 2.0664,  1.4246,  1.0438, ...,  1.9817,  1.5163,  0.9521],
       [16.6133,  3.3106,  1.9864, ...,  0.1264,  0.1324,  0.1384]],
      dtype=float32)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>HBV_lb</span></div><div class='xr-var-dims'>(hru, time)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>1.173 1.067 ... 0.1385 0.1369</div><input id='attrs-c454b1c0-2d3c-420c-b4eb-d36f3f55dc42' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-c454b1c0-2d3c-420c-b4eb-d36f3f55dc42' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-078baefd-6cff-438e-bf39-49343e3c274d' class='xr-var-data-in' type='checkbox'><label for='data-078baefd-6cff-438e-bf39-49343e3c274d' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([[1.1732277 , 1.0668093 , 0.922691  , ..., 0.2184677 , 0.3045745 ,
        0.37006873],
       [1.8438152 , 2.2564352 , 2.084682  , ..., 0.20398037, 0.20235156,
        0.19880016],
       [0.04353404, 0.04275264, 0.04199876, ..., 0.05119828, 0.05038265,
        0.04959878],
       ...,
       [0.14138831, 0.14171295, 0.14012384, ..., 0.1719522 , 0.16893138,
        0.16607852],
       [1.8650454 , 1.8612905 , 1.7770017 , ..., 2.2404819 , 2.16955   ,
        1.88983   ],
       [4.6446013 , 4.3490405 , 3.5387397 , ..., 0.13999681, 0.13854413,
        0.13686155]], dtype=float32)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>HBV_ub</span></div><div class='xr-var-dims'>(hru, time)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>1.183 0.9443 ... 0.05157 0.05042</div><input id='attrs-0cbc6fa5-a427-478c-b5d7-8d7107aa2f9d' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-0cbc6fa5-a427-478c-b5d7-8d7107aa2f9d' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-8783f2ad-22b9-49b1-95dc-480207994110' class='xr-var-data-in' type='checkbox'><label for='data-8783f2ad-22b9-49b1-95dc-480207994110' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([[1.1827742 , 0.94425225, 0.8917579 , ..., 0.47654778, 0.48081917,
        0.4820289 ],
       [5.727309  , 3.9447038 , 1.200813  , ..., 0.30642113, 0.30192485,
        0.2973761 ],
       [0.05238058, 0.05094112, 0.04954331, ..., 0.06717253, 0.06525942,
        0.06340084],
       ...,
       [1.0915654 , 1.0886041 , 1.0843958 , ..., 1.1794578 , 1.1741726 ,
        1.1689323 ],
       [1.5170289 , 1.5039592 , 1.4400109 , ..., 1.699768  , 1.6795825 ,
        1.3397464 ],
       [6.838475  , 3.2784853 , 2.082744  , ..., 0.05011057, 0.05157239,
        0.05041706]], dtype=float32)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>SAC_SMA</span></div><div class='xr-var-dims'>(hru, time)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>0.4151 0.4034 ... 0.2743 0.2674</div><input id='attrs-6420bd21-81f7-4de8-9079-67089ec215f8' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-6420bd21-81f7-4de8-9079-67089ec215f8' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-b55dcc66-a0b8-488b-8bb9-304b4d03906e' class='xr-var-data-in' type='checkbox'><label for='data-b55dcc66-a0b8-488b-8bb9-304b4d03906e' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([[0.4151, 0.4034, 0.4005, ..., 0.308 , 0.317 , 0.2466],
       [8.1195, 1.9507, 0.7269, ..., 0.0856, 0.086 , 0.0817],
       [0.0573, 0.0572, 0.0571, ..., 0.0591, 0.0596, 0.0589],
       ...,
       [0.445 , 0.4408, 0.437 , ..., 0.5781, 0.5747, 0.5715],
       [1.5976, 1.5416, 1.4521, ..., 1.2835, 1.444 , 1.419 ],
       [7.6499, 2.1937, 1.6903, ..., 0.2787, 0.2743, 0.2674]],
      dtype=float32)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>VIC_basin</span></div><div class='xr-var-dims'>(hru, time)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>2.532 1.31 ... 0.1104 0.09831</div><input id='attrs-0ef57141-0540-48e3-835f-a7dee0eaf044' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-0ef57141-0540-48e3-835f-a7dee0eaf044' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-d048ab1b-b6b9-446b-bd66-175f35fc195a' class='xr-var-data-in' type='checkbox'><label for='data-d048ab1b-b6b9-446b-bd66-175f35fc195a' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([[2.5316603 , 1.3099518 , 0.7073785 , ..., 0.6165066 , 1.2071991 ,
        0.89594185],
       [7.1612086 , 4.3722725 , 2.0177977 , ..., 0.08130282, 0.04285068,
        0.02407086],
       [0.18345551, 0.18145551, 0.17997436, ..., 0.23264357, 0.23051323,
        0.22847159],
       ...,
       [0.49168628, 0.4905012 , 0.48397288, ..., 0.534549  , 0.5303376 ,
        0.5260858 ],
       [1.651127  , 1.4495255 , 1.1011438 , ..., 1.7176143 , 1.3402405 ,
        0.91884524],
       [7.036835  , 3.448694  , 1.6045144 , ..., 0.12147204, 0.11042105,
        0.09831201]], dtype=float32)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>q_sim_fuse_900</span></div><div class='xr-var-dims'>(hru, time)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>1.912 1.048 0.7786 ... 0.17 0.1467</div><input id='attrs-eab423d5-89cc-4a96-8bc1-8c83c8366388' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-eab423d5-89cc-4a96-8bc1-8c83c8366388' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-2a50732a-bda4-4d1c-b6e9-72fb01017090' class='xr-var-data-in' type='checkbox'><label for='data-2a50732a-bda4-4d1c-b6e9-72fb01017090' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([[1.9115833 , 1.0483276 , 0.7785752 , ..., 0.86044   , 1.345835  ,
        1.0652622 ],
       [5.3827143 , 3.4035218 , 1.3628743 , ..., 0.23439345, 0.15283047,
        0.10352625],
       [0.10436994, 0.10295364, 0.10156184, ..., 0.035221  , 0.03538835,
        0.03455446],
       ...,
       [0.7976768 , 0.7906209 , 0.758691  , ..., 0.9655678 , 0.9398599 ,
        0.92005754],
       [1.4731803 , 1.3717071 , 1.1840831 , ..., 1.8347287 , 1.60561   ,
        1.1278081 ],
       [7.005104  , 3.0108612 , 1.1682624 , ..., 0.14970626, 0.1700341 ,
        0.14665334]], dtype=float32)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>dayl</span></div><div class='xr-var-dims'>(hru, time)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>4.182e+04 4.182e+04 ... 4.182e+04</div><input id='attrs-c6bd9eec-7ad8-43a2-a7c1-3cbf54d676ad' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-c6bd9eec-7ad8-43a2-a7c1-3cbf54d676ad' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-d1df3fb1-f06d-422f-b5bb-ae3281674b04' class='xr-var-data-in' type='checkbox'><label for='data-d1df3fb1-f06d-422f-b5bb-ae3281674b04' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([[41817.6 , 41817.6 , 41817.6 , ..., 42163.2 , 42163.2 , 42163.2 ],
       [41817.6 , 41817.6 , 41817.6 , ..., 42163.2 , 42163.2 , 42163.2 ],
       [42163.2 , 41817.6 , 41817.6 , ..., 42508.8 , 42163.2 , 42163.2 ],
       ...,
       [41126.4 , 40780.8 , 40780.8 , ..., 41817.6 , 41472.  , 41438.63],
       [42163.2 , 41817.6 , 41817.6 , ..., 42508.8 , 42163.2 , 42163.2 ],
       [41817.6 , 41817.6 , 41472.  , ..., 42163.2 , 42163.2 , 41817.6 ]],
      dtype=float32)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>prcp</span></div><div class='xr-var-dims'>(hru, time)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>0.1 0.0 0.0 0.0 ... 0.46 2.14 0.0</div><input id='attrs-22ec8539-8554-4d28-9652-cbec08c9c3a7' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-22ec8539-8554-4d28-9652-cbec08c9c3a7' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-8f4565f1-f237-4f87-94f4-23b67c523031' class='xr-var-data-in' type='checkbox'><label for='data-8f4565f1-f237-4f87-94f4-23b67c523031' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([[1.000e-01, 0.000e+00, 0.000e+00, ..., 3.220e+00, 3.948e+01,
        2.000e-02],
       [5.390e+01, 2.300e-01, 0.000e+00, ..., 3.480e+00, 3.040e+00,
        0.000e+00],
       [0.000e+00, 0.000e+00, 9.000e-02, ..., 2.600e-01, 1.280e+00,
        0.000e+00],
       ...,
       [3.100e-01, 0.000e+00, 0.000e+00, ..., 4.000e-02, 3.600e-01,
        2.000e-02],
       [1.036e+01, 7.360e+00, 7.000e-02, ..., 9.060e+00, 2.000e-01,
        0.000e+00],
       [1.120e+01, 0.000e+00, 1.400e-01, ..., 4.600e-01, 2.140e+00,
        0.000e+00]], dtype=float32)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>srad</span></div><div class='xr-var-dims'>(hru, time)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>295.5 511.7 509.5 ... 235.5 519.8</div><input id='attrs-fe7771f1-4425-452d-854e-b6d6f7ff1bc5' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-fe7771f1-4425-452d-854e-b6d6f7ff1bc5' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-15e0ede9-d249-4f2b-a422-efaa7eaad763' class='xr-var-data-in' type='checkbox'><label for='data-15e0ede9-d249-4f2b-a422-efaa7eaad763' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([[295.49, 511.66, 509.54, ..., 317.47, 307.48, 535.6 ],
       [210.24, 498.67, 501.32, ..., 321.42, 317.11, 498.6 ],
       [470.88, 472.03, 438.85, ..., 478.39, 404.81, 554.38],
       ...,
       [289.28, 391.34, 397.22, ..., 400.31, 387.3 , 382.17],
       [323.79, 422.64, 516.47, ..., 383.73, 347.93, 438.24],
       [279.83, 484.58, 487.06, ..., 278.41, 235.5 , 519.76]],
      dtype=float32)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>swe</span></div><div class='xr-var-dims'>(hru, time)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0 0.0</div><input id='attrs-f21f2a07-b47f-4340-a201-91cc8e511f62' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-f21f2a07-b47f-4340-a201-91cc8e511f62' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-43ae3341-df1a-40aa-9ed0-41c95dc73fa1' class='xr-var-data-in' type='checkbox'><label for='data-43ae3341-df1a-40aa-9ed0-41c95dc73fa1' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([[0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],
       ...,
       [0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>Tmax</span></div><div class='xr-var-dims'>(hru, time)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>21.31 22.92 24.86 ... 22.33 14.51</div><input id='attrs-d03750a3-1ac3-4fe5-988e-b9e5bed9e9ef' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-d03750a3-1ac3-4fe5-988e-b9e5bed9e9ef' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-15e94f19-f4df-42fa-af08-2e106a882113' class='xr-var-data-in' type='checkbox'><label for='data-15e94f19-f4df-42fa-af08-2e106a882113' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([[21.31, 22.92, 24.86, ..., 26.33, 23.81, 16.18],
       [19.6 , 21.68, 22.98, ..., 25.25, 26.15, 20.49],
       [25.85, 27.59, 25.75, ..., 27.84, 22.91, 19.78],
       ...,
       [10.2 , 11.32, 11.47, ..., 11.14, 13.62, 10.23],
       [27.36, 26.44, 24.58, ..., 26.77, 27.12, 26.39],
       [17.65, 21.71, 21.9 , ..., 25.7 , 22.33, 14.51]], dtype=float32)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>Tmin</span></div><div class='xr-var-dims'>(hru, time)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>21.31 22.92 24.86 ... 22.33 14.51</div><input id='attrs-f14c3a88-c5bb-415a-abaf-74f6258f8a81' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-f14c3a88-c5bb-415a-abaf-74f6258f8a81' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-45a9feb2-0e7e-44ec-9dd2-bf8746c0dca6' class='xr-var-data-in' type='checkbox'><label for='data-45a9feb2-0e7e-44ec-9dd2-bf8746c0dca6' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([[21.31, 22.92, 24.86, ..., 26.33, 23.81, 16.18],
       [19.6 , 21.68, 22.98, ..., 25.25, 26.15, 20.49],
       [25.85, 27.59, 25.75, ..., 27.84, 22.91, 19.78],
       ...,
       [10.2 , 11.32, 11.47, ..., 11.14, 13.62, 10.23],
       [27.36, 26.44, 24.58, ..., 26.77, 27.12, 26.39],
       [17.65, 21.71, 21.9 , ..., 25.7 , 22.33, 14.51]], dtype=float32)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>vp</span></div><div class='xr-var-dims'>(hru, time)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>2.046e+03 2.129e+03 ... 1.046e+03</div><input id='attrs-9670f115-eff9-4467-9eca-dfa65110412a' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-9670f115-eff9-4467-9eca-dfa65110412a' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-3a7479b9-620d-4cd3-a6a7-3d280e9900a1' class='xr-var-data-in' type='checkbox'><label for='data-3a7479b9-620d-4cd3-a6a7-3d280e9900a1' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([[2046.16, 2129.38, 2164.61, ..., 2514.96, 2575.36, 1256.73],
       [2142.07, 2134.94, 2055.54, ..., 2588.44, 2637.16, 1482.93],
       [1191.47, 1164.85, 1535.44, ..., 2293.79, 1518.16,  709.61],
       ...,
       [1043.18,  913.52,  669.55, ...,  714.63,  825.41,  989.33],
       [2979.01, 2728.94, 2335.26, ..., 2845.01, 2922.01, 2677.59],
       [1900.85, 2236.97, 2119.64, ..., 2560.21, 2305.93, 1046.43]],
      dtype=float32)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>streamflow</span></div><div class='xr-var-dims'>(hru, time)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>1.27e+03 606.0 408.0 ... 2.2 2.3</div><input id='attrs-4ea85b71-f64e-4925-a009-16b2050644c5' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-4ea85b71-f64e-4925-a009-16b2050644c5' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-acbf0cb0-090a-4ce2-9aa4-228307d013ad' class='xr-var-data-in' type='checkbox'><label for='data-acbf0cb0-090a-4ce2-9aa4-228307d013ad' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([[1270. ,  606. ,  408. , ...,  207. ,  451. ,  853. ],
       [ 561. ,  193. ,   78. , ...,    3.3,    2.6,    2.1],
       [   0. ,    0. ,    0. , ...,    0. ,    0. ,    0. ],
       ...,
       [  93. ,   99. ,   89. , ...,   97. ,   97. ,   95. ],
       [ 293. ,  202. ,  148. , ...,  281. ,  215. ,  135. ],
       [ 276. ,   55. ,   33. , ...,    2.1,    2.2,    2.3]],
      dtype=float32)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>elevation</span></div><div class='xr-var-dims'>(hru)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>0.1158 0.1277 ... 0.04145 0.15</div><input id='attrs-2aa4a8e9-d12e-4327-b7af-13e346f19c2b' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-2aa4a8e9-d12e-4327-b7af-13e346f19c2b' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-bd97eec0-15e4-4a30-a73f-eda134fb74fe' class='xr-var-data-in' type='checkbox'><label for='data-bd97eec0-15e4-4a30-a73f-eda134fb74fe' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([0.11581   , 0.1277    , 0.30804998, 0.31010997, 0.09587999,
       0.39903   , 0.064     , 0.54256   , 0.2506    , 0.30831   ,
       0.07308999, 0.07108   , 0.72507   , 0.74046004, 0.24226   ,
       0.33732998, 0.0868    , 0.29235   , 0.37923002, 0.66921   ,
       0.10272   , 0.11714   , 0.05795   , 0.16792999, 0.56777   ,
       0.06747   , 0.02279   , 0.12913   , 0.08353   , 1.2339599 ,
       0.10986   , 0.06731   , 0.24950999, 0.38297   , 0.30917   ,
       0.53553003, 0.89733005, 0.57221997, 0.22908999, 0.08684999,
       0.07813   , 0.28695002, 0.08845   , 0.08282   , 0.28523   ,
       0.13539   , 0.12324   , 0.37873   , 0.02188   , 0.59040004,
       0.11373001, 0.03999   , 0.03123   , 0.11412   , 0.08345   ,
       0.02571   , 0.02625   , 0.47557998, 0.27607998, 0.12586   ,
       0.11327   , 0.07021   , 0.12294   , 0.47869   , 0.75776   ,
       0.62531   , 0.15945   , 0.03367   , 0.27616   , 0.53677005,
       0.27056   , 1.24376   , 0.76403004, 0.39744002, 0.23688   ,
       0.03551   , 0.05166   , 0.07595   , 0.43701002, 0.03719   ,
       0.1058    , 0.14369   , 0.17601   , 0.04292   , 0.14930001,
       1.04023   , 0.93906   , 1.33286   , 0.70112   , 0.6798    ,
       0.13977   , 0.95269   , 0.43945003, 0.54699   , 0.14081   ,
       0.06468   , 1.03785   , 0.06519   , 0.06448001, 0.02175   ,
       0.03493   , 0.65653   , 0.11308   , 0.10687999, 0.16127001,
       0.31744   , 0.56365   , 0.08467   , 0.59258   , 0.46272   ,
       0.34951   , 1.0349301 , 0.10261   , 0.06349   , 1.39531   ,
       0.70983005, 0.05403   , 0.14305   , 0.1015    , 0.14219001,
       0.87566996, 0.10375   , 0.03457   , 0.5076    , 1.3475    ,
       0.11619   , 0.14517999, 0.38823003, 0.37521   , 0.04145   ,
       0.15000999], dtype=float32)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>area</span></div><div class='xr-var-dims'>(hru)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>2.073 0.2901 ... 0.3484 0.04056</div><input id='attrs-0fb9b2ac-38e4-4422-aabc-42345acfa9f5' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-0fb9b2ac-38e4-4422-aabc-42345acfa9f5' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-109c92c3-a2ba-4f34-b74b-32598253a367' class='xr-var-data-in' type='checkbox'><label for='data-109c92c3-a2ba-4f34-b74b-32598253a367' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([2.07309   , 0.2901    , 0.03179   , 0.50162   , 0.46657997,
       0.43475   , 0.80065995, 0.85058004, 0.08401   , 0.85716   ,
       2.124     , 0.98937   , 1.57796   , 0.15508999, 0.68241   ,
       0.23274   , 0.36412   , 0.05401   , 1.06747   , 0.43598998,
       0.86153996, 1.78161   , 1.30515   , 0.08787   , 1.9614301 ,
       0.38357002, 0.31234   , 0.4793    , 0.12911   , 0.02246   ,
       0.44572   , 1.80829   , 0.22652   , 0.086     , 0.33769   ,
       0.60823   , 0.04172   , 0.00806   , 0.10093   , 0.18761   ,
       0.42268   , 1.4886899 , 0.92544   , 0.99608004, 0.1054    ,
       1.29251   , 1.92713   , 0.33719   , 0.44757998, 1.7990899 ,
       0.78994   , 6.1362596 , 0.88640004, 0.14862   , 0.07949   ,
       0.52838   , 0.29770002, 0.73297995, 0.27351   , 1.29279   ,
       1.4216601 , 0.13728   , 1.1452199 , 0.07185   , 0.57238   ,
       0.70263   , 0.18796001, 0.17427   , 0.52633   , 0.32698002,
       0.49138   , 0.093     , 0.12061   , 0.01473   , 0.40489998,
       0.0936    , 0.24923   , 1.29369   , 1.15344   , 0.25392   ,
       1.68873   , 0.57894   , 0.4908    , 0.01567   , 0.7699    ,
       0.18871   , 0.17747   , 0.10365   , 0.33856   , 0.19152   ,
       1.36512   , 3.34895   , 0.62434995, 0.71804   , 0.01582   ,
       1.45433   , 1.92501   , 1.1442    , 0.65160996, 0.54065   ,
       0.59046996, 0.44307   , 0.42029002, 0.01973   , 1.22058   ,
       0.34262   , 0.55752003, 0.84106   , 0.01679   , 0.40345   ,
       0.11887001, 0.42531   , 0.67524   , 0.13117999, 0.78196   ,
       0.22492   , 0.24935001, 0.61013   , 0.08342   , 1.40838   ,
       0.04142   , 0.95989   , 0.45106   , 1.5848199 , 1.17959   ,
       0.12287001, 0.14218   , 1.1771    , 1.74354   , 0.34842998,
       0.04056   ], dtype=float32)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>slope</span></div><div class='xr-var-dims'>(hru)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>7.038 7.99 10.64 ... 4.144 6.73</div><input id='attrs-6e7bfd9f-ab8b-4ea6-9a13-04eee93abf84' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-6e7bfd9f-ab8b-4ea6-9a13-04eee93abf84' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-b7c56b5d-7147-4b3c-8e7c-bb78b4c11db6' class='xr-var-data-in' type='checkbox'><label for='data-b7c56b5d-7147-4b3c-8e7c-bb78b4c11db6' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([  7.03828,   7.99022,  10.64469,   5.60451,   6.82945,  15.73611,
         5.13464,  19.49002,   9.60933,  57.46785,   4.02264,   4.64193,
       112.11076, 103.93357,  15.57552,  13.093  ,   6.98455,  60.28846,
        13.97922,  10.29971,   5.75162,   8.27039,   3.28615,   7.49879,
        17.30756,   4.66804,   1.6186 ,   7.60783,   5.30253, 169.65242,
         7.40892,   4.02675,  35.95163,   9.98524,  61.57144,  56.57053,
        52.40447,  70.81645,   5.75131,   4.78985,   9.86442,   6.30245,
         5.1182 ,   5.30737,  71.42838,   7.57689,   6.76654,  72.9688 ,
         2.57074,  13.29277,   6.76541,   2.02123,   1.71633,   8.63619,
         5.25896,   1.18116,   3.67575,   7.94291,  45.14956,   7.42604,
         5.3832 ,   6.65609,   7.29973,  94.52911, 122.52826,  98.81802,
         7.25507,   1.61485,  55.46804,  22.61663,  12.25237,  87.50629,
       138.61035,  62.50098,  33.69605,   1.24624,   5.61014,   4.567  ,
        96.58146,   1.85956,   7.48765,   9.66599,   7.55177,  16.48391,
        29.3479 ,  77.535  ,  66.19504, 112.56283,  78.77162,  87.84629,
         6.74759,   5.15091,  15.828  , 114.46463,   9.04939,   6.14661,
       126.70666,   5.84957,   3.57506,   0.82221,   2.40016, 124.96889,
         4.53352,  10.48159,   5.02405,  12.46897,  14.64471,   5.61372,
        90.33273,  66.18997,  68.54063,  92.82902,   6.93052,   4.91804,
        59.50706, 110.42527,   3.81251,   6.2489 ,   9.53966,   7.2448 ,
       109.93127,   7.44495,   4.00959,  10.25442,  44.72847,   3.41104,
        47.2961 ,  11.33266,  62.14889,   4.14377,   6.72984],
      dtype=float32)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>lat</span></div><div class='xr-var-dims'>(hru)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>31.32 32.02 30.16 ... 29.98 34.47</div><input id='attrs-ff0ca9e5-c776-4406-bc75-246cffd1477c' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-ff0ca9e5-c776-4406-bc75-246cffd1477c' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-2031921d-0c21-418c-bb19-371bd3d6b73d' class='xr-var-data-in' type='checkbox'><label for='data-2031921d-0c21-418c-bb19-371bd3d6b73d' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([31.32472, 32.01766, 30.15549, 33.81288, 31.22694, 29.37079,
       30.48361, 29.72384, 34.24278, 44.38595, 28.95998, 30.14549,
       41.7915 , 39.16545, 32.91679, 30.29632, 30.71631, 35.23553,
       29.97938, 30.0641 , 29.46691, 31.34295, 30.69875, 33.68263,
       29.42857, 30.48139, 27.34366, 31.50306, 31.99139, 33.76002,
       31.4185 , 28.29195, 44.04984, 30.91157, 46.65093, 36.26802,
       37.84187, 45.32428, 33.55455, 31.97933, 31.74432, 34.00426,
       28.86165, 33.37596, 41.01096, 31.59489, 31.70694, 47.96008,
       35.06417, 29.47273, 31.42583, 30.32578, 27.37504, 33.42484,
       32.93766, 27.19949, 28.87453, 32.64846, 39.42822, 31.5735 ,
       29.21525, 31.02528, 31.59627, 40.35125, 40.48042, 42.12344,
       33.09985, 27.47365, 44.71512, 29.50468, 33.06679, 34.16087,
       36.2458 , 44.2479 , 46.6201 , 27.48726, 30.55861, 30.99602,
       47.53786, 28.89138, 32.01778, 33.47928, 33.25236, 47.38926,
       47.00065, 33.88726, 33.9742 , 32.31674, 37.56132, 34.59666,
       31.76444, 33.03843, 29.31431, 41.29929, 33.41345, 30.80908,
       39.70627, 30.73611, 30.5038 , 27.052  , 32.16798, 42.8915 ,
       32.23944, 35.18278, 27.96501, 30.62575, 30.64352, 30.3366 ,
       39.7296 , 35.78858, 37.26078, 33.69421, 31.99626, 31.53629,
       32.95562, 42.804  , 30.61602, 30.33938, 32.99735, 33.7293 ,
       42.15401, 32.77792, 30.1133 , 32.7329 , 32.03591, 32.19556,
       46.37399, 31.28489, 45.704  , 29.97941, 34.46667], dtype=float32)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>lon</span></div><div class='xr-var-dims'>(hru)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>-91.11 -85.3 ... -81.85 -88.28</div><input id='attrs-7e87d16b-dece-4b22-b338-1fdda222dec5' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-7e87d16b-dece-4b22-b338-1fdda222dec5' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-c5a776db-1415-40f2-b39a-4a08ff9c6586' class='xr-var-data-in' type='checkbox'><label for='data-c5a776db-1415-40f2-b39a-4a08ff9c6586' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([ -91.10944,  -85.29577,  -97.94001,  -98.08504,  -91.29556,
        -99.28782,  -89.27444,  -99.07004,  -84.88972, -123.83178,
        -96.68637,  -95.12438, -124.07619, -122.61999,  -86.27025,
        -97.92557,  -94.95882, -120.47239,  -97.91   ,  -99.38699,
        -96.81276,  -85.61049,  -92.89319,  -82.85792,  -99.99729,
        -94.77972,  -82.15676,  -90.7775 ,  -82.92194, -116.55002,
        -86.98664,  -97.27916, -123.42621,  -98.03697, -123.65266,
       -121.0663 , -120.18491, -123.5465 ,  -96.94723,  -93.93408,
        -88.02251,  -97.56697,  -97.22638,  -92.77711, -124.08173,
        -85.783  ,  -89.40694, -124.39299,  -77.46139, -100.23646,
        -89.41472,  -82.73818,  -81.79647,  -87.64251,  -81.81539,
        -81.98842,  -81.48938,  -99.00451, -123.73779,  -86.25162,
        -97.44943,  -89.01667,  -86.40552, -124.00393, -123.89088,
       -124.18731,  -83.72351,  -82.2112 , -123.88733,  -99.78145,
        -85.87913, -111.69292, -121.77329, -123.63649, -122.94513,
        -82.02342,  -89.12194,  -92.67375, -124.31575,  -96.81915,
        -90.87694,  -87.59723,  -83.48128, -122.69902, -123.49488,
       -111.95404, -112.09905, -110.81037, -121.68384, -119.90875,
        -84.25333, -101.19763,  -99.48047, -124.05118,  -87.51056,
        -88.45863, -123.32529,  -88.78111,  -90.67732,  -81.78453,
        -81.48817, -124.07065,  -83.50167,  -79.1775 ,  -98.96697,
        -97.69112,  -99.09588,  -95.1041 , -123.64391, -121.09381,
       -122.32886, -111.5418 ,  -87.06832,  -92.40847, -109.53119,
       -123.61091,  -90.24869,  -96.9047 ,  -87.62223,  -82.18179,
       -123.07532,  -94.35742,  -81.90649,  -99.14063, -110.67758,
        -83.90222, -123.74348,  -97.88502, -123.7554 ,  -81.85204,
        -88.28361], dtype=float32)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>frac_forest</span></div><div class='xr-var-dims'>(hru)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>0.9468 0.9083 ... 0.8235 0.8644</div><input id='attrs-8a2352b9-ea97-4793-a5de-aa121ca8947e' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-8a2352b9-ea97-4793-a5de-aa121ca8947e' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-e6a335af-5d04-4f02-848e-1d51dcd177ad' class='xr-var-data-in' type='checkbox'><label for='data-e6a335af-5d04-4f02-848e-1d51dcd177ad' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([9.468e-01, 9.083e-01, 5.480e-02, 9.230e-02, 9.400e-01, 4.827e-01,
       7.816e-01, 4.391e-01, 7.132e-01, 9.993e-01, 7.400e-02, 8.129e-01,
       9.993e-01, 8.707e-01, 8.204e-01, 8.800e-02, 8.456e-01, 4.501e-01,
       5.690e-02, 1.466e-01, 1.220e-02, 4.408e-01, 8.187e-01, 8.688e-01,
       2.878e-01, 8.251e-01, 7.560e-02, 9.777e-01, 4.884e-01, 5.081e-01,
       9.490e-01, 1.046e-01, 9.030e-01, 2.010e-02, 9.896e-01, 1.373e-01,
       7.577e-01, 1.000e+00, 1.279e-01, 8.629e-01, 9.839e-01, 4.370e-02,
       1.949e-01, 9.703e-01, 9.378e-01, 6.350e-01, 6.696e-01, 1.000e+00,
       7.118e-01, 1.388e-01, 5.865e-01, 9.266e-01, 1.676e-01, 9.717e-01,
       4.500e-01, 1.446e-01, 6.142e-01, 6.600e-03, 1.000e+00, 6.862e-01,
       7.030e-02, 9.355e-01, 7.608e-01, 9.966e-01, 9.953e-01, 1.000e+00,
       9.270e-01, 5.720e-02, 9.943e-01, 6.396e-01, 9.106e-01, 5.022e-01,
       9.458e-01, 9.933e-01, 8.617e-01, 1.264e-01, 8.845e-01, 9.144e-01,
       9.969e-01, 5.730e-02, 7.965e-01, 9.846e-01, 8.252e-01, 1.000e+00,
       9.705e-01, 1.822e-01, 1.114e-01, 4.456e-01, 3.530e-01, 7.047e-01,
       3.941e-01, 0.000e+00, 4.132e-01, 9.830e-01, 9.571e-01, 8.849e-01,
       9.609e-01, 8.895e-01, 9.532e-01, 1.369e-01, 6.165e-01, 1.000e+00,
       1.516e-01, 6.906e-01, 8.000e-04, 2.630e-02, 3.860e-02, 8.302e-01,
       9.922e-01, 4.250e-01, 8.210e-01, 1.580e-01, 9.336e-01, 9.040e-01,
       1.601e-01, 1.000e+00, 7.492e-01, 2.820e-02, 8.617e-01, 8.727e-01,
       1.000e+00, 8.518e-01, 8.293e-01, 3.800e-03, 6.210e-02, 9.890e-02,
       9.981e-01, 6.700e-03, 9.630e-01, 8.235e-01, 8.644e-01],
      dtype=float32)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>p_mean</span></div><div class='xr-var-dims'>(hru)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>4.256 3.815 2.509 ... 3.756 4.233</div><input id='attrs-ce342954-8e23-456d-9cd0-f85526d79e72' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-ce342954-8e23-456d-9cd0-f85526d79e72' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-e934dbb8-97ec-42a7-b6a1-d5dd97931140' class='xr-var-data-in' type='checkbox'><label for='data-e934dbb8-97ec-42a7-b6a1-d5dd97931140' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([4.2555304, 3.8146038, 2.508961 , 2.2319932, 4.3807516, 2.226349 ,
       4.6208253, 2.475807 , 3.753707 , 6.2869377, 2.9330008, 3.6767147,
       5.584642 , 2.9614716, 4.065551 , 2.504512 , 3.8147583, 1.883666 ,
       2.560382 , 2.228876 , 2.8500602, 3.9580424, 4.47233  , 3.2740657,
       1.9173895, 3.9762492, 3.896312 , 4.273158 , 3.409098 , 1.048308 ,
       4.4196234, 2.374371 , 5.050238 , 2.4449513, 6.8749375, 1.3327844,
       2.822434 , 6.6944065, 2.8193483, 4.0233674, 4.0960083, 2.5022068,
       2.4921436, 3.807911 , 4.3631306, 3.960397 , 4.1584024, 8.284583 ,
       3.7827911, 1.8268542, 4.2561574, 3.6672785, 3.6802464, 4.0980587,
       3.3192184, 3.841662 , 3.7435017, 2.018211 , 3.582883 , 3.9699836,
       2.4163094, 4.4288883, 3.983117 , 4.8341846, 4.551621 , 5.5560713,
       3.3718727, 3.9627721, 6.67003  , 2.0857878, 4.055131 , 1.53705  ,
       2.836768 , 6.489867 , 4.7079797, 3.9681163, 4.7916427, 4.3200464,
       8.154612 , 3.10259  , 4.154616 , 4.2723093, 3.359124 , 4.0094705,
       6.987945 , 1.1819412, 1.1800945, 1.5645038, 1.4762094, 2.0521903,
       3.6358206, 1.3724203, 2.2533731, 4.5799766, 4.159726 , 4.6499906,
       3.6535537, 4.618568 , 4.5874057, 3.6844475, 3.3413649, 6.297437 ,
       3.3543983, 3.3550677, 1.3972156, 2.5203314, 2.10541  , 3.6437795,
       5.166086 , 2.2885325, 2.6919794, 1.2273538, 4.0434155, 4.2429075,
       1.0724257, 4.977781 , 4.6118836, 2.6378167, 4.0434923, 3.3244667,
       2.7816756, 3.5820246, 3.703221 , 1.908219 , 1.2634045, 3.391477 ,
       7.9279423, 2.3964818, 5.819217 , 3.7559905, 4.232671 ],
      dtype=float32)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>pet_mean</span></div><div class='xr-var-dims'>(hru)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>3.475 3.275 3.377 ... 3.81 2.947</div><input id='attrs-8454c6f8-f580-471e-8122-1508396047e2' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-8454c6f8-f580-471e-8122-1508396047e2' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-e44f678e-3586-418c-82b9-97f21c6e7390' class='xr-var-data-in' type='checkbox'><label for='data-e44f678e-3586-418c-82b9-97f21c6e7390' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([3.474859 , 3.2751064, 3.3770826, 3.8114874, 3.5538812, 3.4286418,
       3.2160869, 3.3824854, 2.9469426, 2.9639468, 4.743906 , 4.0257716,
       2.3207688, 2.5903316, 3.1359894, 3.3766212, 3.8864117, 2.7515624,
       4.6750374, 3.3454733, 4.7189584, 3.2905831, 3.2702677, 3.0247023,
       3.3989081, 4.1909184, 3.6225574, 3.1913815, 3.189064 , 3.1332207,
       4.348987 , 4.736853 , 3.0691845, 3.32525  , 2.1167104, 3.6447382,
       3.4802144, 2.16097  , 3.1417925, 3.2216694, 3.2828758, 3.0694742,
       3.8805728, 3.0545096, 2.3689864, 4.1713114, 3.167662 , 2.2500076,
       3.2678006, 4.2063613, 3.6184597, 3.7085364, 3.5079975, 3.1621282,
       3.6032202, 4.0429068, 4.1242127, 3.5747094, 2.7171624, 3.147583 ,
       3.4442956, 3.2004776, 3.14446  , 2.3263075, 2.7211537, 2.2796676,
       4.0176754, 3.5227084, 2.1728907, 3.4210217, 3.0005956, 3.863441 ,
       2.5829408, 2.4443924, 2.0948234, 3.8671913, 3.2156103, 3.2196553,
       1.8990965, 3.7774491, 3.4228578, 3.0024033, 3.1424088, 2.8562589,
       1.9802686, 3.4585934, 3.5221481, 4.597359 , 3.2606719, 3.1865656,
       3.1564844, 3.5807564, 3.4152603, 2.5177915, 3.0301282, 3.1850972,
       2.797848 , 3.2130122, 3.935051 , 3.5255775, 3.1650188, 2.4346516,
       3.1587017, 3.0197144, 3.6192653, 3.3521163, 3.3503053, 3.6783774,
       3.0671427, 2.7563639, 3.447233 , 3.4008267, 3.9715807, 3.4136755,
       3.2594604, 3.1222038, 3.7151341, 3.3909214, 3.5898702, 3.905833 ,
       3.3251884, 3.1423192, 3.286836 , 3.2612162, 3.703829 , 3.1570308,
       1.9671209, 3.3018892, 2.8381026, 3.8102221, 2.9471962],
      dtype=float32)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>aridity</span></div><div class='xr-var-dims'>(hru)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>0.8166 0.8586 ... 1.014 0.6963</div><input id='attrs-82636382-7b21-4f0a-9ab3-9f1cefdd68c5' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-82636382-7b21-4f0a-9ab3-9f1cefdd68c5' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-18c02222-fef3-441e-9f0f-349730ea9cfb' class='xr-var-data-in' type='checkbox'><label for='data-18c02222-fef3-441e-9f0f-349730ea9cfb' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([0.8165513 , 0.8585705 , 1.3460084 , 1.7076609 , 0.8112492 ,
       1.5400289 , 0.6959984 , 1.3662153 , 0.78507525, 0.47144526,
       1.617424  , 1.0949372 , 0.4155627 , 0.8746772 , 0.7713566 ,
       1.3482152 , 1.0187831 , 1.4607484 , 1.8259141 , 1.5009687 ,
       1.6557399 , 0.8313663 , 0.73122233, 0.92383677, 1.7726749 ,
       1.053988  , 0.9297401 , 0.74684376, 0.9354569 , 2.9888358 ,
       0.9840175 , 1.9949927 , 0.6077307 , 1.3600475 , 0.30788794,
       2.7346797 , 1.2330543 , 0.32280234, 1.1143683 , 0.8007395 ,
       0.8014817 , 1.2267069 , 1.5571225 , 0.80214834, 0.54295564,
       1.0532558 , 0.7617497 , 0.27158973, 0.8638596 , 2.3025162 ,
       0.85017055, 1.0112503 , 0.95319635, 0.7716161 , 1.085563  ,
       1.0523849 , 1.1016991 , 1.771227  , 0.7583732 , 0.79284537,
       1.4254365 , 0.72263676, 0.78944707, 0.48122025, 0.59784275,
       0.41030207, 1.1915264 , 0.8889505 , 0.32576925, 1.640158  ,
       0.7399504 , 2.513543  , 0.9105224 , 0.37664753, 0.44495165,
       0.97456604, 0.6710872 , 0.74528253, 0.2328862 , 1.2175148 ,
       0.82386863, 0.70275885, 0.93548465, 0.71237814, 0.28338352,
       2.9261978 , 2.9846325 , 2.9385417 , 2.208814  , 1.5527632 ,
       0.8681628 , 2.6090815 , 1.5156214 , 0.54973894, 0.7284441 ,
       0.68496853, 0.7657881 , 0.6956728 , 0.85779434, 0.9568809 ,
       0.94722337, 0.3866099 , 0.9416596 , 0.90004575, 2.5903413 ,
       1.3300301 , 1.591284  , 1.009495  , 0.59370726, 1.2044241 ,
       1.2805569 , 2.770861  , 0.9822341 , 0.8045604 , 3.0393345 ,
       0.6272281 , 0.8055568 , 1.2855031 , 0.8878143 , 1.174875  ,
       1.1953905 , 0.8772467 , 0.8875613 , 1.7090366 , 2.9316256 ,
       0.93087196, 0.24812502, 1.3778069 , 0.48771212, 1.0144387 ,
       0.69629705], dtype=float32)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>Tavg</span></div><div class='xr-var-dims'>(hru, time)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>21.31 22.92 24.86 ... 22.33 14.51</div><input id='attrs-f640c2c2-4174-42a3-9496-5e1b4548ff4f' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-f640c2c2-4174-42a3-9496-5e1b4548ff4f' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-fc585b57-275b-4e00-bae2-acb2ed3978c6' class='xr-var-data-in' type='checkbox'><label for='data-fc585b57-275b-4e00-bae2-acb2ed3978c6' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([[21.31, 22.92, 24.86, ..., 26.33, 23.81, 16.18],
       [19.6 , 21.68, 22.98, ..., 25.25, 26.15, 20.49],
       [25.85, 27.59, 25.75, ..., 27.84, 22.91, 19.78],
       ...,
       [10.2 , 11.32, 11.47, ..., 11.14, 13.62, 10.23],
       [27.36, 26.44, 24.58, ..., 26.77, 27.12, 26.39],
       [17.65, 21.71, 21.9 , ..., 25.7 , 22.33, 14.51]], dtype=float32)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>pet</span></div><div class='xr-var-dims'>(hru, time)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>3.207 5.699 5.843 ... 2.623 4.953</div><input id='attrs-e06e8163-ef91-4195-aeb3-01e65f0cbe47' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-e06e8163-ef91-4195-aeb3-01e65f0cbe47' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-70c09420-82e6-4fc3-a868-0fa2cfc1431e' class='xr-var-data-in' type='checkbox'><label for='data-70c09420-82e6-4fc3-a868-0fa2cfc1431e' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([[3.2069297, 5.699203 , 5.8427835, ..., 3.7462773, 3.5005717,
        5.326026 ],
       [2.2161143, 5.4475927, 5.591488 , ..., 3.7381718, 3.7342553,
        5.3828278],
       [5.552106 , 5.6468163, 5.1250753, ..., 5.835704 , 4.574785 ,
        5.950892 ],
       ...,
       [2.471159 , 3.4106917, 3.4748366, ..., 3.561544 , 3.6252842,
        3.2920253],
       [3.864946 , 4.94296  , 5.8845286, ..., 4.5822806, 4.1401153,
        5.164263 ],
       [2.8465893, 5.300418 , 5.2998905, ..., 3.2605543, 2.62337  ,
        4.9532857]], dtype=float32)</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-a592ea39-941f-4257-a05e-9821d1de9e1f' class='xr-section-summary-in' type='checkbox' disabled ><label for='section-a592ea39-941f-4257-a05e-9821d1de9e1f' class='xr-section-summary'  title='Expand/collapse section'>Attributes: <span>(0)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><dl class='xr-attrs'></dl></div></li></ul></div></div></div></div>
</div>
<p>Now that we’ve got a dataset to use we need a way of ingesting it so that we can actually train the model. To do so we will employ a slightly non-standard technique called “multiple trajectory”, or “multiple shooting”, optimization. The problem is essentially that the model we defined above is somewhat analagous to a recurrent neural network (RNN), where to train we iterate over sequences with some length. In this case the sequences are multiple timesteps. Like RNNs, you don’t want to update the model parameters after every step because that makes the training process almost impossible. Instead, we run the model forward in time for some period of time, then update the model parameters according to the accumulated gradients. In principle, we could run the model over the entire training period, but this is means fewer data points to update the model parameters, leading to slower convergence. Instead, we break the full dataset into a series of “trajectories” which contain a specified time period. Then, during the training process we iterate over each of these trajectories, updating model parameters along the way. A full pass over all of the trajectories, then, is a single training epoch.</p>
<p>We implement this below. This sort of data-wrangling is core to doing machine learning, so thinking about how and why to arrange data any particular way is very important. As such, we build on the PyTorch <code class="docutils literal notranslate"><span class="pre">Dataset</span></code> class, which simplifies the interface to referencing data for both training and inference (commonly referred to as prediction). Without getting too far into the weeds of data loading we just set up the way to index the dataset via the <code class="docutils literal notranslate"><span class="pre">__getitem__</span></code> method and ways to determine how bid the dataset is through the <code class="docutils literal notranslate"><span class="pre">__len__</span></code> method.</p>
<p>Finally, let’s talk about what actually comes out of the dataset. When you index on the dataset (as <code class="docutils literal notranslate"><span class="pre">x[i]</span></code>) you will get two tensor arrays back. The first is the input to the model, and the second is the target data that we want the model to produce when given the input. In our case we will record the inputs and outputs via the <code class="docutils literal notranslate"><span class="pre">in_vars</span></code> and <code class="docutils literal notranslate"><span class="pre">out_vars</span></code> variables. This will make it easier to explore which variables have an impact during training.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">MultipleTrajectoryDataset</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>
    
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ds</span><span class="p">,</span> <span class="n">in_vars</span><span class="p">,</span> <span class="n">out_vars</span><span class="p">,</span> <span class="n">trajectory_len</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ds</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">load</span><span class="p">()</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s1">&#39;hru&#39;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">in_vars</span> <span class="o">=</span> <span class="n">in_vars</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out_vars</span> <span class="o">=</span> <span class="n">out_vars</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">trajectory_len</span> <span class="o">=</span> <span class="n">trajectory_len</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_trajectories</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ds</span><span class="p">[</span><span class="s1">&#39;time&#39;</span><span class="p">])</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">trajectory_len</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">time_starts</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="o">*</span> <span class="n">trajectory_len</span> 
                            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_trajectories</span><span class="p">)]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">time_ends</span> <span class="o">=</span> <span class="p">[(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">trajectory_len</span> 
                          <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_trajectories</span><span class="p">)]</span>
        
    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">):</span>
        <span class="n">time_slice</span> <span class="o">=</span> <span class="nb">slice</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">time_starts</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">time_ends</span><span class="p">[</span><span class="n">idx</span><span class="p">])</span>
        <span class="n">sample_ds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ds</span><span class="o">.</span><span class="n">isel</span><span class="p">(</span><span class="n">time</span><span class="o">=</span><span class="n">time_slice</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">sample_ds</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">in_vars</span><span class="p">]</span><span class="o">.</span><span class="n">to_dataframe</span><span class="p">()</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">sample_ds</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">out_vars</span><span class="p">]</span><span class="o">.</span><span class="n">to_dataframe</span><span class="p">()</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span>
    
    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">time_starts</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="on-dunder-methods">
<h3>On <code class="docutils literal notranslate"><span class="pre">__dunder__</span></code> methods<a class="headerlink" href="#on-dunder-methods" title="Permalink to this headline">#</a></h3>
<p>The methods that we implemented in the <code class="docutils literal notranslate"><span class="pre">MultipleTrajectoryDataset</span></code> are referred to as “dunder” (aka double underscore) methods which python uses to call the base indexing calls. Simply stated, if you call <code class="docutils literal notranslate"><span class="pre">x[i]</span></code> you are really calling <code class="docutils literal notranslate"><span class="pre">x.__getitem__(i)</span></code> and if you call <code class="docutils literal notranslate"><span class="pre">len(x)</span></code> you are really calling <code class="docutils literal notranslate"><span class="pre">x.__len__()</span></code>. Of course these are simplifications, but the shorthand is useful to understand.</p>
</section>
<section id="the-model-training-functions">
<h3>The model training functions<a class="headerlink" href="#the-model-training-functions" title="Permalink to this headline">#</a></h3>
<p>With a model and dataset in hand we will define some functions to simplify the core training loop. First the <code class="docutils literal notranslate"><span class="pre">update_model_step</span></code> function is used to actually perform the optimization step. This is pretty much a standard update function where we run the model on some training data, compute the loss, and use the gradients of the loss with respect to the parameters to update the parameters via the optimizer’s <code class="docutils literal notranslate"><span class="pre">step</span></code> method. The other function we define is the <code class="docutils literal notranslate"><span class="pre">update_ic_step</span></code> which is where we update the initial conditions (that is, the initial storages) at the end of an individual training trajectory. This is calculated after <code class="docutils literal notranslate"><span class="pre">update_model_step</span></code> and used to transition between training trajectories.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">update_model_step</span><span class="p">(</span>
    <span class="n">model</span><span class="p">,</span> <span class="n">opt</span><span class="p">,</span> <span class="n">train_data</span><span class="p">,</span> <span class="n">S_init</span><span class="p">,</span> 
    <span class="n">loss_fun</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">(),</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span>
<span class="p">):</span>
    <span class="n">Xd</span><span class="p">,</span> <span class="n">yd</span> <span class="o">=</span> <span class="n">train_data</span>
    <span class="n">Xd</span> <span class="o">=</span> <span class="n">Xd</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="n">yd</span> <span class="o">=</span> <span class="n">yd</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="n">opt</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
    <span class="n">yp</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">Xd</span><span class="p">,</span> <span class="n">storage</span><span class="o">=</span><span class="n">S_init</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fun</span><span class="p">(</span><span class="n">yp</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(),</span> <span class="n">yd</span><span class="o">.</span><span class="n">squeeze</span><span class="p">())</span>
    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
    <span class="n">opt</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">loss</span>

<span class="k">def</span> <span class="nf">update_ic_step</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">train_data</span><span class="p">,</span> <span class="n">S_init</span><span class="p">):</span>
    <span class="n">forcing</span><span class="p">,</span> <span class="n">q_true</span> <span class="o">=</span> <span class="n">train_data</span>
    <span class="n">q_pred</span>  <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">forcing</span><span class="p">,</span> <span class="n">storage</span><span class="o">=</span><span class="n">S_init</span><span class="p">)</span>
    <span class="n">final_storage</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">end_storage</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">final_storage</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="setting-up-our-training-testing-data">
<h3>Setting up our training/testing data<a class="headerlink" href="#setting-up-our-training-testing-data" title="Permalink to this headline">#</a></h3>
<p>Now that we’ve got everything we need to do the training let’s go ahead and set up our process. First, we need to select a basin that we want to train at, select out the train and test timeframes, and then create the dataset with some trajectory lengths (in units of days). Finally we create a <code class="docutils literal notranslate"><span class="pre">MultipleTrajectoryDataset</span></code> for our training and testing periods.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># HRU that tend to perform well</span>
<span class="c1"># 14166500 , 14306500, 11476600 , 14306500 ,11532500, 11143000 </span>
<span class="c1"># HRU that tend to perform poorly</span>
<span class="c1"># 7292500 , 2102908, 8155200, 2212600</span>
<span class="n">selected_basin</span> <span class="o">=</span> <span class="mi">11143000</span>

<span class="n">train_time</span> <span class="o">=</span> <span class="nb">slice</span><span class="p">(</span><span class="s1">&#39;10-01-1989&#39;</span><span class="p">,</span> <span class="s1">&#39;09-30-1996&#39;</span><span class="p">)</span>
<span class="n">test_time</span> <span class="o">=</span> <span class="nb">slice</span><span class="p">(</span><span class="s1">&#39;10-01-1997&#39;</span><span class="p">,</span> <span class="s1">&#39;09-30-1999&#39;</span><span class="p">)</span>
<span class="n">train_ds</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">sel</span><span class="p">(</span><span class="n">hru</span><span class="o">=</span><span class="n">selected_basin</span><span class="p">,</span> <span class="n">time</span><span class="o">=</span><span class="n">train_time</span><span class="p">)</span>
<span class="n">test_ds</span>  <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">sel</span><span class="p">(</span><span class="n">hru</span><span class="o">=</span><span class="n">selected_basin</span><span class="p">,</span> <span class="n">time</span><span class="o">=</span><span class="n">test_time</span><span class="p">)</span>

<span class="n">seq_len</span> <span class="o">=</span> <span class="mi">365</span>
<span class="n">attrs</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s1">&#39;elevation&#39;</span><span class="p">,</span>
    <span class="s1">&#39;area&#39;</span><span class="p">,</span>
    <span class="s1">&#39;frac_forest&#39;</span><span class="p">,</span>
    <span class="s1">&#39;aridity&#39;</span>
<span class="p">]</span>
<span class="n">in_vars</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;pet&#39;</span><span class="p">,</span> <span class="s1">&#39;prcp&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="n">attrs</span>
<span class="n">out_vars</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;QObs&#39;</span><span class="p">]</span>

<span class="c1"># Training dataset</span>
<span class="n">train_data</span> <span class="o">=</span> <span class="n">MultipleTrajectoryDataset</span><span class="p">(</span>
    <span class="n">train_ds</span><span class="p">,</span> <span class="n">in_vars</span><span class="p">,</span> <span class="n">out_vars</span><span class="p">,</span>  <span class="n">seq_len</span>
<span class="p">)</span>

<span class="c1"># Test dataset</span>
<span class="n">test_data</span> <span class="o">=</span> <span class="n">MultipleTrajectoryDataset</span><span class="p">(</span>
    <span class="n">test_ds</span><span class="p">,</span> <span class="n">in_vars</span><span class="p">,</span> <span class="n">out_vars</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">test_ds</span><span class="p">[</span><span class="s1">&#39;time&#39;</span><span class="p">])</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="defining-the-model-setup">
<h3>Defining the model setup<a class="headerlink" href="#defining-the-model-setup" title="Permalink to this headline">#</a></h3>
<p>Now we set some hyperparameters, which are our the neural network width and depth for each parameterization defined previously, initial storage values, the learning rate, and the bounds of the physical constants of each parameter for the <code class="docutils literal notranslate"><span class="pre">HydroSimulator</span></code>. The initial storage warrants some discussion. In our testing this can actually have a decent impact on the overall performance, so if you try different basins you might fiddle with this to see if you can get better performance. We have set up some infrastructure in our training loop that minimizes this effect, but it is still present to some extent.</p>
<p>The way that we mitigate some of the impact of the choice of the <code class="docutils literal notranslate"><span class="pre">initial_storage</span></code> values is after a full epoch (that is, a pass over each of the training trajectories) we take the average of the ending storage values and use that as the initial storage for the next epoch.</p>
<p>Following that we set the hyperparameters for the <code class="docutils literal notranslate"><span class="pre">HydroParam</span></code> objects which represent parameter values for the model. We have simply set all of them to be single layer MLPs with 6 nodes. You can try to adjust this, but since we are training on a single basin with only static attributes the model complexity does not actually have a large impact on model performance. The actual bounds on each of the <code class="docutils literal notranslate"><span class="pre">HydroParam</span></code> instances was taken more or less from the recommendations from the original implementation of this conceptual model by <strong>Clark et al. (2008)</strong>.</p>
<p>With the hyperparameters set up, we will create our model instance and set the optimizer. Here we’ll just use the Adam optimizer and mean squared error losses as they’re a good all around picks, but you can explore different options here as well. The learning rate was chosen by trial and error, and seems to work well enough.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">initial_storage</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">30.0</span><span class="p">,</span> <span class="mf">50.0</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="n">width</span> <span class="o">=</span> <span class="mi">6</span>
<span class="n">depth</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">in_dim</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">attrs</span><span class="p">)</span>

<span class="n">S0max</span> <span class="o">=</span> <span class="n">HydroParam</span><span class="p">(</span> <span class="mf">50.000</span><span class="p">,</span> <span class="mf">200.0</span><span class="p">,</span> <span class="n">MLP</span><span class="p">(</span><span class="n">width</span><span class="p">,</span> <span class="n">depth</span><span class="p">,</span> <span class="n">in_dim</span><span class="o">=</span><span class="n">in_dim</span><span class="p">))</span>
<span class="n">S1max</span> <span class="o">=</span> <span class="n">HydroParam</span><span class="p">(</span><span class="mf">100.000</span><span class="p">,</span> <span class="mf">500.0</span><span class="p">,</span> <span class="n">MLP</span><span class="p">(</span><span class="n">width</span><span class="p">,</span> <span class="n">depth</span><span class="p">,</span> <span class="n">in_dim</span><span class="o">=</span><span class="n">in_dim</span><span class="p">))</span>
<span class="n">p</span>     <span class="o">=</span> <span class="n">HydroParam</span><span class="p">(</span>  <span class="mf">0.001</span><span class="p">,</span>   <span class="mf">1.5</span><span class="p">,</span> <span class="n">MLP</span><span class="p">(</span><span class="n">width</span><span class="p">,</span> <span class="n">depth</span><span class="p">,</span> <span class="n">in_dim</span><span class="o">=</span><span class="n">in_dim</span><span class="p">))</span>
<span class="n">ku</span>    <span class="o">=</span> <span class="n">HydroParam</span><span class="p">(</span>  <span class="mf">0.010</span><span class="p">,</span> <span class="mf">100.0</span><span class="p">,</span> <span class="n">MLP</span><span class="p">(</span><span class="n">width</span><span class="p">,</span> <span class="n">depth</span><span class="p">,</span> <span class="n">in_dim</span><span class="o">=</span><span class="n">in_dim</span><span class="p">))</span>
<span class="n">ks</span>    <span class="o">=</span> <span class="n">HydroParam</span><span class="p">(</span>  <span class="mf">0.010</span><span class="p">,</span> <span class="mf">100.0</span><span class="p">,</span> <span class="n">MLP</span><span class="p">(</span><span class="n">width</span><span class="p">,</span> <span class="n">depth</span><span class="p">,</span> <span class="n">in_dim</span><span class="o">=</span><span class="n">in_dim</span><span class="p">))</span>
<span class="n">b</span>     <span class="o">=</span> <span class="n">HydroParam</span><span class="p">(</span>  <span class="mf">0.001</span><span class="p">,</span>   <span class="mf">3.0</span><span class="p">,</span> <span class="n">MLP</span><span class="p">(</span><span class="n">width</span><span class="p">,</span> <span class="n">depth</span><span class="p">,</span> <span class="n">in_dim</span><span class="o">=</span><span class="n">in_dim</span><span class="p">))</span>
<span class="n">c</span>     <span class="o">=</span> <span class="n">HydroParam</span><span class="p">(</span>  <span class="mf">0.010</span><span class="p">,</span>  <span class="mf">10.0</span><span class="p">,</span> <span class="n">MLP</span><span class="p">(</span><span class="n">width</span><span class="p">,</span> <span class="n">depth</span><span class="p">,</span> <span class="n">in_dim</span><span class="o">=</span><span class="n">in_dim</span><span class="p">))</span>
<span class="n">n</span>     <span class="o">=</span> <span class="n">HydroParam</span><span class="p">(</span>  <span class="mf">0.010</span><span class="p">,</span>  <span class="mf">10.0</span><span class="p">,</span> <span class="n">MLP</span><span class="p">(</span><span class="n">width</span><span class="p">,</span> <span class="n">depth</span><span class="p">,</span> <span class="n">in_dim</span><span class="o">=</span><span class="n">in_dim</span><span class="p">))</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">HydroSimulator</span><span class="p">(</span><span class="n">S0max</span><span class="p">,</span> <span class="n">S1max</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">ku</span><span class="p">,</span> <span class="n">ks</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">3e-3</span>
<span class="n">opt</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>
<span class="n">loss_fun</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">()</span> 
</pre></div>
</div>
</div>
</div>
</section>
<section id="training-the-model">
<h3>Training the model<a class="headerlink" href="#training-the-model" title="Permalink to this headline">#</a></h3>
<p>Now, finally, we get to train the model. The “training loop” here consists of three actual python loops. The first is for overall epochs, which is the number of times that we pass over the full dataset. The second is to pass over each of our training trajectories. And, finally, the third is the number of times that we look at an individual trajectory before moving to the next. For each inner-most loop (that is passes over the same trajectory) we compute the training loss. Once we have moved onto a new trajectory we record the ending storages so that they can be supplied to the next trajectory as an initial condition. This is how we use the multiple trajectory training to work around the fact that we do not know the actual values for the storages in the upper and lower layers at any given time, and particularly at the initial times of each trajectory, and is done by calling <code class="docutils literal notranslate"><span class="pre">update_ic_step</span></code> after the innermost training loop has completed. In our case, training may take a couple of minutes.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">max_epochs</span> <span class="o">=</span> <span class="mi">6</span>        <span class="c1"># Number of times we pass over the full training set</span>
<span class="n">max_sub_epochs</span> <span class="o">=</span> <span class="mi">2</span>    <span class="c1"># Number of times we pass over each trajectory </span>
<span class="n">train_loss_history</span> <span class="o">=</span> <span class="p">{</span><span class="n">i</span><span class="p">:</span> <span class="p">[]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">train_data</span><span class="p">))}</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">max_epochs</span><span class="p">)):</span>
    <span class="n">storage</span> <span class="o">=</span> <span class="n">initial_storage</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">idx_traj</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">train_data</span><span class="p">)):</span>
        <span class="k">for</span> <span class="n">sub_epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_sub_epochs</span><span class="p">):</span>
            <span class="c1"># Get the training data for this trajectory</span>
            <span class="n">data</span> <span class="o">=</span> <span class="n">train_data</span><span class="p">[</span><span class="n">idx_traj</span><span class="p">]</span>
            <span class="c1"># Train on the current trajectory</span>
            <span class="n">l</span> <span class="o">=</span> <span class="n">update_model_step</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">opt</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">storage</span><span class="o">.</span><span class="n">clone</span><span class="p">())</span>
            <span class="n">train_loss_history</span><span class="p">[</span><span class="n">idx_traj</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">l</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
        <span class="c1"># Update the storage for the next trajectory</span>
        <span class="n">storage</span> <span class="o">=</span> <span class="n">update_ic_step</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">storage</span><span class="o">.</span><span class="n">clone</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "bb566e27eb224cb69af81758173e4164", "version_major": 2, "version_minor": 0}
</script></div>
</div>
<p>As you can see from the training curves we were able to reduce the loss relatively quickly. Additionally you see that each of the trajectories (which are different periods of time) end up with different loss curves. You can see then that some years are harder for the model than others, although all show improvement over their starting point. You might look at these trajectories individually to see if you can diagnose why some trajectories are easier to optimize than others. You may also notice that this training process did not converge to a minimum. We cut the training time off here because we wanted to provide a simple and efficient example for you to be able to tinker with.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">train_loss_history</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;Trajectory </span><span class="si">{</span><span class="n">k</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Epoch&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;MSE Loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">semilogy</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[]
</pre></div>
</div>
<img alt="../_images/chapter2_79_1.png" src="../_images/chapter2_79_1.png" />
</div>
</div>
</section>
<section id="model-analysis">
<h3>Model analysis<a class="headerlink" href="#model-analysis" title="Permalink to this headline">#</a></h3>
<p>With the model trained we can now run it on the test data and see what we’ve produced. Before analyzing the model we’ll define the <code class="docutils literal notranslate"><span class="pre">nse</span></code> function which calculates the Nash-Sutcliffe efficiency which is a measure of performance <strong>(Nash &amp; Sutcliffe, 1970)</strong>. Values above 0 indicate that the model does better than simply using the observed mean while a value of 1 is a perfect match.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">nse</span><span class="p">(</span><span class="n">sim</span><span class="p">,</span> <span class="n">obs</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">obs</span> <span class="o">-</span> <span class="n">sim</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span> 
            <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">obs</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">obs</span><span class="p">))</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)))</span>
</pre></div>
</div>
</div>
</div>
<p>To actually run the model we pull our forcings (that is, daily precipitation and potential-evapotranspiration) and observed streamflow from the <code class="docutils literal notranslate"><span class="pre">test_data</span></code>. The forcings can then be put into the model, with the average storage from training as our starting place. We first run the trained model to get the predicted streamflow as well as pull out the relevant storage terms and fluxes.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">test_data</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">initial_storage</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">end_storage</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>

<span class="n">forcing</span> <span class="o">=</span> <span class="n">to_np</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">q_true</span> <span class="o">=</span> <span class="n">to_np</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
<span class="n">q_pred</span> <span class="o">=</span> <span class="n">to_np</span><span class="p">(</span><span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">initial_storage</span><span class="p">))</span>

<span class="n">surf_storage</span> <span class="o">=</span> <span class="n">to_np</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">storage_ts</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">])</span>
<span class="n">subsurf_storage</span> <span class="o">=</span> <span class="n">to_np</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">storage_ts</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">])</span>

<span class="n">surf_flow</span> <span class="o">=</span> <span class="n">to_np</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">surface_flow</span><span class="p">)</span>
<span class="n">subsurf_flow</span> <span class="o">=</span> <span class="n">to_np</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">subsurface_flow</span><span class="p">)</span>

<span class="n">et</span> <span class="o">=</span> <span class="n">to_np</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">et</span><span class="p">)</span>
<span class="n">drainage</span> <span class="o">=</span> <span class="n">to_np</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">drainage</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Next, we can plot all of the data to see what’s going on in the model. There are a number of interesting things to discuss in the model outputs, but obviously the first thing you will look at is how well the predicted streamflow matches the observed streamflow. If you are using the basin we selected as default you will find we get a value of about 0.71, which is a quite reasonably performing model. Not bad for such a simple setup!</p>
<p>You can also look at the storage timeseries, which shows the internal dynamics of the system. Overall we see slower dynamics in the subsurface, which is reasonable. Further, we see that the subsurface in this model configuration retains quite a bit of water as a “steady state”. The surface bucket, on the other hand, reacts much more quickly to precipitation inputs and seems to help produce the “flashy” streamflow events, as you would suspsect.</p>
<p>Finally, looking at the ET/PET ratios we see that generally the ratio is maximized when moisture is high in the system, while the ratio becomes lower in the dry periods, despite a high demand. Again all of this is reasonable for a hydrologic model. But the key difference here is that our parameter values were represented by neural-networks rather than single numbers.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">sharex</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">times</span><span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">forcing</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]))</span>
<span class="n">p_ax</span> <span class="o">=</span> <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">twinx</span><span class="p">()</span>
<span class="n">p_ax</span><span class="o">.</span><span class="n">invert_yaxis</span><span class="p">()</span>
<span class="n">p_ax</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">times</span><span class="p">,</span> <span class="n">forcing</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Precipitation&#39;</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">p_ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="mi">150</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>

<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_zorder</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">patch</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">q_true</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Observed&#39;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">q_pred</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;crimson&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Predicted&#39;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Streamflow </span><span class="se">\n</span><span class="s1"> [$m^3/day$]&#39;</span><span class="p">)</span>
<span class="n">p_ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Precipitation </span><span class="se">\n</span><span class="s1"> [mm/day]&#39;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;upper right&#39;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">text</span><span class="p">(</span>
    <span class="mi">600</span><span class="p">,</span> <span class="mi">10</span> <span class="p">,</span> <span class="sa">f</span><span class="s1">&#39;NSE=</span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">around</span><span class="p">(</span><span class="n">nse</span><span class="p">(</span><span class="n">q_pred</span><span class="p">[</span><span class="n">i</span><span class="p">:],</span> <span class="n">q_true</span><span class="p">[</span><span class="n">i</span><span class="p">::]),</span> <span class="mi">2</span><span class="p">)</span><span class="si">}</span><span class="s1">&#39;</span>
<span class="p">)</span>

<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">surf_storage</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Surface&#39;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">subsurf_storage</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Subsurface&#39;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Storage </span><span class="se">\n</span><span class="s1"> [$m^3$]&#39;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;upper right&#39;</span><span class="p">)</span>

<span class="n">axes</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">forcing</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;PET&#39;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">et</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;ET&#39;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Fluxes </span><span class="se">\n</span><span class="s1"> [$mm/day$]&#39;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;lower right&#39;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Day of prediction&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Text(0.5, 0, &#39;Day of prediction&#39;)
</pre></div>
</div>
<img alt="../_images/chapter2_85_1.png" src="../_images/chapter2_85_1.png" />
</div>
</div>
</section>
<section id="conclusions">
<h3>6. Conclusions<a class="headerlink" href="#conclusions" title="Permalink to this headline">#</a></h3>
<p>In this chapter we hope you have learned that the numerical modeling approaches in traditional hydrologic models is not so different from than those of machine learning (particularly with respect to ODE based models). The conceptual model that we formulated within the pytorch framework was able to be trained with standard optimizers via backpropagation. While the final model we trained is not state of the art in performance we hope that seeing it built up from base principles demystifies many aspects of merging physics with machine learning.</p>
<section id="assignments">
<h4>6.1 Assignments<a class="headerlink" href="#assignments" title="Permalink to this headline">#</a></h4>
<p>To this end we offer some possible modifications and extensions of the work that we’ve described above that we hope sparks your own work.</p>
<ol class="simple">
<li><p>Rather than working the nonlinear reservoir, can you replace the ODE with other classical examples? Perhaps try things like a forced/damped oscillator or projectile motion. How might you handle something like a reservoir with hysteresis where filling has different trajectories than draining?</p></li>
<li><p>Consider how you might adapt storage-discharge relations to a more readily observed area-elevation relation from satellite imagery of reservoirs. Do you think you could reconstruct operations curves from such observations?</p></li>
<li><p>How would you extend the <code class="docutils literal notranslate"><span class="pre">HydroEquation</span></code> module to include more storage buckets? What if this was a configurable option? What about including a store for snow processes? Or a specific vegetation store to account for canopy storage?</p></li>
<li><p>Could you extend the <code class="docutils literal notranslate"><span class="pre">HydroEquation</span></code> to take in time-dependent quantities as inputs? Perhaps you could start with including the precipitation and potential evapotranspiration as input variables.</p></li>
<li><p>Consider spatially explicit subsurface representations. Could such methods possibly be used to learn subsurface properties?</p></li>
</ol>
</section>
<section id="open-questions">
<h4>6.2 Open questions<a class="headerlink" href="#open-questions" title="Permalink to this headline">#</a></h4>
<p>We hope that our simple worked examples are enough for you to be able to modify and expand into code that is useful for your own research. In doing so, there are clearly many open questions. For instance, a natural extension of the final model would be to replace the parameters with more complex neural networks such as Long-Short-Term-Memory (LSTM) networks. Would it be possible to feed such networks with data from multiple basins to produce a global model as has been possible with Long-Short-Term-Memory (LSTM) models? There is also the question of adding on pre/post processing networks which could enhance predictive capabilities, yet retain the ability to model internal states in a physically satisfying way that moves the needle closer to “best of both worlds” with respect to the interpretibility-predictive spectrum.</p>
</section>
</section>
<section id="references">
<h3>References<a class="headerlink" href="#references" title="Permalink to this headline">#</a></h3>
<p>Addor, N., Newman, A. J., Mizukami, N., &amp; Clark, M. P. (2017). The CAMELS data set: catchment attributes and meteorology for large-sample studies. Hydrol. Earth Syst. Sci., 21.</p>
<p>Bennett, A., &amp; Nijssen, B. (2021). Deep Learned Process Parameterizations Provide Better Representations of Turbulent Heat Fluxes in Hydrologic Models. Water Resources Research, 57(5), e2020WR029328. <a class="reference external" href="https://doi.org/10.1029/2020WR029328">https://doi.org/10.1029/2020WR029328</a></p>
<p>Beucler, T., Pritchard, M., Rasp, S., Ott, J., Baldi, P., &amp; Gentine, P. (2020). Enforcing Analytic Constraints in Neural-Networks Emulating Physical Systems. ArXiv:1909.00912 [Physics]. Retrieved from <a class="reference external" href="http://arxiv.org/abs/1909.00912">http://arxiv.org/abs/1909.00912</a></p>
<p>Brenowitz, N. D., &amp; Bretherton, C. S. (2018). Prognostic Validation of a Neural Network Unified Physics Parameterization. Geophysical Research Letters, 45(12), 6289–6298. <a class="reference external" href="https://doi.org/10.1029/2018GL078510">https://doi.org/10.1029/2018GL078510</a></p>
<p>Chen, R. T. Q., Rubanova, Y., Bettencourt, J., &amp; Duvenaud, D. (2018). Neural Ordinary Differential Equations. ArXiv:1806.07366 [Cs, Stat]. Retrieved from <a class="reference external" href="http://arxiv.org/abs/1806.07366">http://arxiv.org/abs/1806.07366</a></p>
<p>Clark, M. P., Slater, A. G., Rupp, D. E., Woods, R. A., Vrugt, J. A., Gupta, H. V., et al. (2008). Framework for Understanding Structural Errors (FUSE): A modular framework to diagnose differences between hydrological models. Water Resources Research, 44(12). <a class="reference external" href="https://doi.org/10.1029/2007WR006735">https://doi.org/10.1029/2007WR006735</a></p>
<p>Feigl, M., Herrnegger, M., Klotz, D., &amp; Schulz, K. (2020). Function Space Optimization: A Symbolic Regression Method for Estimating Parameter Transfer Functions for Hydrological Models. Water Resources Research, 56(10), e2020WR027385. <a class="reference external" href="https://doi.org/10.1029/2020WR027385">https://doi.org/10.1029/2020WR027385</a></p>
<p>Feigl, Moritz, Roesky, B., Herrnegger, M., Schulz, K., &amp; Hayashi, M. (2022). Learning from mistakes—Assessing the performance and uncertainty in process-based models. Hydrological Processes, 36(2), e14515. <a class="reference external" href="https://doi.org/10.1002/hyp.14515">https://doi.org/10.1002/hyp.14515</a></p>
<p>Frame, J., Nearing, G., Kratzert, F., &amp; Rahman, M. (2020). Post processing the U.S. National Water Model with a Long Short-Term Memory network (preprint). EarthArXiv. <a class="reference external" href="https://doi.org/10.31223/osf.io/4xhac">https://doi.org/10.31223/osf.io/4xhac</a></p>
<p>Gauch, M., Kratzert, F., Klotz, D., Nearing, G., Lin, J., &amp; Hochreiter, S. (2021). Rainfall–runoff prediction at multiple timescales with a single Long Short-Term Memory network. Hydrology and Earth System Sciences, 25(4), 2045–2062. <a class="reference external" href="https://doi.org/10.5194/hess-25-2045-2021">https://doi.org/10.5194/hess-25-2045-2021</a></p>
<p>Ian Goodfellow, Yoshua Bengio, &amp; Aaron Courville. (2016). Deep Learning. MIT Press. Retrieved from <a class="reference external" href="https://mitpress.mit.edu/books/deep-learning">https://mitpress.mit.edu/books/deep-learning</a></p>
<p>Isaacson, E., &amp; Keller, H. B. (1994). Analysis of numerical methods. New York: Dover Publications.</p>
<p>Jiang, S., Zheng, Y., &amp; Solomatine, D. (2020). Improving AI System Awareness of Geoscience Knowledge: Symbiotic Integration of Physical Approaches and Deep Learning. Geophysical Research Letters, 47(13), e2020GL088229. <a class="reference external" href="https://doi.org/10.1029/2020GL088229">https://doi.org/10.1029/2020GL088229</a></p>
<p>Jiang, S., Zheng, Y., Wang, C., &amp; Babovic, V. (2022). Uncovering Flooding Mechanisms Across the Contiguous United States Through Interpretive Deep Learning on Representative Catchments. Water Resources Research, 58(1), e2021WR030185. <a class="reference external" href="https://doi.org/10.1029/2021WR030185">https://doi.org/10.1029/2021WR030185</a></p>
<p>Kingma, D. P., &amp; Ba, J. (2017). Adam: A Method for Stochastic Optimization. ArXiv:1412.6980 [Cs]. Retrieved from <a class="reference external" href="http://arxiv.org/abs/1412.6980">http://arxiv.org/abs/1412.6980</a></p>
<p>Kochenderfer, M., &amp; Wheeler, T. (n.d.). Algorithms for Optimization | The MIT Press. Retrieved April 30, 2022, from <a class="reference external" href="https://mitpress.mit.edu/books/algorithms-optimization">https://mitpress.mit.edu/books/algorithms-optimization</a></p>
<p>Konapala, G., Kao, S.-C., Painter, S. L., &amp; Lu, D. (2020). Machine learning assisted hybrid models can improve streamflow simulation in diverse catchments across the conterminous US. Environmental Research Letters, 15(10), 104022. <a class="reference external" href="https://doi.org/10.1088/1748-9326/aba927">https://doi.org/10.1088/1748-9326/aba927</a></p>
<p>Kraft, B., Jung, M., Körner, M., Koirala, S., &amp; Reichstein, M. (2021). Towards hybrid modeling of the global hydrological cycle (preprint). Global hydrology/Modelling approaches. <a class="reference external" href="https://doi.org/10.5194/hess-2021-211">https://doi.org/10.5194/hess-2021-211</a></p>
<p>Kraft, B., Jung, M., Körner, M., Koirala, S., &amp; Reichstein, M. (2022). Towards hybrid modeling of the global hydrological cycle. Hydrology and Earth System Sciences, 26(6), 1579–1614. <a class="reference external" href="https://doi.org/10.5194/hess-26-1579-2022">https://doi.org/10.5194/hess-26-1579-2022</a></p>
<p>Kratzert, F., Klotz, D., Herrnegger, M., Sampson, A. K., Hochreiter, S., &amp; Nearing, G. S. (2019). Toward Improved Predictions in Ungauged Basins: Exploiting the Power of Machine Learning. Water Resources Research, 55(12), 11344–11354. <a class="reference external" href="https://doi.org/10.1029/2019WR026065">https://doi.org/10.1029/2019WR026065</a></p>
<p>Krishnapriyan, A. S., Gholami, A., Zhe, S., Kirby, R. M., &amp; Mahoney, M. W. (2021). Characterizing possible failure modes in physics-informed neural networks. ArXiv:2109.01050 [Physics]. Retrieved from <a class="reference external" href="http://arxiv.org/abs/2109.01050">http://arxiv.org/abs/2109.01050</a></p>
<p>Liang, X., Lettenmaier, D. P., Wood, E. F., &amp; Burges, S. J. (1994). A simple hydrologically based model of land surface water and energy fluxes for general circulation models. Journal of Geophysical Research: Atmospheres, 99(D7), 14415–14428. <a class="reference external" href="https://doi.org/10.1029/94JD00483">https://doi.org/10.1029/94JD00483</a></p>
<p>Mai, J., Shen, H., Tolson, B. A., Gaborit, É., Arsenault, R., Craig, J. R., et al. (2022). The Great Lakes Runoff Intercomparison Project Phase 4: the Great Lakes (GRIP-GL). Hydrology and Earth System Sciences, 26(13), 3537–3572. <a class="reference external" href="https://doi.org/10.5194/hess-26-3537-2022">https://doi.org/10.5194/hess-26-3537-2022</a></p>
<p>Nash, J. E., &amp; Sutcliffe, J. V. (1970). River flow forecasting through conceptual models part I — A discussion of principles. Journal of Hydrology, 10(3), 282–290. <a class="reference external" href="https://doi.org/10.1016/0022-1694(70)90255-6">https://doi.org/10.1016/0022-1694(70)90255-6</a></p>
<p>Nearing, G. S., Kratzert, F., Sampson, A. K., Pelissier, C. S., Klotz, D., Frame, J. M., et al. (n.d.). What Role Does Hydrological Science Play in the Age of Machine Learning? Water Resources Research, n/a(n/a), e2020WR028091. <a class="reference external" href="https://doi.org/10.1029/2020WR028091">https://doi.org/10.1029/2020WR028091</a></p>
<p>Newman, A. J., Clark, M. P., Sampson, K., Wood, A., Hay, L. E., Bock, A., et al. (2015). Development of a large-sample watershed-scale hydrometeorological data set for the contiguous USA: data set characteristics and assessment of regional variability in hydrologic model performance. Hydrology and Earth System Sciences, 19(1), 209–223. <a class="reference external" href="https://doi.org/10.5194/hess-19-209-2015">https://doi.org/10.5194/hess-19-209-2015</a></p>
<p>Nocedal, J., &amp; Wright, S. J. (2006). Numerical optimization (2nd ed). New York: Springer.</p>
<p>Paszke, A., Gross, S., Massa, F., Lerer, A., Bradbury, J., Chanan, G., et al. (2019, December 3). PyTorch: An Imperative Style, High-Performance Deep Learning Library. arXiv. Retrieved from <a class="reference external" href="http://arxiv.org/abs/1912.01703">http://arxiv.org/abs/1912.01703</a></p>
<p>Raissi, M., Perdikaris, P., &amp; Karniadakis, G. E. (2019). Physics-informed neural networks: A deep learning framework for solving forward and inverse problems involving nonlinear partial differential equations. Journal of Computational Physics, 378, 686–707. <a class="reference external" href="https://doi.org/10.1016/j.jcp.2018.10.045">https://doi.org/10.1016/j.jcp.2018.10.045</a></p>
<p>Rasp, S., Pritchard, M. S., &amp; Gentine, P. (2018). Deep learning to represent subgrid processes in climate models. Proceedings of the National Academy of Sciences, 115(39), 9684–9689. <a class="reference external" href="https://doi.org/10.1073/pnas.1810286115">https://doi.org/10.1073/pnas.1810286115</a></p>
<p>Ruder, S. (2017, June 15). An overview of gradient descent optimization algorithms. arXiv. Retrieved from <a class="reference external" href="http://arxiv.org/abs/1609.04747">http://arxiv.org/abs/1609.04747</a></p>
<p>Schaeffer, H. (2017). Learning partial differential equations via data discovery and sparse optimization. Proceedings of the Royal Society A: Mathematical, Physical and Engineering Science, 473(2197), 20160446. <a class="reference external" href="https://doi.org/10.1098/rspa.2016.0446">https://doi.org/10.1098/rspa.2016.0446</a></p>
<p>Shen, C. (2018). A Transdisciplinary Review of Deep Learning Research and Its Relevance for Water Resources Scientists. Water Resources Research, 54(11), 8558–8593. <a class="reference external" href="https://doi.org/10.1029/2018WR022643">https://doi.org/10.1029/2018WR022643</a></p>
<p>Thapa, S., Zhao, Z., Li, B., Lu, L., Fu, D., Shi, X., et al. (2020). Snowmelt-Driven Streamflow Prediction Using Machine Learning Techniques (LSTM, NARX, GPR, and SVR). Water, 12(6), 1734. <a class="reference external" href="https://doi.org/10.3390/w12061734">https://doi.org/10.3390/w12061734</a></p>
<p>Tian, Y., Xu, Y.-P., Yang, Z., Wang, G., &amp; Zhu, Q. (2018). Integration of a Parsimonious Hydrological Model with Recurrent Neural Networks for Improved Streamflow Forecasting. Water, 10(11), 1655. <a class="reference external" href="https://doi.org/10.3390/w10111655">https://doi.org/10.3390/w10111655</a></p>
<p>Xingyuan Chen, Peishi Jiang, Justine E.C. Missik, Zhongming Gao, Brittany Verbeke, &amp; Heping Liu. (2020). Opening the black box of LSTM models using XAI. Presented at the American Geophysical Union Fall Meeting, Virtual: American Geophysical Union.</p>
<p>Yuan-Heng, W., Link to external site,  this link will open in a new window, Gupta, H. V., Zeng, X., Niu, G., &amp; Link to external site,  this link will open in a new window. (2021). Exploring the Potential of Long Short-Term Memory Networks for Improving Understanding of Continental- and Regional-Scale Snowpack Dynamics. Earth and Space Science Open Archive ESSOAr. <a class="reference external" href="http://dx.doi.org/10.1002/essoar.10507610.1">http://dx.doi.org/10.1002/essoar.10507610.1</a></p>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "earthai"
        },
        kernelOptions: {
            kernelName: "earthai",
            path: "./chapters"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'earthai'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="chapter1.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Chapter 7: AI for physics-inspired hydrology modeling</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="../reference/glossary.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Glossaries</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By eScience Institute, University of Washington<br/>
  
      &copy; Copyright 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>